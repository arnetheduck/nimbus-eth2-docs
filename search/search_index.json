{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"The Nimbus Guide If you're eager to get started, check out our quickstart guide . Coming from a different client? Check out the migration guide . Nimbus is client for the Ethereum consensus layer (eth2) and execution layer (eth1) that is lightweight , secure and easy to use . This book describes the consensus layer client, nimbus-eth2 , in particular. Its efficiency and low resource consumption allows it to perform well on all kinds of systems, ranging from Raspberry Pi's and mobile devices where it contributes to low power consumption and security -- to powerful servers where it leaves resources free to perform other tasks, such as running an execution node . \"just because it [Nimbus] is optimized to be minimally resource intensive, doesn't mean you can't run it on a server. It means that when you do run it on a server, it is consuming a lot less resources.\" https://t.co/F2sdZouBtD \u2014 Nimbus (@ethnimbus) March 30, 2021 This book explains the ways in which you can use Nimbus to either monitor the beacon chain or become a fully-fledged validator. Tip The Merge \ud83d\udc3c is happening soon! Bookmark our merge readiness page to stay on top of how you need to prepare. Note Staking and becoming a validator on Ethereum requires 32 ETH, a stable high-speed internet connection and an always-on server. Before staking, make sure that you understand the requirements and practice setting up a validator on a testnet. Pooled staking and Staking as a service are alternative ways to stake in the network. You can also run a Nimbus node without staking. Helpful resources Ethereum consensus spec Ben Edgington's annotated spec Vitalik's annotated spec Danny Ryan's annotated spec Get in touch Need help with anything? Join us on Status and Discord . Donate If you'd like to contribute to Nimbus development: Our donation address is 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 We're also listed on GitCoin Stay updated Subscribe to our newsletter here . Disclaimer This documentation assumes Nimbus is in its ideal state. The project is still under active development. Please submit a Github issue if you come across a problem.","title":"The Nimbus Guide"},{"location":"index.html#the-nimbus-guide","text":"If you're eager to get started, check out our quickstart guide . Coming from a different client? Check out the migration guide . Nimbus is client for the Ethereum consensus layer (eth2) and execution layer (eth1) that is lightweight , secure and easy to use . This book describes the consensus layer client, nimbus-eth2 , in particular. Its efficiency and low resource consumption allows it to perform well on all kinds of systems, ranging from Raspberry Pi's and mobile devices where it contributes to low power consumption and security -- to powerful servers where it leaves resources free to perform other tasks, such as running an execution node . \"just because it [Nimbus] is optimized to be minimally resource intensive, doesn't mean you can't run it on a server. It means that when you do run it on a server, it is consuming a lot less resources.\" https://t.co/F2sdZouBtD \u2014 Nimbus (@ethnimbus) March 30, 2021 This book explains the ways in which you can use Nimbus to either monitor the beacon chain or become a fully-fledged validator. Tip The Merge \ud83d\udc3c is happening soon! Bookmark our merge readiness page to stay on top of how you need to prepare. Note Staking and becoming a validator on Ethereum requires 32 ETH, a stable high-speed internet connection and an always-on server. Before staking, make sure that you understand the requirements and practice setting up a validator on a testnet. Pooled staking and Staking as a service are alternative ways to stake in the network. You can also run a Nimbus node without staking.","title":"The Nimbus Guide"},{"location":"index.html#helpful-resources","text":"Ethereum consensus spec Ben Edgington's annotated spec Vitalik's annotated spec Danny Ryan's annotated spec","title":"Helpful resources"},{"location":"index.html#get-in-touch","text":"Need help with anything? Join us on Status and Discord .","title":"Get in touch"},{"location":"index.html#donate","text":"If you'd like to contribute to Nimbus development: Our donation address is 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 We're also listed on GitCoin","title":"Donate"},{"location":"index.html#stay-updated","text":"Subscribe to our newsletter here .","title":"Stay updated"},{"location":"index.html#disclaimer","text":"This documentation assumes Nimbus is in its ideal state. The project is still under active development. Please submit a Github issue if you come across a problem.","title":"Disclaimer"},{"location":"additional-validator.html","text":"Add an additional validator To add an additional validator, generate a new key then follow the same steps as you did when adding your other keys. You'll have to restart the beacon node for the changes to take effect. Tip A single Nimbus instance is able to handle multiple validators.","title":"Add an additional validator"},{"location":"additional-validator.html#add-an-additional-validator","text":"To add an additional validator, generate a new key then follow the same steps as you did when adding your other keys. You'll have to restart the beacon node for the changes to take effect. Tip A single Nimbus instance is able to handle multiple validators.","title":"Add an additional validator"},{"location":"api.html","text":"JSON-RPC API (deprecated) Warning As of v22.6.0, the Nimbus JSON-RPC interface has been removed following an extended deprecation period. You are encouraged to migrate your applications to the REST API . The JSON-RPC API pre-dated the REST API and was based on early designs of the beacon chain. This guide is kept for historical reference, as well as to aid migration. Beacon chain API get_v1_beacon_genesis curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_genesis\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/genesis -s | jq get_v1_beacon_states_root curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_root\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/root -s | jq get_v1_beacon_states_fork curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_fork\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/fork -s | jq get_v1_beacon_states_finality_checkpoints curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_finality_checkpoints\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/finality_checkpoints -s | jq get_v1_beacon_states_stateId_validators curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validators\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validators -s | jq get_v1_beacon_states_stateId_validators_validatorId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validators_validatorId\",\"params\":[\"finalized\", \"100167\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validators/100167 -s | jq get_v1_beacon_states_stateId_validator_balances curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validator_balances\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validator_balances -s | jq get_v1_beacon_states_stateId_committees_epoch curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_committees_epoch\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/committees -s | jq get_v1_beacon_headers get_v1_beacon_headers_blockId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_headers_blockId\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/headers/finalized -s | jq post_v1_beacon_blocks curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_blocks\",\"params\":[{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body\":{\"randao_reveal\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"eth1_data\":{\"deposit_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"deposit_count\":\"1\",\"block_hash\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"graffiti\":\"string\",\"proposer_slashings\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"attester_slashings\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"attestations\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"deposits\":[{\"proof\":[\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"data\":{\"pubkey\":\"0x93247f2209abcacf57b75a51dafae777f9dd38bc7053d1af526f220a7489a6d3a2753e5f3e8b1cfe39b56f43611df74a\",\"withdrawal_credentials\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"amount\":\"1\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"voluntary_exits\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]}},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body\":{\"randao_reveal\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"eth1_data\":{\"deposit_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"deposit_count\":\"1\",\"block_hash\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"graffiti\":\"string\",\"proposer_slashings\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"attester_slashings\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"attestations\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"deposits\":[{\"proof\":[\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"data\":{\"pubkey\":\"0x93247f2209abcacf57b75a51dafae777f9dd38bc7053d1af526f220a7489a6d3a2753e5f3e8b1cfe39b56f43611df74a\",\"withdrawal_credentials\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"amount\":\"1\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"voluntary_exits\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]}},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/blocks -s | jq get_v1_beacon_blocks_blockId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/beacon/blocks/finalized -s | jq get_v1_beacon_blocks_blockId_root curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_root\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/blocks/finalized/root -s | jq get_v1_beacon_blocks_blockId_attestations curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_attestations\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/blocks/finalized/attestations -s | jq post_v1_beacon_pool_attestations curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_attestations\",\"params\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}]' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/attestations -s | jq get_v1_beacon_pool_attester_slashings curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_attester_slashings\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/attester_slashings -s | jq post_v1_beacon_pool_attester_slashings curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_attester_slashings\",\"params\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/attester_slashings -s | jq get_v1_beacon_pool_proposer_slashings curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_proposer_slashings\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/proposer_slashings -s | jq post_v1_beacon_pool_proposer_slashings curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_proposer_slashings\",\"params\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/proposer_slashings -s | jq get_v1_beacon_pool_voluntary_exits curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_voluntary_exits\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/voluntary_exits -s | jq post_v1_beacon_pool_voluntary_exits curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_voluntary_exits\",\"params\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/voluntary_exits -s | jq Beacon Node API get_v1_node_identity curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_identity\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/identity -s | jq get_v1_node_peers curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peers -s | jq get_v1_node_peers_peerId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peers_peerId\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peer/QmYyQSo1c1Ym7orWxLYvCrM2EmxFTANf8wXmmE7DWjhx5N -s | jq get_v1_node_peer_count curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peer_count\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peer_count -s | jq get_v1_node_version curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_version\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/version -s | jq get_v1_node_syncing curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_syncing\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/syncing -s | jq get_v1_node_health curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_health\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/health -s -w \"%{http_code}\" Valdiator API get_v1_validator_duties_attester curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_duties_attester\",\"params\":[1,[\"a7a0502eae26043d1ac39a39457a6cdf68fae2055d89c7dc59092c25911e4ee55c4e7a31ade61c39480110a393be28e8\",\"a1826dd94cd96c48a81102d316a2af4960d19ca0b574ae5695f2d39a88685a43997cef9a5c26ad911847674d20c46b75\"]],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/eth/v1/validator/duties/attester/1 -H 'Content-Type: application/json' -d '[\"a7a0502eae26043d1ac39a39457a6cdf68fae2055d89c7dc59092c25911e4ee55c4e7a31ade61c39480110a393be28e8\"]' -s | jq get_v1_validator_duties_proposer curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"get_v1_validator_duties_proposer\",\"params\":[1] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/duties/proposer/1 -s | jq get_v1_validator_block curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_block\",\"params\":[1,\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"0x4e696d6275732f76312e302e322d64333032633164382d73746174656f667573\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/blocks/1?randao_reveal=0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505&graffiti=0x4e696d6275732f76312e302e322d64333032633164382d73746174656f667573 -s | jq get_v1_validator_attestation_data curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_attestation_data\",\"params\":[1, 1],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/attestation_data?slot=1&committee_index=1 -s | jq get_v1_validator_aggregate_attestation curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_aggregate_attestation\",\"params\":[1, \"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/aggregate_attestation?slot=1&attestation_data_root=0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2 -s | jq post_v1_validator_aggregate_and_proofs curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_validator_aggregate_and_proofs\",\"params\":[{\"message\":{\"aggregator_index\":\"1\",\"aggregate\":{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"selection_proof\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/eth/v1/validator/aggregate_and_proofs -H 'Content-Type: application/json' -d '[{\"message\":{\"aggregator_index\":\"1\",\"aggregate\":{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"selection_proof\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]' -s | jq post_v1_validator_beacon_committee_subscriptions Config API get_v1_config_fork_schedule curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_fork_schedule\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/fork_schedule -s | jq get_v1_config_spec curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_spec\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/spec -s | jq get_v1_config_deposit_contract curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_deposit_contract\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/deposit_contract -s | jq Administrative / Debug API get_v1_debug_beacon_states_stateId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_debug_beacon_states_stateId\",\"params\":[\"head\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/debug/beacon/states/head -s | jq get_v1_debug_beacon_heads Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/debug/beacon/heads -s | jq Nimbus extensions getBeaconHead The latest head slot, as chosen by the latest fork choice. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getBeaconHead\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/beacon/head -s | jq getChainHead Show chain head information, including head, justified and finalized checkpoints. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getChainHead\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/chain/head -s | jq getNodeVersion curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNodeVersion\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/node/version -s | jq peers Show a list of peers in PeerPool. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"peers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/network/peers -s | jq getSyncing Shows current state of forward syncing manager. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getSyncing\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/syncmanager/status -s | jq getNetworkPeerId Shows current node's libp2p peer identifier (PeerID). curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNetworkPeerId\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq getNetworkPeers Shows list of available PeerIDs in PeerPool. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNetworkPeers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/network/peers -s | jq getNetworkEnr setLogLevel Set the current logging level dynamically: TRACE, DEBUG, INFO, NOTICE, WARN, ERROR or FATAL curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"setLogLevel\",\"params\":[\"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\"] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/nimbus/v1/chronicles/settings -d \"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\" -s | jq setGraffiti Set the graffiti bytes that will be included in proposed blocks. The graffiti bytes can be specified as an UTF-8 encoded string or as an 0x-prefixed hex string specifying raw bytes. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"setGraffiti\",\"params\":[\"Mr F was here\"] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/nimbus/v1/graffiti -d \"Mr F was here\" -s | jq getEth1Chain Get the list of Eth1 blocks that the beacon node is currently storing in memory. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getEth1Chain\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/eth1/chain -s | jq getEth1ProposalData Inspect the eth1 data that the beacon node would produce if it was tasked to produce a block for the current slot. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getEth1ProposalData\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/eth1/proposal_data -s | jq debug_getChronosFutures Get the current list of live async futures in the process - compile with -d:chronosFutureTracking to enable. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"debug_getChronosFutures\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result | (.[0] | keys_unsorted) as $keys | $keys, map([.[ $keys[] ]])[] | @csv' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/debug/chronos/futures -s | jq debug_getGossipSubPeers Get the current list of live async futures in the process - compile with -d:chronosFutureTracking to enable. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"debug_getGossipSubPeers\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/debug/gossip/peers -s | jq","title":"JSON-RPC API (deprecated)"},{"location":"api.html#json-rpc-api-deprecated","text":"Warning As of v22.6.0, the Nimbus JSON-RPC interface has been removed following an extended deprecation period. You are encouraged to migrate your applications to the REST API . The JSON-RPC API pre-dated the REST API and was based on early designs of the beacon chain. This guide is kept for historical reference, as well as to aid migration.","title":"JSON-RPC API (deprecated)"},{"location":"api.html#beacon-chain-api","text":"","title":"Beacon chain API"},{"location":"api.html#get_v1_beacon_genesis","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_genesis\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/genesis -s | jq","title":"get_v1_beacon_genesis"},{"location":"api.html#get_v1_beacon_states_root","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_root\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/root -s | jq","title":"get_v1_beacon_states_root"},{"location":"api.html#get_v1_beacon_states_fork","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_fork\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/fork -s | jq","title":"get_v1_beacon_states_fork"},{"location":"api.html#get_v1_beacon_states_finality_checkpoints","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_finality_checkpoints\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/finality_checkpoints -s | jq","title":"get_v1_beacon_states_finality_checkpoints"},{"location":"api.html#get_v1_beacon_states_stateid_validators","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validators\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validators -s | jq","title":"get_v1_beacon_states_stateId_validators"},{"location":"api.html#get_v1_beacon_states_stateid_validators_validatorid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validators_validatorId\",\"params\":[\"finalized\", \"100167\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validators/100167 -s | jq","title":"get_v1_beacon_states_stateId_validators_validatorId"},{"location":"api.html#get_v1_beacon_states_stateid_validator_balances","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validator_balances\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validator_balances -s | jq","title":"get_v1_beacon_states_stateId_validator_balances"},{"location":"api.html#get_v1_beacon_states_stateid_committees_epoch","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_committees_epoch\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/committees -s | jq","title":"get_v1_beacon_states_stateId_committees_epoch"},{"location":"api.html#get_v1_beacon_headers","text":"","title":"get_v1_beacon_headers"},{"location":"api.html#get_v1_beacon_headers_blockid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_headers_blockId\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/headers/finalized -s | jq","title":"get_v1_beacon_headers_blockId"},{"location":"api.html#post_v1_beacon_blocks","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_blocks\",\"params\":[{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body\":{\"randao_reveal\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"eth1_data\":{\"deposit_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"deposit_count\":\"1\",\"block_hash\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"graffiti\":\"string\",\"proposer_slashings\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"attester_slashings\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"attestations\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"deposits\":[{\"proof\":[\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"data\":{\"pubkey\":\"0x93247f2209abcacf57b75a51dafae777f9dd38bc7053d1af526f220a7489a6d3a2753e5f3e8b1cfe39b56f43611df74a\",\"withdrawal_credentials\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"amount\":\"1\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"voluntary_exits\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]}},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body\":{\"randao_reveal\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"eth1_data\":{\"deposit_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"deposit_count\":\"1\",\"block_hash\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"graffiti\":\"string\",\"proposer_slashings\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"attester_slashings\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"attestations\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"deposits\":[{\"proof\":[\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"data\":{\"pubkey\":\"0x93247f2209abcacf57b75a51dafae777f9dd38bc7053d1af526f220a7489a6d3a2753e5f3e8b1cfe39b56f43611df74a\",\"withdrawal_credentials\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"amount\":\"1\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"voluntary_exits\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]}},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/blocks -s | jq","title":"post_v1_beacon_blocks"},{"location":"api.html#get_v1_beacon_blocks_blockid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/beacon/blocks/finalized -s | jq","title":"get_v1_beacon_blocks_blockId"},{"location":"api.html#get_v1_beacon_blocks_blockid_root","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_root\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/blocks/finalized/root -s | jq","title":"get_v1_beacon_blocks_blockId_root"},{"location":"api.html#get_v1_beacon_blocks_blockid_attestations","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_attestations\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/blocks/finalized/attestations -s | jq","title":"get_v1_beacon_blocks_blockId_attestations"},{"location":"api.html#post_v1_beacon_pool_attestations","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_attestations\",\"params\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}]' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/attestations -s | jq","title":"post_v1_beacon_pool_attestations"},{"location":"api.html#get_v1_beacon_pool_attester_slashings","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_attester_slashings\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/attester_slashings -s | jq","title":"get_v1_beacon_pool_attester_slashings"},{"location":"api.html#post_v1_beacon_pool_attester_slashings","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_attester_slashings\",\"params\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/attester_slashings -s | jq","title":"post_v1_beacon_pool_attester_slashings"},{"location":"api.html#get_v1_beacon_pool_proposer_slashings","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_proposer_slashings\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/proposer_slashings -s | jq","title":"get_v1_beacon_pool_proposer_slashings"},{"location":"api.html#post_v1_beacon_pool_proposer_slashings","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_proposer_slashings\",\"params\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/proposer_slashings -s | jq","title":"post_v1_beacon_pool_proposer_slashings"},{"location":"api.html#get_v1_beacon_pool_voluntary_exits","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_voluntary_exits\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/voluntary_exits -s | jq","title":"get_v1_beacon_pool_voluntary_exits"},{"location":"api.html#post_v1_beacon_pool_voluntary_exits","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_voluntary_exits\",\"params\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/voluntary_exits -s | jq","title":"post_v1_beacon_pool_voluntary_exits"},{"location":"api.html#beacon-node-api","text":"","title":"Beacon Node API"},{"location":"api.html#get_v1_node_identity","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_identity\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/identity -s | jq","title":"get_v1_node_identity"},{"location":"api.html#get_v1_node_peers","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peers -s | jq","title":"get_v1_node_peers"},{"location":"api.html#get_v1_node_peers_peerid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peers_peerId\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peer/QmYyQSo1c1Ym7orWxLYvCrM2EmxFTANf8wXmmE7DWjhx5N -s | jq","title":"get_v1_node_peers_peerId"},{"location":"api.html#get_v1_node_peer_count","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peer_count\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peer_count -s | jq","title":"get_v1_node_peer_count"},{"location":"api.html#get_v1_node_version","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_version\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/version -s | jq","title":"get_v1_node_version"},{"location":"api.html#get_v1_node_syncing","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_syncing\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/syncing -s | jq","title":"get_v1_node_syncing"},{"location":"api.html#get_v1_node_health","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_health\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/health -s -w \"%{http_code}\"","title":"get_v1_node_health"},{"location":"api.html#valdiator-api","text":"","title":"Valdiator API"},{"location":"api.html#get_v1_validator_duties_attester","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_duties_attester\",\"params\":[1,[\"a7a0502eae26043d1ac39a39457a6cdf68fae2055d89c7dc59092c25911e4ee55c4e7a31ade61c39480110a393be28e8\",\"a1826dd94cd96c48a81102d316a2af4960d19ca0b574ae5695f2d39a88685a43997cef9a5c26ad911847674d20c46b75\"]],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/eth/v1/validator/duties/attester/1 -H 'Content-Type: application/json' -d '[\"a7a0502eae26043d1ac39a39457a6cdf68fae2055d89c7dc59092c25911e4ee55c4e7a31ade61c39480110a393be28e8\"]' -s | jq","title":"get_v1_validator_duties_attester"},{"location":"api.html#get_v1_validator_duties_proposer","text":"curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"get_v1_validator_duties_proposer\",\"params\":[1] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/duties/proposer/1 -s | jq","title":"get_v1_validator_duties_proposer"},{"location":"api.html#get_v1_validator_block","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_block\",\"params\":[1,\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"0x4e696d6275732f76312e302e322d64333032633164382d73746174656f667573\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/blocks/1?randao_reveal=0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505&graffiti=0x4e696d6275732f76312e302e322d64333032633164382d73746174656f667573 -s | jq","title":"get_v1_validator_block"},{"location":"api.html#get_v1_validator_attestation_data","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_attestation_data\",\"params\":[1, 1],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/attestation_data?slot=1&committee_index=1 -s | jq","title":"get_v1_validator_attestation_data"},{"location":"api.html#get_v1_validator_aggregate_attestation","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_aggregate_attestation\",\"params\":[1, \"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/aggregate_attestation?slot=1&attestation_data_root=0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2 -s | jq","title":"get_v1_validator_aggregate_attestation"},{"location":"api.html#post_v1_validator_aggregate_and_proofs","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_validator_aggregate_and_proofs\",\"params\":[{\"message\":{\"aggregator_index\":\"1\",\"aggregate\":{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"selection_proof\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/eth/v1/validator/aggregate_and_proofs -H 'Content-Type: application/json' -d '[{\"message\":{\"aggregator_index\":\"1\",\"aggregate\":{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"selection_proof\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]' -s | jq","title":"post_v1_validator_aggregate_and_proofs"},{"location":"api.html#post_v1_validator_beacon_committee_subscriptions","text":"","title":"post_v1_validator_beacon_committee_subscriptions"},{"location":"api.html#config-api","text":"","title":"Config API"},{"location":"api.html#get_v1_config_fork_schedule","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_fork_schedule\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/fork_schedule -s | jq","title":"get_v1_config_fork_schedule"},{"location":"api.html#get_v1_config_spec","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_spec\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/spec -s | jq","title":"get_v1_config_spec"},{"location":"api.html#get_v1_config_deposit_contract","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_deposit_contract\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/deposit_contract -s | jq","title":"get_v1_config_deposit_contract"},{"location":"api.html#administrative-debug-api","text":"","title":"Administrative / Debug API"},{"location":"api.html#get_v1_debug_beacon_states_stateid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_debug_beacon_states_stateId\",\"params\":[\"head\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/debug/beacon/states/head -s | jq","title":"get_v1_debug_beacon_states_stateId"},{"location":"api.html#get_v1_debug_beacon_heads","text":"Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/debug/beacon/heads -s | jq","title":"get_v1_debug_beacon_heads"},{"location":"api.html#nimbus-extensions","text":"","title":"Nimbus extensions"},{"location":"api.html#getbeaconhead","text":"The latest head slot, as chosen by the latest fork choice. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getBeaconHead\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/beacon/head -s | jq","title":"getBeaconHead"},{"location":"api.html#getchainhead","text":"Show chain head information, including head, justified and finalized checkpoints. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getChainHead\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/chain/head -s | jq","title":"getChainHead"},{"location":"api.html#getnodeversion","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNodeVersion\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/node/version -s | jq","title":"getNodeVersion"},{"location":"api.html#peers","text":"Show a list of peers in PeerPool. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"peers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/network/peers -s | jq","title":"peers"},{"location":"api.html#getsyncing","text":"Shows current state of forward syncing manager. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getSyncing\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/syncmanager/status -s | jq","title":"getSyncing"},{"location":"api.html#getnetworkpeerid","text":"Shows current node's libp2p peer identifier (PeerID). curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNetworkPeerId\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq","title":"getNetworkPeerId"},{"location":"api.html#getnetworkpeers","text":"Shows list of available PeerIDs in PeerPool. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNetworkPeers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/network/peers -s | jq","title":"getNetworkPeers"},{"location":"api.html#getnetworkenr","text":"","title":"getNetworkEnr"},{"location":"api.html#setloglevel","text":"Set the current logging level dynamically: TRACE, DEBUG, INFO, NOTICE, WARN, ERROR or FATAL curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"setLogLevel\",\"params\":[\"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\"] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/nimbus/v1/chronicles/settings -d \"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\" -s | jq","title":"setLogLevel"},{"location":"api.html#setgraffiti","text":"Set the graffiti bytes that will be included in proposed blocks. The graffiti bytes can be specified as an UTF-8 encoded string or as an 0x-prefixed hex string specifying raw bytes. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"setGraffiti\",\"params\":[\"Mr F was here\"] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/nimbus/v1/graffiti -d \"Mr F was here\" -s | jq","title":"setGraffiti"},{"location":"api.html#geteth1chain","text":"Get the list of Eth1 blocks that the beacon node is currently storing in memory. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getEth1Chain\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/eth1/chain -s | jq","title":"getEth1Chain"},{"location":"api.html#geteth1proposaldata","text":"Inspect the eth1 data that the beacon node would produce if it was tasked to produce a block for the current slot. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getEth1ProposalData\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/eth1/proposal_data -s | jq","title":"getEth1ProposalData"},{"location":"api.html#debug_getchronosfutures","text":"Get the current list of live async futures in the process - compile with -d:chronosFutureTracking to enable. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"debug_getChronosFutures\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result | (.[0] | keys_unsorted) as $keys | $keys, map([.[ $keys[] ]])[] | @csv' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/debug/chronos/futures -s | jq","title":"debug_getChronosFutures"},{"location":"api.html#debug_getgossipsubpeers","text":"Get the current list of live async futures in the process - compile with -d:chronosFutureTracking to enable. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"debug_getGossipSubPeers\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/debug/gossip/peers -s | jq","title":"debug_getGossipSubPeers"},{"location":"attestation-performance.html","text":"Analyze attestation performance ncli_db validatorPerf is an advanced tool that helps you analyze the performance of your validator over time. The tool requires that you built nimbus from source . Steps Make sure you're in the nimbus-eth2 repository. 1. Build ncli_db The first step is to build ncli_db : make ncli_db 2. View options To view the options available to you, run: build/ncli_db --help At the top you should see ncli_db [OPTIONS]... command The following options are available: --db Directory where `nbc.sqlite` is stored. --network The Eth2 network preset to use. Where: The network can either be mainnet , prater , ropsten or sepolia The default location of the db is build/data/shared_mainnet_0/db for mainnet , build/data/shared_prater_0/db for prater , etc. Near the bottom, you should see ncli_db validatorPerf [OPTIONS]... The following options are available: --start-slot Starting slot, negative = backwards from head [=-128 * SLOTS_PER_EPOCH.int64]. --slots Number of slots to run benchmark for, 0 = all the way to head [=0]. Use start-slot and slots to restrict the analysis on a specific block range. 3. Run To view the performance of all validators on Prater so far across the entire block range stored in your database, run: build/ncli_db validatorPerf \\ --network = prater \\ --db = build/data/shared_prater_0/db You should see output that looks like to the following: validator_index,attestation_hits,attestation_misses,head_attestation_hits,head_attestation_misses,target_attestation_hits,target_attestation_misses,delay_avg,first_slot_head_attester_when_first_slot_empty,first_slot_head_attester_when_first_slot_not_empty 0,128,0,127,1,128,0,1.0078125,0,3 1,128,0,125,3,127,1,1.0078125,0,2 2,128,0,127,1,127,1,1.0078125,0,5 ... 4. Adjust to target a specific block range To restrict the analysis to the performance between slots 0 and 128, say, run: build/ncli_db validatorPerf \\ --network = prater \\ --db = build/data/shared_prater_0/db \\ --start-slot = 0 \\ --slots = 128 5. Compare my validators to the global average We'll use Paul Hauner's wonderful workbook as a template. This workbook consists of three inter-related spreadsheets - Summary , My Validators , and datasource . Make a copy of the document Remove the table entries in My Validators and delete everything in the datasource sheet Import the output from validatorPerf to datasource - the easiest way to do this is to pipe the output to a csv , remove the first few lines, and import the csv into datasource Manually copy over your validator(s) to the My Validators sheet - the easiest way to find your validator's validator_index is to search for it by its public key on beaconcha.in (for example, this validator's index is 115733) Go to the Summary page and view your results Resources The workbook's method is explained here .","title":"Analyze attestation performance"},{"location":"attestation-performance.html#analyze-attestation-performance","text":"ncli_db validatorPerf is an advanced tool that helps you analyze the performance of your validator over time. The tool requires that you built nimbus from source .","title":"Analyze attestation performance"},{"location":"attestation-performance.html#steps","text":"Make sure you're in the nimbus-eth2 repository.","title":"Steps"},{"location":"attestation-performance.html#1-build-ncli_db","text":"The first step is to build ncli_db : make ncli_db","title":"1. Build ncli_db"},{"location":"attestation-performance.html#2-view-options","text":"To view the options available to you, run: build/ncli_db --help At the top you should see ncli_db [OPTIONS]... command The following options are available: --db Directory where `nbc.sqlite` is stored. --network The Eth2 network preset to use. Where: The network can either be mainnet , prater , ropsten or sepolia The default location of the db is build/data/shared_mainnet_0/db for mainnet , build/data/shared_prater_0/db for prater , etc. Near the bottom, you should see ncli_db validatorPerf [OPTIONS]... The following options are available: --start-slot Starting slot, negative = backwards from head [=-128 * SLOTS_PER_EPOCH.int64]. --slots Number of slots to run benchmark for, 0 = all the way to head [=0]. Use start-slot and slots to restrict the analysis on a specific block range.","title":"2. View options"},{"location":"attestation-performance.html#3-run","text":"To view the performance of all validators on Prater so far across the entire block range stored in your database, run: build/ncli_db validatorPerf \\ --network = prater \\ --db = build/data/shared_prater_0/db You should see output that looks like to the following: validator_index,attestation_hits,attestation_misses,head_attestation_hits,head_attestation_misses,target_attestation_hits,target_attestation_misses,delay_avg,first_slot_head_attester_when_first_slot_empty,first_slot_head_attester_when_first_slot_not_empty 0,128,0,127,1,128,0,1.0078125,0,3 1,128,0,125,3,127,1,1.0078125,0,2 2,128,0,127,1,127,1,1.0078125,0,5 ...","title":"3. Run"},{"location":"attestation-performance.html#4-adjust-to-target-a-specific-block-range","text":"To restrict the analysis to the performance between slots 0 and 128, say, run: build/ncli_db validatorPerf \\ --network = prater \\ --db = build/data/shared_prater_0/db \\ --start-slot = 0 \\ --slots = 128","title":"4. Adjust to target a specific block range"},{"location":"attestation-performance.html#5-compare-my-validators-to-the-global-average","text":"We'll use Paul Hauner's wonderful workbook as a template. This workbook consists of three inter-related spreadsheets - Summary , My Validators , and datasource . Make a copy of the document Remove the table entries in My Validators and delete everything in the datasource sheet Import the output from validatorPerf to datasource - the easiest way to do this is to pipe the output to a csv , remove the first few lines, and import the csv into datasource Manually copy over your validator(s) to the My Validators sheet - the easiest way to find your validator's validator_index is to search for it by its public key on beaconcha.in (for example, this validator's index is 115733) Go to the Summary page and view your results","title":"5. Compare my validators to the global average"},{"location":"attestation-performance.html#resources","text":"The workbook's method is explained here .","title":"Resources"},{"location":"audit.html","text":"Security Audit Summary Nimbus has undergone an extensive, multi-vendor ( ConsenSys Diligence , NCC Group , and Trail of Bits ) security assessment over a period of several months. During that process, we were notified of several issues within the codebase. These issues have been addressed contributing significantly to the overall security of Nimbus and other applications that use its libraries. Additionally, as a result of the work done from our security vendors, we have incoroprated many new security processes and tooling to improve our ability to find security issues in the future. For more information on the issues and how they were addressed, the interested reader should direct themselves to the scoped repositories ; all reported issues and their mitigations are open to the public. History Back in May of last year (2020), Status and the Nimbus Team posted a Request for Proposal document regarding the security assessment of the nimbus-eth2 repository (formerly nim-beacon-chain ) and its software dependencies. After thoroughly vetting and weighing the submitted proposals, 3 security vendors were chosen to review the codebase for a timeline of approximately 3 months . The kickoff announcement can be read here . We separated the codebase into sub-topics with various tasks. These tasks were then broken up and assigned to the vendor(s) with the required expertise. The desired deliverable outcome was GitHub issues in the repositories under review, which is a shift from the standard \u201cassessment report\u201d provided by most security assessments in the space. You can view the issues here . To be very clear, we did not engage in this security assessment to get a stamp of approval from the security community. All of the effort put into creating this process and engaging the community was in the service of increasing the level of security and code quality of the Nimbus software.","title":"Security Audit"},{"location":"audit.html#security-audit","text":"","title":"Security Audit"},{"location":"audit.html#summary","text":"Nimbus has undergone an extensive, multi-vendor ( ConsenSys Diligence , NCC Group , and Trail of Bits ) security assessment over a period of several months. During that process, we were notified of several issues within the codebase. These issues have been addressed contributing significantly to the overall security of Nimbus and other applications that use its libraries. Additionally, as a result of the work done from our security vendors, we have incoroprated many new security processes and tooling to improve our ability to find security issues in the future. For more information on the issues and how they were addressed, the interested reader should direct themselves to the scoped repositories ; all reported issues and their mitigations are open to the public.","title":"Summary"},{"location":"audit.html#history","text":"Back in May of last year (2020), Status and the Nimbus Team posted a Request for Proposal document regarding the security assessment of the nimbus-eth2 repository (formerly nim-beacon-chain ) and its software dependencies. After thoroughly vetting and weighing the submitted proposals, 3 security vendors were chosen to review the codebase for a timeline of approximately 3 months . The kickoff announcement can be read here . We separated the codebase into sub-topics with various tasks. These tasks were then broken up and assigned to the vendor(s) with the required expertise. The desired deliverable outcome was GitHub issues in the repositories under review, which is a shift from the standard \u201cassessment report\u201d provided by most security assessments in the space. You can view the issues here . To be very clear, we did not engage in this security assessment to get a stamp of approval from the security community. All of the effort put into creating this process and engaging the community was in the service of increasing the level of security and code quality of the Nimbus software.","title":"History"},{"location":"beacon-node-systemd.html","text":"Set up a systemd service This page will take you through how to set up a systemd service for your beacon node. systemd is used in order to have a command or program run when your device boots (i.e. add it as a service). Once this is done, you can start/stop enable/disable from the linux prompt. Note systemd is a service manager designed specifically for Linux - it cannot be used on Windows / Mac. You can get more information about systemd here When installing Nimbus via your package manager, a user and service will already have been created for you and you can skip straight to the configuration section. 1. Create a dedicated user We will start by creating a dedicated user and data directory for Nimbus. The same user can also be used for the execution client. # Create the `nimbus` group sudo groupadd nimbus # Create the `nimbus` user in the `nimbus` group - we will use /var/lib/nimbus as data directory. sudo useradd -g nimbus nimbus -m -d /var/lib/nimbus 2. Create the service file systemd services are created by placing a service file in /etc/systemd/system , or, if Nimbus was installed by a package manager, /usr/lib/systemd/system . A good starting point is the example service file in the Nimbus repository. # Download example service file and save it to `/etc/systemd/system/nimbus_beacon_node.service` curl -s https://raw.githubusercontent.com/status-im/nimbus-eth2/stable/scripts/package_image/usr/lib/systemd/system/nimbus_beacon_node.service | sudo tee /etc/systemd/system/nimbus_beacon_node.service > /dev/null The format of service files is documented in the systemd manual . Tip Automatic restarts increase the risk that the doppelganger detection fails - set RestartPreventExitStatus=1031 to prevent this from happening 3. Configure your service Services are configured either by editing the service file directly or using systemctl edit to create an override. # Edit the systemd file to match your installation sudo vi /etc/systemd/system/nimbus_beacon_node.service # If you installed nimbus via the package manager, use `systemctl edit` instead sudo systemctl edit nimbus_beacon_node.service The service file contains several options for controlling Nimbus. Important options include: Environment=NETWORK : set this to mainnet , prater or ropsten , depending on which network you want to connect to Environment=WEB3_URL : point this to your execution client - see the Execution Client setup guide Environment=REST_ENABLED : REST is used to interact with the beacon node, in particular when setting up a separate Validator Client - see the REST API guide Environment=METRICS_ENABLED : Metrics are used for monitoring the node - see the metrics setup guide ExecStart= : Custom options - see the options guide Note The example assumes Nimbus was installed in /usr/bin/nimbus_beacon_node - if you installed Nimbus elsewhere, make sure to update this path. 4. Notify systemd of the newly added service Every time you add or update a service, the systemd daemon must be notified of the changes: sudo systemctl daemon-reload 4. Start the service # start the beacon node sudo systemctl start nimbus_beacon_node # (Optional) Set the beacon node to start automatically at boot sudo systemctl enable nimbus_beacon_node 5. Check the status of the service systemctl status will show if your beacon node is up and running, or has stopped for some reason. sudo systemctl status nimbus_beacon_node.service You can also follow the logs using the following command: sudo journalctl -uf nimbus_beacon_node.service This will show you the Nimbus logs at the default setting -- it should include regular \"slot start\" messages which will show your sync progress . Press ctrl-c to stop following the logs. To rewind logs - by one day, say - run: sudo journalctl -u nimbus_beacon_node.service --since yesterday Import validator keys When using a service, the beacon node is running as a different user - key import must be performed as this user in order for the key files to have the correct permission: # Run import command as the `nimbus` user sudo -u nimbus /usr/bin/nimbus_beacon_node deposit import --data-dir=/var/lib/nimbus/shared_mainnet_0 /path/to/keys Note Make sure to use the same --data-dir option as is used in the service file! Some guides use --data-dir=/var/lib/nimbus instead. Running multiple beacon nodes You can run multiple beacon nodes on the same machine simply by copying the .service file and adjusting the parameters. When running multiple beacon nodes, make sure that each service: has its own .service file has its own --data-dir has its own --*-port settings Further examples A service template file by Pawel Bylica which allows you to start two services at the same time: e.g. nimbus@prater.service and nimbus@mainnet.service . The EthereumOnARM project maintains a service file as part of their Ethereum installation package repository.","title":"Set up a systemd service"},{"location":"beacon-node-systemd.html#set-up-a-systemd-service","text":"This page will take you through how to set up a systemd service for your beacon node. systemd is used in order to have a command or program run when your device boots (i.e. add it as a service). Once this is done, you can start/stop enable/disable from the linux prompt. Note systemd is a service manager designed specifically for Linux - it cannot be used on Windows / Mac. You can get more information about systemd here When installing Nimbus via your package manager, a user and service will already have been created for you and you can skip straight to the configuration section.","title":"Set up a systemd service"},{"location":"beacon-node-systemd.html#1-create-a-dedicated-user","text":"We will start by creating a dedicated user and data directory for Nimbus. The same user can also be used for the execution client. # Create the `nimbus` group sudo groupadd nimbus # Create the `nimbus` user in the `nimbus` group - we will use /var/lib/nimbus as data directory. sudo useradd -g nimbus nimbus -m -d /var/lib/nimbus","title":"1. Create a dedicated user"},{"location":"beacon-node-systemd.html#2-create-the-service-file","text":"systemd services are created by placing a service file in /etc/systemd/system , or, if Nimbus was installed by a package manager, /usr/lib/systemd/system . A good starting point is the example service file in the Nimbus repository. # Download example service file and save it to `/etc/systemd/system/nimbus_beacon_node.service` curl -s https://raw.githubusercontent.com/status-im/nimbus-eth2/stable/scripts/package_image/usr/lib/systemd/system/nimbus_beacon_node.service | sudo tee /etc/systemd/system/nimbus_beacon_node.service > /dev/null The format of service files is documented in the systemd manual . Tip Automatic restarts increase the risk that the doppelganger detection fails - set RestartPreventExitStatus=1031 to prevent this from happening","title":"2. Create the service file"},{"location":"beacon-node-systemd.html#3-configure-your-service","text":"Services are configured either by editing the service file directly or using systemctl edit to create an override. # Edit the systemd file to match your installation sudo vi /etc/systemd/system/nimbus_beacon_node.service # If you installed nimbus via the package manager, use `systemctl edit` instead sudo systemctl edit nimbus_beacon_node.service The service file contains several options for controlling Nimbus. Important options include: Environment=NETWORK : set this to mainnet , prater or ropsten , depending on which network you want to connect to Environment=WEB3_URL : point this to your execution client - see the Execution Client setup guide Environment=REST_ENABLED : REST is used to interact with the beacon node, in particular when setting up a separate Validator Client - see the REST API guide Environment=METRICS_ENABLED : Metrics are used for monitoring the node - see the metrics setup guide ExecStart= : Custom options - see the options guide Note The example assumes Nimbus was installed in /usr/bin/nimbus_beacon_node - if you installed Nimbus elsewhere, make sure to update this path.","title":"3. Configure your service"},{"location":"beacon-node-systemd.html#4-notify-systemd-of-the-newly-added-service","text":"Every time you add or update a service, the systemd daemon must be notified of the changes: sudo systemctl daemon-reload","title":"4. Notify systemd of the newly added service"},{"location":"beacon-node-systemd.html#4-start-the-service","text":"# start the beacon node sudo systemctl start nimbus_beacon_node # (Optional) Set the beacon node to start automatically at boot sudo systemctl enable nimbus_beacon_node","title":"4. Start the service"},{"location":"beacon-node-systemd.html#5-check-the-status-of-the-service","text":"systemctl status will show if your beacon node is up and running, or has stopped for some reason. sudo systemctl status nimbus_beacon_node.service You can also follow the logs using the following command: sudo journalctl -uf nimbus_beacon_node.service This will show you the Nimbus logs at the default setting -- it should include regular \"slot start\" messages which will show your sync progress . Press ctrl-c to stop following the logs. To rewind logs - by one day, say - run: sudo journalctl -u nimbus_beacon_node.service --since yesterday","title":"5. Check the status of the service"},{"location":"beacon-node-systemd.html#import-validator-keys","text":"When using a service, the beacon node is running as a different user - key import must be performed as this user in order for the key files to have the correct permission: # Run import command as the `nimbus` user sudo -u nimbus /usr/bin/nimbus_beacon_node deposit import --data-dir=/var/lib/nimbus/shared_mainnet_0 /path/to/keys Note Make sure to use the same --data-dir option as is used in the service file! Some guides use --data-dir=/var/lib/nimbus instead.","title":"Import validator keys"},{"location":"beacon-node-systemd.html#running-multiple-beacon-nodes","text":"You can run multiple beacon nodes on the same machine simply by copying the .service file and adjusting the parameters. When running multiple beacon nodes, make sure that each service: has its own .service file has its own --data-dir has its own --*-port settings","title":"Running multiple beacon nodes"},{"location":"beacon-node-systemd.html#further-examples","text":"A service template file by Pawel Bylica which allows you to start two services at the same time: e.g. nimbus@prater.service and nimbus@mainnet.service . The EthereumOnARM project maintains a service file as part of their Ethereum installation package repository.","title":"Further examples"},{"location":"binaries.html","text":"Binaries Binary releases can be downloaded from https://github.com/status-im/nimbus-eth2/releases/latest . We currently have binaries available for Linux AMD64 , ARM and ARM64 , Windows AMD64 and macOS ( AMD64 and ARM64 ). Download The binaries are available at the bottom of the page under Assets . You should see a list that looks like the following: Click on the file that corresponds to your OS and architecture, unpack the archive, read the README and run the binary directly (or through one of our provided wrapper scripts). Installation To install or upgrade a binary release, simply unpack the downloaded archive in a directory of your choice. # Create a directory that can hold the beacon chain data and applications - this should be a fast SSD mkdir -p nimbus-eth2 # Unpack the archive into the `nimbus-eth2` directory you just created tar xvf nimbus-eth2_Linux_amd64_22.6.1_2444e994.tar.gz --strip-components 1 -C nimbus-eth2 After unpacking, you may wish to verify the checksum . Reproducible builds We've designed the build process to be reproducible. In practice, this means that anyone can verify that these exact binaries were produced from the corresponding source code commits. For more about the philosophy and importance of this feature see reproducible-builds.org . For instructions on how to reproduce those binaries, see \"README.md\" inside the archive, as well as the in-depth guide .","title":"Binaries"},{"location":"binaries.html#binaries","text":"Binary releases can be downloaded from https://github.com/status-im/nimbus-eth2/releases/latest . We currently have binaries available for Linux AMD64 , ARM and ARM64 , Windows AMD64 and macOS ( AMD64 and ARM64 ).","title":"Binaries"},{"location":"binaries.html#download","text":"The binaries are available at the bottom of the page under Assets . You should see a list that looks like the following: Click on the file that corresponds to your OS and architecture, unpack the archive, read the README and run the binary directly (or through one of our provided wrapper scripts).","title":"Download"},{"location":"binaries.html#installation","text":"To install or upgrade a binary release, simply unpack the downloaded archive in a directory of your choice. # Create a directory that can hold the beacon chain data and applications - this should be a fast SSD mkdir -p nimbus-eth2 # Unpack the archive into the `nimbus-eth2` directory you just created tar xvf nimbus-eth2_Linux_amd64_22.6.1_2444e994.tar.gz --strip-components 1 -C nimbus-eth2 After unpacking, you may wish to verify the checksum .","title":"Installation"},{"location":"binaries.html#reproducible-builds","text":"We've designed the build process to be reproducible. In practice, this means that anyone can verify that these exact binaries were produced from the corresponding source code commits. For more about the philosophy and importance of this feature see reproducible-builds.org . For instructions on how to reproduce those binaries, see \"README.md\" inside the archive, as well as the in-depth guide .","title":"Reproducible builds"},{"location":"build.html","text":"Build from source Building Nimbus from source ensures that all hardware-specific optimizations are turned on. The build process itself is simple and fully automated, but may take a few minutes. Nim Nimbus is written in the Nim programming language - the correct version will automatically be downloaded as part of the build process! Prerequisites Tip If you are planning to use the precompiled binaries, you can skip this section and go straight to the binaries ! When building from source, you will need additional build dependencies to be installed: Developer tools (C compiler, Make, Bash, Git) CMake Linux macOS Windows Android On common Linux distributions the dependencies can be installed with # Debian and Ubuntu sudo apt-get install build-essential git cmake # Fedora dnf install @development-tools cmake # Archlinux, using an AUR manager yourAURmanager -S base-devel cmake With Homebrew : brew install cmake To build Nimbus on windows, the Mingw-w64 build environment is recommended. Install Mingw-w64 for your architecture using the \" MinGW-W64 Online Installer \": Select your architecture in the setup menu ( i686 on 32-bit, x86_64 on 64-bit) Set threads to win32 Set exceptions to \"dwarf\" on 32-bit and \"seh\" on 64-bit. Change the installation directory to C:\\mingw-w64 and add it to your system PATH in \"My Computer\"/\"This PC\" -> Properties -> Advanced system settings -> Environment Variables -> Path -> Edit -> New -> C:\\mingw-w64\\mingw64\\bin ( C:\\mingw-w64\\mingw32\\bin on 32-bit) Install Git for Windows and use a \"Git Bash\" shell to clone and build nimbus-eth2 . Note: If the online installer isn't working you can try installing Mingw-w64 through MSYS2 . Install the Termux app from FDroid or the Google Play store Install a PRoot of your choice following the instructions for your preferred distribution. Note, the Ubuntu PRoot is known to contain all Nimbus prerequisites compiled on Arm64 architecture (the most common architecture for Android devices). Assuming you use Ubuntu PRoot apt install build-essential git Building the node 1. Clone the nimbus-eth2 repository git clone https://github.com/status-im/nimbus-eth2 cd nimbus-eth2 2. Run the beacon node build process To build the Nimbus beacon node and its dependencies, run: make -j4 nimbus_beacon_node Tip Omit -j4 on systems with 4GB of memory or less.","title":"Build from source"},{"location":"build.html#build-from-source","text":"Building Nimbus from source ensures that all hardware-specific optimizations are turned on. The build process itself is simple and fully automated, but may take a few minutes. Nim Nimbus is written in the Nim programming language - the correct version will automatically be downloaded as part of the build process!","title":"Build from source"},{"location":"build.html#prerequisites","text":"Tip If you are planning to use the precompiled binaries, you can skip this section and go straight to the binaries ! When building from source, you will need additional build dependencies to be installed: Developer tools (C compiler, Make, Bash, Git) CMake Linux macOS Windows Android On common Linux distributions the dependencies can be installed with # Debian and Ubuntu sudo apt-get install build-essential git cmake # Fedora dnf install @development-tools cmake # Archlinux, using an AUR manager yourAURmanager -S base-devel cmake With Homebrew : brew install cmake To build Nimbus on windows, the Mingw-w64 build environment is recommended. Install Mingw-w64 for your architecture using the \" MinGW-W64 Online Installer \": Select your architecture in the setup menu ( i686 on 32-bit, x86_64 on 64-bit) Set threads to win32 Set exceptions to \"dwarf\" on 32-bit and \"seh\" on 64-bit. Change the installation directory to C:\\mingw-w64 and add it to your system PATH in \"My Computer\"/\"This PC\" -> Properties -> Advanced system settings -> Environment Variables -> Path -> Edit -> New -> C:\\mingw-w64\\mingw64\\bin ( C:\\mingw-w64\\mingw32\\bin on 32-bit) Install Git for Windows and use a \"Git Bash\" shell to clone and build nimbus-eth2 . Note: If the online installer isn't working you can try installing Mingw-w64 through MSYS2 . Install the Termux app from FDroid or the Google Play store Install a PRoot of your choice following the instructions for your preferred distribution. Note, the Ubuntu PRoot is known to contain all Nimbus prerequisites compiled on Arm64 architecture (the most common architecture for Android devices). Assuming you use Ubuntu PRoot apt install build-essential git","title":"Prerequisites"},{"location":"build.html#building-the-node","text":"","title":"Building the node"},{"location":"build.html#1-clone-the-nimbus-eth2-repository","text":"git clone https://github.com/status-im/nimbus-eth2 cd nimbus-eth2","title":"1. Clone the nimbus-eth2 repository"},{"location":"build.html#2-run-the-beacon-node-build-process","text":"To build the Nimbus beacon node and its dependencies, run: make -j4 nimbus_beacon_node Tip Omit -j4 on systems with 4GB of memory or less.","title":"2. Run the beacon node build process"},{"location":"checksums.html","text":"Checksums Checksums for each build are included in the release notes . Please make sure you get into the habit of verifying these \ud83d\ude4f For those of you who are unfamiliar, a checksum is a special type of hash used to verify the integrity of a file. Verifying a checksum ensures there was no corruption or manipulation during the download and that the file was downloaded completely and correctly. For a short and simple guide on how to do so, see here . In the case of the v1.1.0 release for example, the SHA512 checksums are: # Linux AMD64 8d553ea5422645b5f06001e7f47051706ae5cffd8d88c45e4669939f3abb6caf41a2477431fce3e647265cdb4f8671fa360d392f423ac68ffb9459607eaab462 nimbus_beacon_node # Linux ARM64 93ffd03a0ce67f7d035e3dc45e97de3c2c9a05a8dd0c6d5f45402ddb04404dc3cf15b80fee972f34152ef171ce97c40f794448bc779ca056081c945f71f19788 nimbus_beacon_node # Linux ARM f2e75f3fae2aea0a9f8d45861d52b0e2546c3990f453b509fab538692d18c64e65f58441c5492064fc371e0bc77de6bab970e05394cfd124417601b55cb4a825 nimbus_beacon_node # Windows AMD64 fd68c8792ea60c2c72e9c2201745f9698bfd1dae4af4fa9e1683f082109045efebd1d80267f13cafeb1cd7414dc0f589a8a73f12161ac2758779369289d5a832 nimbus_beacon_node","title":"Checksums"},{"location":"checksums.html#checksums","text":"Checksums for each build are included in the release notes . Please make sure you get into the habit of verifying these \ud83d\ude4f For those of you who are unfamiliar, a checksum is a special type of hash used to verify the integrity of a file. Verifying a checksum ensures there was no corruption or manipulation during the download and that the file was downloaded completely and correctly. For a short and simple guide on how to do so, see here . In the case of the v1.1.0 release for example, the SHA512 checksums are: # Linux AMD64 8d553ea5422645b5f06001e7f47051706ae5cffd8d88c45e4669939f3abb6caf41a2477431fce3e647265cdb4f8671fa360d392f423ac68ffb9459607eaab462 nimbus_beacon_node # Linux ARM64 93ffd03a0ce67f7d035e3dc45e97de3c2c9a05a8dd0c6d5f45402ddb04404dc3cf15b80fee972f34152ef171ce97c40f794448bc779ca056081c945f71f19788 nimbus_beacon_node # Linux ARM f2e75f3fae2aea0a9f8d45861d52b0e2546c3990f453b509fab538692d18c64e65f58441c5492064fc371e0bc77de6bab970e05394cfd124417601b55cb4a825 nimbus_beacon_node # Windows AMD64 fd68c8792ea60c2c72e9c2201745f9698bfd1dae4af4fa9e1683f082109045efebd1d80267f13cafeb1cd7414dc0f589a8a73f12161ac2758779369289d5a832 nimbus_beacon_node","title":"Checksums"},{"location":"connect-eth2.html","text":"Start validating Once your keys have been imported , it is time to restart the beacon node and start validating! (Re)start the node Press Ctrl-c to stop the beacon node if it's running, then use the same command as before to run it again: Mainnet Prater ./run-mainnet-beacon-node.sh ./run-prater-beacon-node.sh Check the logs Your beacon node will launch and connect your validator to the beacon chain network. To check that keys were imported correctly, look for Local validator attached in the logs: INF 2020-11-18 11:20:00.181+01:00 Launching beacon node ... NOT 2020-11-18 11:20:02.091+01:00 Local validator attached Congratulations! Your node is now ready to perform validator duties. Depending on when the deposit was made, it may take a while before the first attestation is sent - this is normal.","title":"Start validating"},{"location":"connect-eth2.html#start-validating","text":"Once your keys have been imported , it is time to restart the beacon node and start validating!","title":"Start validating"},{"location":"connect-eth2.html#restart-the-node","text":"Press Ctrl-c to stop the beacon node if it's running, then use the same command as before to run it again: Mainnet Prater ./run-mainnet-beacon-node.sh ./run-prater-beacon-node.sh","title":"(Re)start the node"},{"location":"connect-eth2.html#check-the-logs","text":"Your beacon node will launch and connect your validator to the beacon chain network. To check that keys were imported correctly, look for Local validator attached in the logs: INF 2020-11-18 11:20:00.181+01:00 Launching beacon node ... NOT 2020-11-18 11:20:02.091+01:00 Local validator attached Congratulations! Your node is now ready to perform validator duties. Depending on when the deposit was made, it may take a while before the first attestation is sent - this is normal.","title":"Check the logs"},{"location":"contribute.html","text":"Updating this book Follow these steps to contribute to this book! We use Material for MkDocs to produce our documentation. Before You Start Clone the repository by git clone https://github.com/status-im/nimbus-eth2.git . Go to the docs folder and type make to install mkdocs Activate mkdocs: . mkdocs/bin/activate Go to where the Markdown files are located by cd the_nimbus_book/ . Real-Time Update and Preview Changes Run mkdocs serve in the terminal. Preview the book at http://localhost:8000 . Build and Deploy The first step is to submit a pull request to the unstable branch . Then, after it is merged, do the following under our main repository: cd nimbus-eth2 git checkout unstable git pull make update # (This is to update the submodules to the latest version) make publish-book Troubleshooting If you see file conflicts in the pull request, this may due to that you have created your new branch from an old version of the unstable branch. Update your new branch using the following commands: git checkout unstable git pull make update git checkout readme git merge unstable # use something like \"git mergetool\" to resolve conflicts, then read the instructions for completing the merge (usually just a `git commit`) # check the output of \"git diff unstable\" Thank you so much for your help to the decentralized and open source community. :)","title":"Updating this book"},{"location":"contribute.html#updating-this-book","text":"Follow these steps to contribute to this book! We use Material for MkDocs to produce our documentation.","title":"Updating this book"},{"location":"contribute.html#before-you-start","text":"Clone the repository by git clone https://github.com/status-im/nimbus-eth2.git . Go to the docs folder and type make to install mkdocs Activate mkdocs: . mkdocs/bin/activate Go to where the Markdown files are located by cd the_nimbus_book/ .","title":"Before You Start"},{"location":"contribute.html#real-time-update-and-preview-changes","text":"Run mkdocs serve in the terminal. Preview the book at http://localhost:8000 .","title":"Real-Time Update and Preview Changes"},{"location":"contribute.html#build-and-deploy","text":"The first step is to submit a pull request to the unstable branch . Then, after it is merged, do the following under our main repository: cd nimbus-eth2 git checkout unstable git pull make update # (This is to update the submodules to the latest version) make publish-book","title":"Build and Deploy"},{"location":"contribute.html#troubleshooting","text":"If you see file conflicts in the pull request, this may due to that you have created your new branch from an old version of the unstable branch. Update your new branch using the following commands: git checkout unstable git pull make update git checkout readme git merge unstable # use something like \"git mergetool\" to resolve conflicts, then read the instructions for completing the merge (usually just a `git commit`) # check the output of \"git diff unstable\" Thank you so much for your help to the decentralized and open source community. :)","title":"Troubleshooting"},{"location":"data-dir.html","text":"The data directory Nimbus stores all the information it needs to run in a data directory. In this directory, you'll find a database, your validator keys and secrets and several other items. When following the installation guide, the chain data will be stored in build/data with separate directories for each chain (mainnet, prater, etc). The --data-dir option The --data-dir=/path/to/data allows picking a specific data directory to store the chain - make sure you use the same --data-dir option for all beacon node commands! Contents Inside the data directory, you'll find several subdirectories and files containing various information about the node, chain and validators. You can examine the contents of the data directory using the ls -l command: cd nimbus-eth2 ls -l build/data/shared_mainnet_0 -rw-r--r-- 1 nimbus nimbus 234 Jul 19 18 :18 beacon_node.enr drwx------ 1 nimbus nimbus 22 Jul 19 18 :18 db drwx------ 1 nimbus nimbus 196 Jul 19 17 :36 secrets drwx------ 1 nimbus nimbus 250 Jul 19 18 :18 validators db The db folder contains historical chain data and information about the latest observed state of the chain. If you remove the db folder, the beacon node will have to resync. secrets and validators These two folders contain your validator keys as well as the passwords needed to unlock them when starting the beacon node. Warning Be careful not to copy the secrets and validator folders, leaving them in two locations - instead, always move them to the new location! Using the same validators with two nodes poses a significant slashing risk! Moving the data directory You can move the data directory to another location or computer simply by moving its contents and updating the --data-dir option when starting the node. Permissions To protect against key loss, Nimbus requires that files and directories be owned by the user running the application. Furthermore, they should not be readable by others. It may happen that the wrong permissions are applied, particularly when creating the directories manually. The following errors are a sign of this: Data folder has insecure ACL Data directory has insecure permissions File has insecure permissions Here is how to fix them. Linux/ BSD / MacOS Run: # Changing ownership to `user:group` for all files/directories in <data-dir>. chown user:group -R <data-dir> # Set permissions to (rwx------ 0700) for all directories starting from <data-dir> find <data-dir> -type d -exec chmod 700 {} \\; # Set permissions to (rw------- 0600) for all files inside <data-dir>/validators find <data-dir>/validators -type f -exec chmod 0600 {} \\; # Set permissions to (rw------- 0600) for all files inside <data-dir>/secrets find <data-dir>/secrets -type f -exec chmod 0600 {} \\; In sum: Directories <data-dir> , <data-dir>/validators , <data-dir>/secrets MUST be owned by user and have rwx------ or 0700 permissions set. Files stored inside <data-dir> , <data-dir>/validators , /secrets MUST be owned by user and have rw------ or 0600 permission set. Windows From inside Git Bash , run: # Set permissions for all the directories starting from <data-dir> find <data-dir> -type d -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( OI \\)\\( CI \\)\\( F \\) \\; # Set permissions for all the files inside <data-dir>/validators find <data-dir>/validators -type f -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( F \\) \\; # Set permissions for all the files inside <data-dir>/secrets find <data-dir>/secrets -type f -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( F \\) \\; Note Make sure you run the above from inside Git Bash , these commands will not work from inside the standard Windows Command Prompt. If you don't already have a Git Bash shell, you'll need to install Git for Windows . In sum: Directories <data-dir> , <data-dir>/validators , <data-dir>/secrets MUST be owned by user and have permissions set for the user only (OI)(CI)(F). All inherited permissions should be removed. Files which are stored inside , /validators, /secrets MUST be owned by user and have permissions set for the user only (F). All inherited permissions should be removed.","title":"The data directory"},{"location":"data-dir.html#the-data-directory","text":"Nimbus stores all the information it needs to run in a data directory. In this directory, you'll find a database, your validator keys and secrets and several other items. When following the installation guide, the chain data will be stored in build/data with separate directories for each chain (mainnet, prater, etc). The --data-dir option The --data-dir=/path/to/data allows picking a specific data directory to store the chain - make sure you use the same --data-dir option for all beacon node commands!","title":"The data directory"},{"location":"data-dir.html#contents","text":"Inside the data directory, you'll find several subdirectories and files containing various information about the node, chain and validators. You can examine the contents of the data directory using the ls -l command: cd nimbus-eth2 ls -l build/data/shared_mainnet_0 -rw-r--r-- 1 nimbus nimbus 234 Jul 19 18 :18 beacon_node.enr drwx------ 1 nimbus nimbus 22 Jul 19 18 :18 db drwx------ 1 nimbus nimbus 196 Jul 19 17 :36 secrets drwx------ 1 nimbus nimbus 250 Jul 19 18 :18 validators","title":"Contents"},{"location":"data-dir.html#db","text":"The db folder contains historical chain data and information about the latest observed state of the chain. If you remove the db folder, the beacon node will have to resync.","title":"db"},{"location":"data-dir.html#secrets-and-validators","text":"These two folders contain your validator keys as well as the passwords needed to unlock them when starting the beacon node. Warning Be careful not to copy the secrets and validator folders, leaving them in two locations - instead, always move them to the new location! Using the same validators with two nodes poses a significant slashing risk!","title":"secrets and validators"},{"location":"data-dir.html#moving-the-data-directory","text":"You can move the data directory to another location or computer simply by moving its contents and updating the --data-dir option when starting the node.","title":"Moving the data directory"},{"location":"data-dir.html#permissions","text":"To protect against key loss, Nimbus requires that files and directories be owned by the user running the application. Furthermore, they should not be readable by others. It may happen that the wrong permissions are applied, particularly when creating the directories manually. The following errors are a sign of this: Data folder has insecure ACL Data directory has insecure permissions File has insecure permissions Here is how to fix them.","title":"Permissions"},{"location":"data-dir.html#linux-bsd-macos","text":"Run: # Changing ownership to `user:group` for all files/directories in <data-dir>. chown user:group -R <data-dir> # Set permissions to (rwx------ 0700) for all directories starting from <data-dir> find <data-dir> -type d -exec chmod 700 {} \\; # Set permissions to (rw------- 0600) for all files inside <data-dir>/validators find <data-dir>/validators -type f -exec chmod 0600 {} \\; # Set permissions to (rw------- 0600) for all files inside <data-dir>/secrets find <data-dir>/secrets -type f -exec chmod 0600 {} \\; In sum: Directories <data-dir> , <data-dir>/validators , <data-dir>/secrets MUST be owned by user and have rwx------ or 0700 permissions set. Files stored inside <data-dir> , <data-dir>/validators , /secrets MUST be owned by user and have rw------ or 0600 permission set.","title":"Linux/ BSD / MacOS"},{"location":"data-dir.html#windows","text":"From inside Git Bash , run: # Set permissions for all the directories starting from <data-dir> find <data-dir> -type d -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( OI \\)\\( CI \\)\\( F \\) \\; # Set permissions for all the files inside <data-dir>/validators find <data-dir>/validators -type f -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( F \\) \\; # Set permissions for all the files inside <data-dir>/secrets find <data-dir>/secrets -type f -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( F \\) \\; Note Make sure you run the above from inside Git Bash , these commands will not work from inside the standard Windows Command Prompt. If you don't already have a Git Bash shell, you'll need to install Git for Windows . In sum: Directories <data-dir> , <data-dir>/validators , <data-dir>/secrets MUST be owned by user and have permissions set for the user only (OI)(CI)(F). All inherited permissions should be removed. Files which are stored inside , /validators, /secrets MUST be owned by user and have permissions set for the user only (F). All inherited permissions should be removed.","title":"Windows"},{"location":"database-backup.html","text":"Back up your database The best way to do this is to simply copy it over: you'll find it either in build/data/shared_mainnet_0/db/ (if you're running Prater, shared_prater_0 ) or the directory you supplied to the --data-dir argument when you launched Nimbus).","title":"Back up your database"},{"location":"database-backup.html#back-up-your-database","text":"The best way to do this is to simply copy it over: you'll find it either in build/data/shared_mainnet_0/db/ (if you're running Prater, shared_prater_0 ) or the directory you supplied to the --data-dir argument when you launched Nimbus).","title":"Back up your database"},{"location":"deposit.html","text":"Make a deposit for your validator To make a deposit, you will need to generate keys then submit a deposit transaction to the execution chain. Tip The process of setting up a validator is also documented at the Ethereum launchpad site: Mainnet Prater Tip Use Prater to stress test / future proof your set up against peak mainnet load. See here for all you need to know Download the deposit tool Start by downloading and unpacking the deposit tool provided by the Ethereum Foundation: # Enter the nimbus folder we previously created cd nimbus-eth2 # Make sure to get the latest version from the download page wget https://github.com/ethereum/staking-deposit-cli/releases/download/v2.2.0/staking_deposit-cli-9ab0b05-linux-amd64.tar.gz # Unpack the archive tar xvf staking_deposit-cli-9ab0b05-linux-amd64.tar.gz --strip-components 2 Generate keys Tip You can increase the security of this process by downloading a Live linux image . To do so, copy deposit to a USB stick, boot into the live image, and run the tool from inside the image. Make sure you don't enable Wifi and unplug any Ethernet cables when using this process. The deposit tool generates a seed phrase, and uses this to create validator and withdrawal keys. Danger If you lose you seed phrase and your withdrawal key, your funds will be lost forever! Mainnet Prater # Run the deposit tool and follow the instructions on screen ./deposit new-mnemonic --chain mainnet # Run the deposit tool and follow the instructions on screen ./deposit new-mnemonic --chain prater Make the deposit Once created, the keys are used to create a deposit transaction on the Ethereum execution chain. Follow the instructions at https://launchpad.ethereum.org/en/upload-deposit-data to upload the deposit data. Warning If you are making a mainnet deposit make sure you verify that the deposit contract you are interacting with is the correct one. You should verify that the address is indeed: 0x00000000219ab540356cBB839Cbe05303d7705Fa . With the keys created, you're ready to perform the key import .","title":"Make a deposit for your validator"},{"location":"deposit.html#make-a-deposit-for-your-validator","text":"To make a deposit, you will need to generate keys then submit a deposit transaction to the execution chain. Tip The process of setting up a validator is also documented at the Ethereum launchpad site: Mainnet Prater Tip Use Prater to stress test / future proof your set up against peak mainnet load. See here for all you need to know","title":"Make a deposit for your validator"},{"location":"deposit.html#download-the-deposit-tool","text":"Start by downloading and unpacking the deposit tool provided by the Ethereum Foundation: # Enter the nimbus folder we previously created cd nimbus-eth2 # Make sure to get the latest version from the download page wget https://github.com/ethereum/staking-deposit-cli/releases/download/v2.2.0/staking_deposit-cli-9ab0b05-linux-amd64.tar.gz # Unpack the archive tar xvf staking_deposit-cli-9ab0b05-linux-amd64.tar.gz --strip-components 2","title":"Download the deposit tool"},{"location":"deposit.html#generate-keys","text":"Tip You can increase the security of this process by downloading a Live linux image . To do so, copy deposit to a USB stick, boot into the live image, and run the tool from inside the image. Make sure you don't enable Wifi and unplug any Ethernet cables when using this process. The deposit tool generates a seed phrase, and uses this to create validator and withdrawal keys. Danger If you lose you seed phrase and your withdrawal key, your funds will be lost forever! Mainnet Prater # Run the deposit tool and follow the instructions on screen ./deposit new-mnemonic --chain mainnet # Run the deposit tool and follow the instructions on screen ./deposit new-mnemonic --chain prater","title":"Generate keys"},{"location":"deposit.html#make-the-deposit","text":"Once created, the keys are used to create a deposit transaction on the Ethereum execution chain. Follow the instructions at https://launchpad.ethereum.org/en/upload-deposit-data to upload the deposit data. Warning If you are making a mainnet deposit make sure you verify that the deposit contract you are interacting with is the correct one. You should verify that the address is indeed: 0x00000000219ab540356cBB839Cbe05303d7705Fa . With the keys created, you're ready to perform the key import .","title":"Make the deposit"},{"location":"developers.html","text":"For Developers This page contains tips and tricks for developers, further resources, along with information on how to set up your build environment on your platform. Before building Nimbus for the first time, make sure to install the prerequisites . Code style The code follows the Status Nim Style Guide . Branch lifecycle The git repository has 3 main branches, stable , testing and unstable as well as feature and bugfix branches. Unstable The unstable branch contains features and bugfixes that are actively being tested and worked on. Features and bugfixes are generally pushed to individual branches, each with their own pull request against the unstable branch. Once the branch has been reviewed and passed CI, the developer or reviewer merges the branch to unstable . The unstable branch is regularly deployed to the Nimbus Prater fleet where additional testing happens. Testing The testing branch contains features and bugfixes that have gone through CI and initial testing on the unstable branch and are ready to be included in the next release. After testing a bugfix or feature on unstable , the features and fixes that are planned for the next release get merged to the testing branch either by the release manager or team members. The testing branch is regularly deployed to the Nimbus prater fleet as well as a smaller mainnet fleet. The branch should remain release-ready at most times. Stable The stable branch tracks the latest released version of Nimbus and is suitable for mainnet staking. Build system Windows mingw32-make # this first invocation will update the Git submodules You can now follow the instructions in this this book by replacing make with mingw32-make (you should run mingw32 regardless of whether you're running 32-bit or 64-bit architecture): mingw32-make test # run the test suite Linux, macOS After cloning the repo: # Build nimbus_beacon_node and all the tools, using 4 parallel Make jobs make -j4 # Run tests make test # Update to latest version git pull make update Environment Nimbus comes with a build environment similar to Python venv - this helps ensure that the correct version of Nim is used and that all dependencies can be found. ./env.sh bash # start a new interactive shell with the right env vars set which nim nim --version # Nimbus is tested and supported on 1.2.12 at the moment # or without starting a new interactive shell: ./env.sh which nim ./env.sh nim --version # Start Visual Studio code with environment ./env.sh code Makefile tips and tricks for developers build all those tools known to the Makefile: # $(nproc) corresponds to the number of cores you have make -j $( nproc ) build a specific tool: make state_sim you can control the Makefile's verbosity with the V variable (defaults to 0): make V = 1 # verbose make V = 2 test # even more verbose same for the Chronicles log level : make LOG_LEVEL = DEBUG bench_bls_sig_agggregation # this is the default make LOG_LEVEL = TRACE nimbus_beacon_node # log everything pass arbitrary parameters to the Nim compiler: make NIMFLAGS = \"-d:release\" you can freely combine those variables on the make command line: make -j $( nproc ) NIMFLAGS = \"-d:release\" USE_MULTITAIL = yes eth2_network_simulation don't use the lightweight stack tracing implementation from nim-libbacktrace : make USE_LIBBACKTRACE = 0 # expect the resulting binaries to be 2-3 times slower disable -march=native because you want to run the binary on a different machine than the one you're building it on: make NIMFLAGS = \"-d:disableMarchNative\" nimbus_beacon_node disable link-time optimisation (LTO): make NIMFLAGS = \"-d:disableLTO\" nimbus_beacon_node show C compiler warnings: make NIMFLAGS = \"-d:cwarnings\" nimbus_beacon_node limit stack usage to 1 MiB per C function (static analysis - see the GCC docs ; if LTO is enabled, it works without -d:cwarnings ): make NIMFLAGS = \"-d:limitStackUsage\" nimbus_beacon_node build a static binary: make NIMFLAGS = \"--passL:-static\" nimbus_beacon_node publish a book using mdBook from sources in \"docs/\" to GitHub pages: make publish-book create a binary distribution: make dist Multi-client interop scripts This repository contains a set of scripts used by the client implementation teams to test interop between the clients (in certain simplified scenarios). It mostly helps us find and debug issues. Stress-testing the client by limiting the CPU power make prater CPU_LIMIT = 20 The limiting is provided by the cpulimit utility, available on Linux and macOS. The specified value is a percentage of a single CPU core. Usually 1 - 100, but can be higher on multi-core CPUs. Build and run the local beacon chain simulation The beacon chain simulation runs several beacon nodes on the local machine, attaches several local validators to each, and builds a beacon chain between them. To run the simulation: make update make eth2_network_simulation To clean the previous run's data: make clean_eth2_network_simulation_all To change the number of validators and nodes: # Clear data files from your last run and start the simulation with a new genesis block: make VALIDATORS = 192 NODES = 6 USER_NODES = 1 eth2_network_simulation If you\u2019d like to see the nodes running on separated sub-terminals inside one big window, install Multitail (if you're on a Mac, follow the instructions here ), then: USE_MULTITAIL=\"yes\" make eth2_network_simulation You\u2019ll get something like this (click for full size): You can find out more about the beacon node simulation here . Build and run the local state transition simulation This simulation is primarily designed for researchers, but we'll cover it briefly here in case you're curious :) The state transition simulation quickly runs the beacon chain state transition function in isolation and outputs JSON snapshots of the state (directly to the nimbus-eth2 directory). It runs without networking and blocks are processed without slot time delays. # build the state simulator, then display its help (\"-d:release\" speeds it # up substantially, allowing the simulation of longer runs in reasonable time) make NIMFLAGS = \"-d:release\" state_sim build/state_sim --help Use the output of the help command to pass desired values to the simulator - experiment with changing the number of slots, validators, , etc. to get different results. The most important options are: slots : the number of slots to run the simulation for (default 192) validators : the number of validators (default 6400) attesterRatio : the expected fraction of attesters that actually do their work for every slot (default 0.73) json_interval : how often JSON snapshots of the state are outputted (default every 32 slots -- or once per epoch) For example, to run the state simulator for 384 slots, with 20,000 validators, and an average of 66% of attesters doing their work every slot, while outputting snapshots of the state twice per epoch, run: build/state_sim --slots=384 --validators=20000 --attesterRatio=0.66 --json_interval=16","title":"For Developers"},{"location":"developers.html#for-developers","text":"This page contains tips and tricks for developers, further resources, along with information on how to set up your build environment on your platform. Before building Nimbus for the first time, make sure to install the prerequisites .","title":"For Developers"},{"location":"developers.html#code-style","text":"The code follows the Status Nim Style Guide .","title":"Code style"},{"location":"developers.html#branch-lifecycle","text":"The git repository has 3 main branches, stable , testing and unstable as well as feature and bugfix branches.","title":"Branch lifecycle"},{"location":"developers.html#unstable","text":"The unstable branch contains features and bugfixes that are actively being tested and worked on. Features and bugfixes are generally pushed to individual branches, each with their own pull request against the unstable branch. Once the branch has been reviewed and passed CI, the developer or reviewer merges the branch to unstable . The unstable branch is regularly deployed to the Nimbus Prater fleet where additional testing happens.","title":"Unstable"},{"location":"developers.html#testing","text":"The testing branch contains features and bugfixes that have gone through CI and initial testing on the unstable branch and are ready to be included in the next release. After testing a bugfix or feature on unstable , the features and fixes that are planned for the next release get merged to the testing branch either by the release manager or team members. The testing branch is regularly deployed to the Nimbus prater fleet as well as a smaller mainnet fleet. The branch should remain release-ready at most times.","title":"Testing"},{"location":"developers.html#stable","text":"The stable branch tracks the latest released version of Nimbus and is suitable for mainnet staking.","title":"Stable"},{"location":"developers.html#build-system","text":"","title":"Build system"},{"location":"developers.html#windows","text":"mingw32-make # this first invocation will update the Git submodules You can now follow the instructions in this this book by replacing make with mingw32-make (you should run mingw32 regardless of whether you're running 32-bit or 64-bit architecture): mingw32-make test # run the test suite","title":"Windows"},{"location":"developers.html#linux-macos","text":"After cloning the repo: # Build nimbus_beacon_node and all the tools, using 4 parallel Make jobs make -j4 # Run tests make test # Update to latest version git pull make update","title":"Linux, macOS"},{"location":"developers.html#environment","text":"Nimbus comes with a build environment similar to Python venv - this helps ensure that the correct version of Nim is used and that all dependencies can be found. ./env.sh bash # start a new interactive shell with the right env vars set which nim nim --version # Nimbus is tested and supported on 1.2.12 at the moment # or without starting a new interactive shell: ./env.sh which nim ./env.sh nim --version # Start Visual Studio code with environment ./env.sh code","title":"Environment"},{"location":"developers.html#makefile-tips-and-tricks-for-developers","text":"build all those tools known to the Makefile: # $(nproc) corresponds to the number of cores you have make -j $( nproc ) build a specific tool: make state_sim you can control the Makefile's verbosity with the V variable (defaults to 0): make V = 1 # verbose make V = 2 test # even more verbose same for the Chronicles log level : make LOG_LEVEL = DEBUG bench_bls_sig_agggregation # this is the default make LOG_LEVEL = TRACE nimbus_beacon_node # log everything pass arbitrary parameters to the Nim compiler: make NIMFLAGS = \"-d:release\" you can freely combine those variables on the make command line: make -j $( nproc ) NIMFLAGS = \"-d:release\" USE_MULTITAIL = yes eth2_network_simulation don't use the lightweight stack tracing implementation from nim-libbacktrace : make USE_LIBBACKTRACE = 0 # expect the resulting binaries to be 2-3 times slower disable -march=native because you want to run the binary on a different machine than the one you're building it on: make NIMFLAGS = \"-d:disableMarchNative\" nimbus_beacon_node disable link-time optimisation (LTO): make NIMFLAGS = \"-d:disableLTO\" nimbus_beacon_node show C compiler warnings: make NIMFLAGS = \"-d:cwarnings\" nimbus_beacon_node limit stack usage to 1 MiB per C function (static analysis - see the GCC docs ; if LTO is enabled, it works without -d:cwarnings ): make NIMFLAGS = \"-d:limitStackUsage\" nimbus_beacon_node build a static binary: make NIMFLAGS = \"--passL:-static\" nimbus_beacon_node publish a book using mdBook from sources in \"docs/\" to GitHub pages: make publish-book create a binary distribution: make dist","title":"Makefile tips and tricks for developers"},{"location":"developers.html#multi-client-interop-scripts","text":"This repository contains a set of scripts used by the client implementation teams to test interop between the clients (in certain simplified scenarios). It mostly helps us find and debug issues.","title":"Multi-client interop scripts"},{"location":"developers.html#stress-testing-the-client-by-limiting-the-cpu-power","text":"make prater CPU_LIMIT = 20 The limiting is provided by the cpulimit utility, available on Linux and macOS. The specified value is a percentage of a single CPU core. Usually 1 - 100, but can be higher on multi-core CPUs.","title":"Stress-testing the client by limiting the CPU power"},{"location":"developers.html#build-and-run-the-local-beacon-chain-simulation","text":"The beacon chain simulation runs several beacon nodes on the local machine, attaches several local validators to each, and builds a beacon chain between them. To run the simulation: make update make eth2_network_simulation To clean the previous run's data: make clean_eth2_network_simulation_all To change the number of validators and nodes: # Clear data files from your last run and start the simulation with a new genesis block: make VALIDATORS = 192 NODES = 6 USER_NODES = 1 eth2_network_simulation If you\u2019d like to see the nodes running on separated sub-terminals inside one big window, install Multitail (if you're on a Mac, follow the instructions here ), then: USE_MULTITAIL=\"yes\" make eth2_network_simulation You\u2019ll get something like this (click for full size): You can find out more about the beacon node simulation here .","title":"Build and run the local beacon chain simulation"},{"location":"developers.html#build-and-run-the-local-state-transition-simulation","text":"This simulation is primarily designed for researchers, but we'll cover it briefly here in case you're curious :) The state transition simulation quickly runs the beacon chain state transition function in isolation and outputs JSON snapshots of the state (directly to the nimbus-eth2 directory). It runs without networking and blocks are processed without slot time delays. # build the state simulator, then display its help (\"-d:release\" speeds it # up substantially, allowing the simulation of longer runs in reasonable time) make NIMFLAGS = \"-d:release\" state_sim build/state_sim --help Use the output of the help command to pass desired values to the simulator - experiment with changing the number of slots, validators, , etc. to get different results. The most important options are: slots : the number of slots to run the simulation for (default 192) validators : the number of validators (default 6400) attesterRatio : the expected fraction of attesters that actually do their work for every slot (default 0.73) json_interval : how often JSON snapshots of the state are outputted (default every 32 slots -- or once per epoch) For example, to run the state simulator for 384 slots, with 20,000 validators, and an average of 66% of attesters doing their work every slot, while outputting snapshots of the state twice per epoch, run: build/state_sim --slots=384 --validators=20000 --attesterRatio=0.66 --json_interval=16","title":"Build and run the local state transition simulation"},{"location":"distribution_internals.html","text":"Binary distribution internals Reproducibility The binaries we build in GitHub Actions and distribute in our releases come from an intricate process meant to ensure reproducibility . While the ability to produce the same exact binaries from the corresponding Git commits is a good idea for any open source project, it is a requirement for software that deals with digital tokens of significant value. Docker containers for internal use The easiest way to guarantee that users are able to replicate our binaries for themselves is to give them the same software environment we used in CI. Docker containers fit the bill, so everything starts with the architecture- and OS-specific containers in docker/dist/base_image/ . These images contain all the packages we need, are built and published once (to Docker Hub), and are then reused as the basis for temporary Docker images where the nimbus-eth2 build is carried out. These temporary images are controlled by Dockerfiles in docker/dist/ . Since we're not publishing them anywhere, we can customize them to the system they run on (we ensure they use the host's UID/GID, the host's QEMU static binaries, etc); they get access to the source code through the use of external volumes. Build process It all starts from the GitHub actions in .github/workflows/release.yml . There is a different job for each supported OS-architecture combination and they all run in parallel (ideally). Once all those CI jobs complete successfully, a GitHub release draft is created and all the distributable archives are uploaded to it. A list of checksums for the main binaries is inserted in the release description. That draft needs to be manually published. The build itself is triggered by a Make target. E.g.: make dist-amd64 . This invokes scripts/make_dist.sh which builds the corresponding Docker container from docker/dist/ and runs it with the Git repository's top directory as an external volume. The entry point for that container is docker/dist/entry_point.sh and that's where you'll find the Make invocations needed to finally build the software and create distributable tarballs. Docker images for end users Configured in .github/workflows/release.yml (only for Linux AMD64, ARM and ARM64): we unpack the distribution tarball and copy its content into a third type of Docker image - meant for end users and defined by docker/dist/binaries/Dockerfile.amd64 (and related). We then publish that to Docker Hub .","title":"Binary distribution internals"},{"location":"distribution_internals.html#binary-distribution-internals","text":"","title":"Binary distribution internals"},{"location":"distribution_internals.html#reproducibility","text":"The binaries we build in GitHub Actions and distribute in our releases come from an intricate process meant to ensure reproducibility . While the ability to produce the same exact binaries from the corresponding Git commits is a good idea for any open source project, it is a requirement for software that deals with digital tokens of significant value.","title":"Reproducibility"},{"location":"distribution_internals.html#docker-containers-for-internal-use","text":"The easiest way to guarantee that users are able to replicate our binaries for themselves is to give them the same software environment we used in CI. Docker containers fit the bill, so everything starts with the architecture- and OS-specific containers in docker/dist/base_image/ . These images contain all the packages we need, are built and published once (to Docker Hub), and are then reused as the basis for temporary Docker images where the nimbus-eth2 build is carried out. These temporary images are controlled by Dockerfiles in docker/dist/ . Since we're not publishing them anywhere, we can customize them to the system they run on (we ensure they use the host's UID/GID, the host's QEMU static binaries, etc); they get access to the source code through the use of external volumes.","title":"Docker containers for internal use"},{"location":"distribution_internals.html#build-process","text":"It all starts from the GitHub actions in .github/workflows/release.yml . There is a different job for each supported OS-architecture combination and they all run in parallel (ideally). Once all those CI jobs complete successfully, a GitHub release draft is created and all the distributable archives are uploaded to it. A list of checksums for the main binaries is inserted in the release description. That draft needs to be manually published. The build itself is triggered by a Make target. E.g.: make dist-amd64 . This invokes scripts/make_dist.sh which builds the corresponding Docker container from docker/dist/ and runs it with the Git repository's top directory as an external volume. The entry point for that container is docker/dist/entry_point.sh and that's where you'll find the Make invocations needed to finally build the software and create distributable tarballs.","title":"Build process"},{"location":"distribution_internals.html#docker-images-for-end-users","text":"Configured in .github/workflows/release.yml (only for Linux AMD64, ARM and ARM64): we unpack the distribution tarball and copy its content into a third type of Docker image - meant for end users and defined by docker/dist/binaries/Dockerfile.amd64 (and related). We then publish that to Docker Hub .","title":"Docker images for end users"},{"location":"docker.html","text":"Docker images Docker images are available from Docker Hub . We have version-specific Docker tags ( statusim/nimbus-eth2:amd64-v1.2.3 ) and a tag for the latest image ( statusim/nimbus-eth2:amd64-latest ). These images are simply the contents of release tarballs inside a debian:bullseye-slim image, running under a user imaginatively named user , with UID:GID of 1000:1000. The unpacked archive is in /home/user/nimbus-eth2 which is also the default WORKDIR . The default ENTRYPOINT is the binary itself: /home/user/nimbus-eth2/build/nimbus_beacon_node Usage Before running Nimbus via docker, you need to prepare a data directory and mount it in docker. It is recommended that you mount the directory at /home/user/nimbus-eth2/build/data and pass --data-dir=build/data/shared_mainnet_0 to all nimbus_becaon_node commands. The wrapper script outlined below will set the data directory automatically. mkdir data docker run -it --rm \\ -v ${ PWD } /data:/home/user/nimbus-eth2/build/data \\ statusim/nimbus-eth2:amd64-latest \\ --data-dir = build/data/shared_mainnet_0 --network = mainnet [ other options ] Wrapper script If you wish, you can choose to use a wrapper script instead: mkdir data docker run -it --rm \\ -v ${ PWD } /data:/home/user/nimbus-eth2/build/data \\ --entrypoint /home/user/nimbus-eth2/run-mainnet-beacon-node.sh \\ statusim/nimbus-eth2:amd64-latest [ other options ] Docker compose Our preferred setup is using docker-compose . You can use one of our example configuration files as a base for your own custom configuration: mkdir data docker-compose -f docker-compose-example1.yml up --quiet-pull --no-color --detach Note The rather voluminous logging is done on stdout , so you might want to change the system-wide Docker logging defaults (which dumps everything in /var/lib/docker/containers/CONTAINER_ID/CONTAINER_ID-json.log ) to something like syslog . We recommend using a log rotation system with appropriate intervals for logs of this size.","title":"Docker images"},{"location":"docker.html#docker-images","text":"Docker images are available from Docker Hub . We have version-specific Docker tags ( statusim/nimbus-eth2:amd64-v1.2.3 ) and a tag for the latest image ( statusim/nimbus-eth2:amd64-latest ). These images are simply the contents of release tarballs inside a debian:bullseye-slim image, running under a user imaginatively named user , with UID:GID of 1000:1000. The unpacked archive is in /home/user/nimbus-eth2 which is also the default WORKDIR . The default ENTRYPOINT is the binary itself: /home/user/nimbus-eth2/build/nimbus_beacon_node","title":"Docker images"},{"location":"docker.html#usage","text":"Before running Nimbus via docker, you need to prepare a data directory and mount it in docker. It is recommended that you mount the directory at /home/user/nimbus-eth2/build/data and pass --data-dir=build/data/shared_mainnet_0 to all nimbus_becaon_node commands. The wrapper script outlined below will set the data directory automatically. mkdir data docker run -it --rm \\ -v ${ PWD } /data:/home/user/nimbus-eth2/build/data \\ statusim/nimbus-eth2:amd64-latest \\ --data-dir = build/data/shared_mainnet_0 --network = mainnet [ other options ]","title":"Usage"},{"location":"docker.html#wrapper-script","text":"If you wish, you can choose to use a wrapper script instead: mkdir data docker run -it --rm \\ -v ${ PWD } /data:/home/user/nimbus-eth2/build/data \\ --entrypoint /home/user/nimbus-eth2/run-mainnet-beacon-node.sh \\ statusim/nimbus-eth2:amd64-latest [ other options ]","title":"Wrapper script"},{"location":"docker.html#docker-compose","text":"Our preferred setup is using docker-compose . You can use one of our example configuration files as a base for your own custom configuration: mkdir data docker-compose -f docker-compose-example1.yml up --quiet-pull --no-color --detach Note The rather voluminous logging is done on stdout , so you might want to change the system-wide Docker logging defaults (which dumps everything in /var/lib/docker/containers/CONTAINER_ID/CONTAINER_ID-json.log ) to something like syslog . We recommend using a log rotation system with appropriate intervals for logs of this size.","title":"Docker compose"},{"location":"email-notifications.html","text":"Email notifications You can create an account on beaconcha.in to set up email notifications in case your validator loses balance (goes offline), or gets slashed. Tip: If your validator loses balance for two epochs in a row, you may want to investigate. It's a strong signal that it may be offline. 1. Sign up at beaconcha.in/register 2. Type your validator's public key into the searchbar 3. Click on the bookmark icon 4. Tick the boxes and select Add To Watchlist","title":"Email notifications"},{"location":"email-notifications.html#email-notifications","text":"You can create an account on beaconcha.in to set up email notifications in case your validator loses balance (goes offline), or gets slashed. Tip: If your validator loses balance for two epochs in a row, you may want to investigate. It's a strong signal that it may be offline.","title":"Email notifications"},{"location":"email-notifications.html#1-sign-up-at-beaconchainregister","text":"","title":"1. Sign up at beaconcha.in/register"},{"location":"email-notifications.html#2-type-your-validators-public-key-into-the-searchbar","text":"","title":"2. Type your validator's public key into the searchbar"},{"location":"email-notifications.html#3-click-on-the-bookmark-icon","text":"","title":"3. Click on the bookmark icon"},{"location":"email-notifications.html#4-tick-the-boxes-and-select-add-to-watchlist","text":"","title":"4. Tick the boxes and select Add To Watchlist"},{"location":"eth1.html","text":"Run an execution client In order to be able to produce blocks and process incoming validator deposits, you'll need to run an execution client in together with the beacon node. Nimbus has been tested all major execution clients - see the execution client comparison for more information. The --web3-url option informs the beacon node how to connect to the execution client - both http:// and ws:// URL:s are supported. You can pass one or more --web3-url parameters to the node. Any additional web3 url:s will be used for backup, should the first client become unavailable: ./run-mainnet-beacon-node.sh \\ --web3-url = ws://127.0.0.1:8546 \\ --web3-url = http://other:8545 Warn You need to run your own execution client after the merge - relying on third-party services such as Infura, Alchemy and Pocket will not be possible. Info Syncing an execution client may take hours or even days, depending on your hardware! Nimbus Geth Nethermind Besu Erigon In parallel to nimbus-eth2 , we are working hard on the Nimbus execution client . While this is very much a project in development (i.e. not yet ready for public consumption), we welcome you to experiment with it. 1. Install Geth See the Installing Geth for instructions on installing Geth. 2. Start Geth Once you have geth installed, make sure to enable the JSON-RPC WebSocket interface when running geth: Mainnet Goerli geth --ws geth --goerli --ws Note The --ws flag is needed to enable the websocket RPC API. This allows Nimbus to query the eth1 chain using Web3 API calls. 3. Leave Geth running Let it sync - Geth uses snap sync by default. It may take anywhere between a few hours and a couple of days. Note It is safe to run Nimbus and start validating even if Geth hasn't fully synced yet You'll know Geth has finished syncing, when you start seeing logs that look like the following: INFO [05-29|01:16:05] Imported new chain segment blocks=1 txs=3 mgas=0.065 elapsed=5.885ms mgasps=11.038 number=3785445 hash=553d9e\u2026fc4547 INFO [05-29|01:16:10] Imported new chain segment blocks=1 txs=0 mgas=0.000 elapsed=5.447ms mgasps=0.000 number=3785446 hash=5e3e7d\u2026bd4afd INFO [05-29|01:16:10] Imported new chain segment blocks=1 txs=1 mgas=0.021 elapsed=7.382ms mgasps=2.845 number=3785447 hash=39986c\u2026dd2a01 INFO [05-29|01:16:14] Imported new chain segment blocks=1 txs=11 mgas=1.135 elapsed=22.281ms mgasps=50.943 number=3785444 hash=277bb9\u2026623d8c Geth accepts connections from the loopback interface ( 127.0.0.1 ), with default WebSocket port 8546 . This means that your default Web3 provider URL should be: ws://127.0.0.1:8546 See the Getting started guide to set up Nethermind. Make sure to enable the JSON-RPC interface over WebSockets. See the Besu documentation for instructions on setting up Besu. Make sure to enable the JSON-RPC WebSocket interface. See the Erigon README for instructions on setting up Erigon. Make sure to enable the JSON-RPC WebSocket interface.","title":"Run an execution client"},{"location":"eth1.html#run-an-execution-client","text":"In order to be able to produce blocks and process incoming validator deposits, you'll need to run an execution client in together with the beacon node. Nimbus has been tested all major execution clients - see the execution client comparison for more information. The --web3-url option informs the beacon node how to connect to the execution client - both http:// and ws:// URL:s are supported. You can pass one or more --web3-url parameters to the node. Any additional web3 url:s will be used for backup, should the first client become unavailable: ./run-mainnet-beacon-node.sh \\ --web3-url = ws://127.0.0.1:8546 \\ --web3-url = http://other:8545 Warn You need to run your own execution client after the merge - relying on third-party services such as Infura, Alchemy and Pocket will not be possible. Info Syncing an execution client may take hours or even days, depending on your hardware! Nimbus Geth Nethermind Besu Erigon In parallel to nimbus-eth2 , we are working hard on the Nimbus execution client . While this is very much a project in development (i.e. not yet ready for public consumption), we welcome you to experiment with it.","title":"Run an execution client"},{"location":"eth1.html#1-install-geth","text":"See the Installing Geth for instructions on installing Geth.","title":"1. Install Geth"},{"location":"eth1.html#2-start-geth","text":"Once you have geth installed, make sure to enable the JSON-RPC WebSocket interface when running geth: Mainnet Goerli geth --ws geth --goerli --ws Note The --ws flag is needed to enable the websocket RPC API. This allows Nimbus to query the eth1 chain using Web3 API calls.","title":"2. Start Geth"},{"location":"eth1.html#3-leave-geth-running","text":"Let it sync - Geth uses snap sync by default. It may take anywhere between a few hours and a couple of days. Note It is safe to run Nimbus and start validating even if Geth hasn't fully synced yet You'll know Geth has finished syncing, when you start seeing logs that look like the following: INFO [05-29|01:16:05] Imported new chain segment blocks=1 txs=3 mgas=0.065 elapsed=5.885ms mgasps=11.038 number=3785445 hash=553d9e\u2026fc4547 INFO [05-29|01:16:10] Imported new chain segment blocks=1 txs=0 mgas=0.000 elapsed=5.447ms mgasps=0.000 number=3785446 hash=5e3e7d\u2026bd4afd INFO [05-29|01:16:10] Imported new chain segment blocks=1 txs=1 mgas=0.021 elapsed=7.382ms mgasps=2.845 number=3785447 hash=39986c\u2026dd2a01 INFO [05-29|01:16:14] Imported new chain segment blocks=1 txs=11 mgas=1.135 elapsed=22.281ms mgasps=50.943 number=3785444 hash=277bb9\u2026623d8c Geth accepts connections from the loopback interface ( 127.0.0.1 ), with default WebSocket port 8546 . This means that your default Web3 provider URL should be: ws://127.0.0.1:8546 See the Getting started guide to set up Nethermind. Make sure to enable the JSON-RPC interface over WebSockets. See the Besu documentation for instructions on setting up Besu. Make sure to enable the JSON-RPC WebSocket interface. See the Erigon README for instructions on setting up Erigon. Make sure to enable the JSON-RPC WebSocket interface.","title":"3. Leave Geth running"},{"location":"faq.html","text":"Frequently Asked Questions General Which version of Nimbus am I running? You can check the version through a number of methods: # Run the beacon node with the --version flag: build/nimbus_beacon_node --version # Query the metrics server - requires running with the '--metrics' option curl -s http://localhost:8008/metrics | grep version # Query the REST API - requires running with the '--rest' option curl -s http://localhost:9100/eth/v1/node/version Why are metrics not working? The metrics server is disabled by default: enable it by passing --metrics to the run command: build/nimbus_beacon_node --metrics ... Why is the REST server not working? The REST server is disabled by default: enable it by passing --rest to the run command: build/nimbus_beacon_node --rest ... Why does my validator miss two epochs of attestations after restarting? When a validator is started (or restarted) it prudently listens for 2 epochs for attestations from a validator with the same index (a doppelganger), before sending an attestation itself. In sum, it's a simple way of handling the case where one validator comes online with the same key as another validator that's already online (i.e one device was started without switching the other off). While this strategy requires the client to wait two whole epochs on restart before attesting, a couple of missed attestations is a very minor price to pay in exchange for significantly reducing the risk of an accidental slashing. You can think of it as a small penalty that you pay only on first launch and restarts. When you take into account the total runtime of your validator, the impact should be minimal. While we strongly recommend it, you can disable it with an explicit flag ( --doppelganger-detection=false ) if you don't plan on moving your setup. What's the best way to stress test my execution + consensus setup before committing with real ETH? We recommend running a Nimbus beacon node on Prater and a mainnet execution client on the same machine - this will simulate the load of running a mainnet validator. To stress test it, add --subscribe-all-subnets to the beacon node options . This simulates the maximum load that the consensus layer will put on the machine should you run 64 validators or more on it. How do I add an additional validator? To add an additional validator, follow the same steps as you did when you added your first. You'll have to restart the beacon node for the changes to take effect. Note Note that a single Nimbus instance is able to handle multiple validators. Networking How can I improve my peer count? See the networking guide . How do I fix the discovered new external address warning log? WRN 2021-03-15 02:23:37.569+00:00 Discovered new external address but ENR auto update is off topics=\"discv5\"... It's possible that your ISP has changed your dynamic IP address without you knowing. The first thing to do it to try relaunching the beacon node with --enr-auto-update (pass it as an option in the command line). If this doesn't fix the problem, the next thing to do is to check your external (public) IP address and detect open ports on your connection - you can use https://www.yougetsignal.com/tools/open-ports/ . Note that Nimbus TCP and UDP ports are both set to 9000 by default. See here , for how to set up port forwarding. Folder Permissions To protect against key loss, Nimbus requires that files and directories be owned by the user running the application. Furthermore, they should not be readable by others. It may happen that the wrong permissions are applied, particularly when creating the directories manually. The following errors are a sign of this: Data folder has insecure ACL Data directory has insecure permissions File has insecure permissions See the data directory page for instructions on how to fix this Validating What exactly is a validator? A validator is an entity that participates in the consensus of the Ethereum protocol, and has staked 32 ETH to do so. Or in plain english, a human running a computer process. This process proposes and vouches for new blocks to be added to the blockchain. In other words, you can think of a validator as a voter for new blocks. The more votes a block gets, the more likely it is to be added to the chain. Importantly, a validator's vote is weighted by the amount it has at stake. What is the deposit contract? You can think of it as a transfer of funds between Ethereum 1.0 accounts and Ethereum 2.0 validators. It specifies who is staking, who is validating, how much is being staked, and who can withdraw the funds. Why do validators need to have funds at stake? Validators need to have funds at stake so they can be penalized for behaving dishonestly. In other words, to keep them honest, their actions need to have financial consequences. How much ETH does a validator need to stake? Before a validator can start to secure the network, they need to stake 32 ETH . This forms the validator's initial balance. Is there any advantage to having more than 32 ETH at stake? No. There is no advantage to having more than 32 ETH staked. Limiting the maximum stake to 32 ETH encourages decentralization of power as it prevents any single validator from having an excessively large vote on the state of the chain. Remember that a validator\u2019s vote is weighted by the amount it has at stake. Can I stop my validator for a few days and then start it back up again? Yes but, under normal conditions, you will lose an amount of ETH roughly equivalent to the amount of ETH you would have gained in that period. In other words, if you stood to earn \u22480.01 ETH, you would instead be penalised \u22480.01 ETH. I want to switch my validator keys to another machine, how long do I need to wait to avoid getting slashed? We recommend waiting 2 epochs (around 15 minutes), before restarting Nimbus on a different machine. When should I top up my validator's balance? The answer to this question very much depends on how much ETH you have at your disposal. You should certainly top up if your balance is close to 16 ETH: this is to ensure you don't get removed from the validator set (which automatically happens if your balance falls below 16 ETH). At the other end of the spectrum, if your balance is closer to 31 ETH, it's probably not worth your while adding the extra ETH required to get back to 32. When can I withdraw my funds, and what's the difference between exiting and withdrawing? You can signal your intent to stop validating by signing a voluntary exit message with your validator. However, bear in mind that in Phase 0, once you've exited, there's no going back. There's no way for you to activate your validator again, and you won't be able to transfer or withdraw your funds until at least Phase 1.5 (which means your funds will remain inaccessible until then). How are validators incentivized to stay active and honest? In addition to being penalized for being offline, validators are penalized for behaving maliciously \u2013 for example attesting to invalid or contradicting blocks. On the other hand, they are rewarded for proposing / attesting to blocks that are included in the chain. The key concept is the following: Rewards are given for actions that help the network reach consensus Minor penalties are given for inadvertant actions (or inactions) that hinder consensus And major penalities -- or slashings -- are given for malicious actions In other words, validators that maximize their rewards also provide the greatest benefit to the network as a whole. How are rewards/penalties issued? Remember that each validator has its own balance -- with the initial balance outlined in the deposit contract. This balance is updated periodically by the Ethereum network rules as the validator carries (or fails to carry) out his or her responsibilities. Put another way, rewards and penalties are reflected in the validator's balance over time. How often are rewards/penalties issued? Approximately every six and a half minutes -- a period of time known as an epoch. Every epoch, the network measures the actions of each validator and issues rewards or penalties appropriately. How large are the rewards/penalties? There is no easy answer to this question as there are many factors that go into this calculation. Arguably the most impactful factor on rewards earned for validating transactions is the total amount of stake in the network. In other words, the total amount of validators. Depending on this figure the max annual return rate for a validator can be anywhere between 2 and 20%. Given a fixed total number of validators, the rewards/penalties predominantly scale with the balance of the validator -- attesting with a higher balance results in larger rewards/penalties whereas attesting with a lower balance results in lower rewards/penalties. Note however that this scaling mechanism works in a non-obvious way. To understand the precise details of how it works requires understanding a concept called effective balance . If you're not yet familiar with this concept, we recommend you read through this excellent post . Why do rewards depend on the total number of validators in the network? Block rewards are calculated using a sliding scale based on the total amount of ETH staked on the network. In plain english: if the total amount of ETH staked is low, the reward (interest rate) is high, but as the total stake rises, the reward (interest) paid out to each validator starts to fall. Why a sliding scale? While we won't get into the gory details here, the basic intution is that there needs to be a minimum number of validators (and hence a minimum amount of ETH staked) for the network to function properly. So, to incentivize more validators to join, it's important that the interest rate remains high until this minimum number is reached. Afterwards, validators are still encouraged to join (the more validators the more decentralized the network), but it's not absolutely essential that they do so (so the interest rate can fall). How badly will a validator be penalized for being offline? It depends. In addition to the impact of effective balance there are two important scenarios to be aware of: Being offline while a supermajority (2/3) of validators is still online leads to relatively small penalties as there are still enough validators online for the chain to finalize. This is the expected scenario. Being offline at the same time as more than 1/3 of the total number of validators leads to harsher penalties, since blocks do not finalize anymore. This scenario is very extreme and unlikely to happen. Note that in the second (unlikely) scenario, validators stand to progressively lose up to 50% (16 ETH) of their stake over 21 days. After 21 days they are ejected out of the validator pool. This ensures that blocks start finalizing again at some point. How great does an honest validator's uptime need to be for it to be net profitable? Overall, validators are expected to be net profitable as long as their uptime is greater than 50% . This means that validators need not go to extreme lengths with backup clients or redundant internet connections as the repercussions of being offline are not so severe. How much will a validator be penalized for acting maliciously? Again, it depends. Behaving maliciously \u2013 for example attesting to invalid or contradicting blocks, will lead to a validator's stake being slashed. The minimum amount that can be slashed is 1 ETH, but this number increases if other validators are slashed at the same time. The idea behind this is to minimize the losses from honest mistakes, but strongly disincentivize coordinated attacks. What exactly is slashing? Slashing has two purposes: (1) to make it prohibitively expensive to attack eth2, and (2) to stop validators from being lazy by checking that they actually perform their duties. Slashing a validator is to destroy (a portion of) the validator\u2019s stake if they act in a provably destructive manner. Validators that are slashed are prevented from participating in the protocol further and are forcibly exited. What happens I lose my signing key? If the signing key is lost, the validator can no longer propose or attest. Over time, the validator's balance will decrease as he or she is punished for not participating in the consensus process. When the validator's balance reaches 16 Eth, he or she will be automatically exited from the validator pool. However, all is not lost. Assuming validators derive their keys using EIP2334 (as per the default onboarding flow)then validators can always recalculate their signing key from their withdrawal key . The 16 Eth can then be withdrawn -- with the withdrawal key -- after a delay of around a day. Note that this delay can be longer if many others are exiting or being kicked out at the same time. What happens if I lose my withdrawal key? If the withdrawal key is lost, there is no way to obtain access to the funds held by the validator. As such, it's a good idea to create your keys from mnemonics which act as another backup. This will be the default for validators who join via this site's onboarding process. What happens if my withdrawal key is stolen? If the withdrawal key is stolen, the thief can transfer the validator\u2019s balance, but only once the validator has exited. If the signing key is not under the thief\u2019s control, the thief cannot exit the validator. The user with the signing key could attempt to quickly exit the validator and then transfer the funds -- with the withdrawal key -- before the thief. Why two keys instead of one? In a nutshell, security. The signing key must be available at all times. As such, it will need to be held online. Since anything online is vulnerable to being hacked, it's not a good idea to use the same key for withdrawals.","title":"Frequently Asked Questions"},{"location":"faq.html#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq.html#general","text":"","title":"General"},{"location":"faq.html#which-version-of-nimbus-am-i-running","text":"You can check the version through a number of methods: # Run the beacon node with the --version flag: build/nimbus_beacon_node --version # Query the metrics server - requires running with the '--metrics' option curl -s http://localhost:8008/metrics | grep version # Query the REST API - requires running with the '--rest' option curl -s http://localhost:9100/eth/v1/node/version","title":"Which version of Nimbus am I running?"},{"location":"faq.html#why-are-metrics-not-working","text":"The metrics server is disabled by default: enable it by passing --metrics to the run command: build/nimbus_beacon_node --metrics ...","title":"Why are metrics not working?"},{"location":"faq.html#why-is-the-rest-server-not-working","text":"The REST server is disabled by default: enable it by passing --rest to the run command: build/nimbus_beacon_node --rest ...","title":"Why is the REST server not working?"},{"location":"faq.html#why-does-my-validator-miss-two-epochs-of-attestations-after-restarting","text":"When a validator is started (or restarted) it prudently listens for 2 epochs for attestations from a validator with the same index (a doppelganger), before sending an attestation itself. In sum, it's a simple way of handling the case where one validator comes online with the same key as another validator that's already online (i.e one device was started without switching the other off). While this strategy requires the client to wait two whole epochs on restart before attesting, a couple of missed attestations is a very minor price to pay in exchange for significantly reducing the risk of an accidental slashing. You can think of it as a small penalty that you pay only on first launch and restarts. When you take into account the total runtime of your validator, the impact should be minimal. While we strongly recommend it, you can disable it with an explicit flag ( --doppelganger-detection=false ) if you don't plan on moving your setup.","title":"Why does my validator miss two epochs of attestations after restarting?"},{"location":"faq.html#whats-the-best-way-to-stress-test-my-execution-consensus-setup-before-committing-with-real-eth","text":"We recommend running a Nimbus beacon node on Prater and a mainnet execution client on the same machine - this will simulate the load of running a mainnet validator. To stress test it, add --subscribe-all-subnets to the beacon node options . This simulates the maximum load that the consensus layer will put on the machine should you run 64 validators or more on it.","title":"What's the best way to stress test my execution + consensus setup before committing with real ETH?"},{"location":"faq.html#how-do-i-add-an-additional-validator","text":"To add an additional validator, follow the same steps as you did when you added your first. You'll have to restart the beacon node for the changes to take effect. Note Note that a single Nimbus instance is able to handle multiple validators.","title":"How do I add an additional validator?"},{"location":"faq.html#networking","text":"","title":"Networking"},{"location":"faq.html#how-can-i-improve-my-peer-count","text":"See the networking guide .","title":"How can I improve my peer count?"},{"location":"faq.html#how-do-i-fix-the-discovered-new-external-address-warning-log","text":"WRN 2021-03-15 02:23:37.569+00:00 Discovered new external address but ENR auto update is off topics=\"discv5\"... It's possible that your ISP has changed your dynamic IP address without you knowing. The first thing to do it to try relaunching the beacon node with --enr-auto-update (pass it as an option in the command line). If this doesn't fix the problem, the next thing to do is to check your external (public) IP address and detect open ports on your connection - you can use https://www.yougetsignal.com/tools/open-ports/ . Note that Nimbus TCP and UDP ports are both set to 9000 by default. See here , for how to set up port forwarding.","title":"How do I fix the discovered new external address warning log?"},{"location":"faq.html#folder-permissions","text":"To protect against key loss, Nimbus requires that files and directories be owned by the user running the application. Furthermore, they should not be readable by others. It may happen that the wrong permissions are applied, particularly when creating the directories manually. The following errors are a sign of this: Data folder has insecure ACL Data directory has insecure permissions File has insecure permissions See the data directory page for instructions on how to fix this","title":"Folder Permissions"},{"location":"faq.html#validating","text":"","title":"Validating"},{"location":"faq.html#what-exactly-is-a-validator","text":"A validator is an entity that participates in the consensus of the Ethereum protocol, and has staked 32 ETH to do so. Or in plain english, a human running a computer process. This process proposes and vouches for new blocks to be added to the blockchain. In other words, you can think of a validator as a voter for new blocks. The more votes a block gets, the more likely it is to be added to the chain. Importantly, a validator's vote is weighted by the amount it has at stake.","title":"What exactly is a validator?"},{"location":"faq.html#what-is-the-deposit-contract","text":"You can think of it as a transfer of funds between Ethereum 1.0 accounts and Ethereum 2.0 validators. It specifies who is staking, who is validating, how much is being staked, and who can withdraw the funds.","title":"What is the deposit contract?"},{"location":"faq.html#why-do-validators-need-to-have-funds-at-stake","text":"Validators need to have funds at stake so they can be penalized for behaving dishonestly. In other words, to keep them honest, their actions need to have financial consequences.","title":"Why do validators need to have funds at stake?"},{"location":"faq.html#how-much-eth-does-a-validator-need-to-stake","text":"Before a validator can start to secure the network, they need to stake 32 ETH . This forms the validator's initial balance.","title":"How much ETH does a validator need to stake?"},{"location":"faq.html#is-there-any-advantage-to-having-more-than-32-eth-at-stake","text":"No. There is no advantage to having more than 32 ETH staked. Limiting the maximum stake to 32 ETH encourages decentralization of power as it prevents any single validator from having an excessively large vote on the state of the chain. Remember that a validator\u2019s vote is weighted by the amount it has at stake.","title":"Is there any advantage to having more than 32 ETH at stake?"},{"location":"faq.html#can-i-stop-my-validator-for-a-few-days-and-then-start-it-back-up-again","text":"Yes but, under normal conditions, you will lose an amount of ETH roughly equivalent to the amount of ETH you would have gained in that period. In other words, if you stood to earn \u22480.01 ETH, you would instead be penalised \u22480.01 ETH.","title":"Can I stop my validator for a few days and then start it back up again?"},{"location":"faq.html#i-want-to-switch-my-validator-keys-to-another-machine-how-long-do-i-need-to-wait-to-avoid-getting-slashed","text":"We recommend waiting 2 epochs (around 15 minutes), before restarting Nimbus on a different machine.","title":"I want to switch my validator keys to another machine, how long do I need to wait to avoid getting slashed?"},{"location":"faq.html#when-should-i-top-up-my-validators-balance","text":"The answer to this question very much depends on how much ETH you have at your disposal. You should certainly top up if your balance is close to 16 ETH: this is to ensure you don't get removed from the validator set (which automatically happens if your balance falls below 16 ETH). At the other end of the spectrum, if your balance is closer to 31 ETH, it's probably not worth your while adding the extra ETH required to get back to 32.","title":"When should I top up my validator's balance?"},{"location":"faq.html#when-can-i-withdraw-my-funds-and-whats-the-difference-between-exiting-and-withdrawing","text":"You can signal your intent to stop validating by signing a voluntary exit message with your validator. However, bear in mind that in Phase 0, once you've exited, there's no going back. There's no way for you to activate your validator again, and you won't be able to transfer or withdraw your funds until at least Phase 1.5 (which means your funds will remain inaccessible until then).","title":"When can I withdraw my funds, and what's the difference between exiting and withdrawing?"},{"location":"faq.html#how-are-validators-incentivized-to-stay-active-and-honest","text":"In addition to being penalized for being offline, validators are penalized for behaving maliciously \u2013 for example attesting to invalid or contradicting blocks. On the other hand, they are rewarded for proposing / attesting to blocks that are included in the chain. The key concept is the following: Rewards are given for actions that help the network reach consensus Minor penalties are given for inadvertant actions (or inactions) that hinder consensus And major penalities -- or slashings -- are given for malicious actions In other words, validators that maximize their rewards also provide the greatest benefit to the network as a whole.","title":"How are validators incentivized to stay active and honest?"},{"location":"faq.html#how-are-rewardspenalties-issued","text":"Remember that each validator has its own balance -- with the initial balance outlined in the deposit contract. This balance is updated periodically by the Ethereum network rules as the validator carries (or fails to carry) out his or her responsibilities. Put another way, rewards and penalties are reflected in the validator's balance over time.","title":"How are rewards/penalties issued?"},{"location":"faq.html#how-often-are-rewardspenalties-issued","text":"Approximately every six and a half minutes -- a period of time known as an epoch. Every epoch, the network measures the actions of each validator and issues rewards or penalties appropriately.","title":"How often are rewards/penalties issued?"},{"location":"faq.html#how-large-are-the-rewardspenalties","text":"There is no easy answer to this question as there are many factors that go into this calculation. Arguably the most impactful factor on rewards earned for validating transactions is the total amount of stake in the network. In other words, the total amount of validators. Depending on this figure the max annual return rate for a validator can be anywhere between 2 and 20%. Given a fixed total number of validators, the rewards/penalties predominantly scale with the balance of the validator -- attesting with a higher balance results in larger rewards/penalties whereas attesting with a lower balance results in lower rewards/penalties. Note however that this scaling mechanism works in a non-obvious way. To understand the precise details of how it works requires understanding a concept called effective balance . If you're not yet familiar with this concept, we recommend you read through this excellent post .","title":"How large are the rewards/penalties?"},{"location":"faq.html#why-do-rewards-depend-on-the-total-number-of-validators-in-the-network","text":"Block rewards are calculated using a sliding scale based on the total amount of ETH staked on the network. In plain english: if the total amount of ETH staked is low, the reward (interest rate) is high, but as the total stake rises, the reward (interest) paid out to each validator starts to fall. Why a sliding scale? While we won't get into the gory details here, the basic intution is that there needs to be a minimum number of validators (and hence a minimum amount of ETH staked) for the network to function properly. So, to incentivize more validators to join, it's important that the interest rate remains high until this minimum number is reached. Afterwards, validators are still encouraged to join (the more validators the more decentralized the network), but it's not absolutely essential that they do so (so the interest rate can fall).","title":"Why do rewards depend on the total number of validators in the network?"},{"location":"faq.html#how-badly-will-a-validator-be-penalized-for-being-offline","text":"It depends. In addition to the impact of effective balance there are two important scenarios to be aware of: Being offline while a supermajority (2/3) of validators is still online leads to relatively small penalties as there are still enough validators online for the chain to finalize. This is the expected scenario. Being offline at the same time as more than 1/3 of the total number of validators leads to harsher penalties, since blocks do not finalize anymore. This scenario is very extreme and unlikely to happen. Note that in the second (unlikely) scenario, validators stand to progressively lose up to 50% (16 ETH) of their stake over 21 days. After 21 days they are ejected out of the validator pool. This ensures that blocks start finalizing again at some point.","title":"How badly will a validator be penalized for being offline?"},{"location":"faq.html#how-great-does-an-honest-validators-uptime-need-to-be-for-it-to-be-net-profitable","text":"Overall, validators are expected to be net profitable as long as their uptime is greater than 50% . This means that validators need not go to extreme lengths with backup clients or redundant internet connections as the repercussions of being offline are not so severe.","title":"How great does an honest validator's uptime need to be for it to be net profitable?"},{"location":"faq.html#how-much-will-a-validator-be-penalized-for-acting-maliciously","text":"Again, it depends. Behaving maliciously \u2013 for example attesting to invalid or contradicting blocks, will lead to a validator's stake being slashed. The minimum amount that can be slashed is 1 ETH, but this number increases if other validators are slashed at the same time. The idea behind this is to minimize the losses from honest mistakes, but strongly disincentivize coordinated attacks.","title":"How much will a validator be penalized for acting maliciously?"},{"location":"faq.html#what-exactly-is-slashing","text":"Slashing has two purposes: (1) to make it prohibitively expensive to attack eth2, and (2) to stop validators from being lazy by checking that they actually perform their duties. Slashing a validator is to destroy (a portion of) the validator\u2019s stake if they act in a provably destructive manner. Validators that are slashed are prevented from participating in the protocol further and are forcibly exited.","title":"What exactly is slashing?"},{"location":"faq.html#what-happens-i-lose-my-signing-key","text":"If the signing key is lost, the validator can no longer propose or attest. Over time, the validator's balance will decrease as he or she is punished for not participating in the consensus process. When the validator's balance reaches 16 Eth, he or she will be automatically exited from the validator pool. However, all is not lost. Assuming validators derive their keys using EIP2334 (as per the default onboarding flow)then validators can always recalculate their signing key from their withdrawal key . The 16 Eth can then be withdrawn -- with the withdrawal key -- after a delay of around a day. Note that this delay can be longer if many others are exiting or being kicked out at the same time.","title":"What happens I lose my signing key?"},{"location":"faq.html#what-happens-if-i-lose-my-withdrawal-key","text":"If the withdrawal key is lost, there is no way to obtain access to the funds held by the validator. As such, it's a good idea to create your keys from mnemonics which act as another backup. This will be the default for validators who join via this site's onboarding process.","title":"What happens if I lose my withdrawal key?"},{"location":"faq.html#what-happens-if-my-withdrawal-key-is-stolen","text":"If the withdrawal key is stolen, the thief can transfer the validator\u2019s balance, but only once the validator has exited. If the signing key is not under the thief\u2019s control, the thief cannot exit the validator. The user with the signing key could attempt to quickly exit the validator and then transfer the funds -- with the withdrawal key -- before the thief.","title":"What happens if my withdrawal key is stolen?"},{"location":"faq.html#why-two-keys-instead-of-one","text":"In a nutshell, security. The signing key must be available at all times. As such, it will need to be held online. Since anything online is vulnerable to being hacked, it's not a good idea to use the same key for withdrawals.","title":"Why two keys instead of one?"},{"location":"goerli-eth.html","text":"Obtain Goerli ETH To participate in an eth2 testnet, you need to stake 32 testnet ETH. You can request this testnet ETH by joining the ethstaker discord - look for the #request-goerli-eth channel.","title":"Obtain Goerli ETH"},{"location":"goerli-eth.html#obtain-goerli-eth","text":"To participate in an eth2 testnet, you need to stake 32 testnet ETH. You can request this testnet ETH by joining the ethstaker discord - look for the #request-goerli-eth channel.","title":"Obtain Goerli ETH"},{"location":"graffiti.html","text":"Graffiti You can use your node's graffiti flag to make your mark on history and forever engrave some words of your choice into an Ethereum block. You will be able to see it using the block explorer. Mainnet Prater ./run-mainnet-beacon-node.sh --graffiti = \"<YOUR_WORDS>\" ./run-prater-beacon-node.sh --graffiti = \"<YOUR_WORDS>\"","title":"Graffiti"},{"location":"graffiti.html#graffiti","text":"You can use your node's graffiti flag to make your mark on history and forever engrave some words of your choice into an Ethereum block. You will be able to see it using the block explorer. Mainnet Prater ./run-mainnet-beacon-node.sh --graffiti = \"<YOUR_WORDS>\" ./run-prater-beacon-node.sh --graffiti = \"<YOUR_WORDS>\"","title":"Graffiti"},{"location":"hardware.html","text":"System requirements The recommended system requirements for running the Nimbus beacon node are: What Recommended Operating system Linux 64-bit , Windows 64-bit, macOS X 10.14+ Memory 4GB Disk space 200GB Network Reliable broadband Execution client In addtion to the beacon node, you will need to run an execution client - check the documentation of the client of choice and add them to the above requirements. Broadly, to run both an execution and a consensus client on the same machine, we recommend a 2 TB SSD drive and 8 GB RAM. Minimal requirements Nimbus has been optimized to also run well on hardware significantly less powerful than the recommended system requirements - the more validators you run on the same node, the more hardware resources and network bandwidth will it will use.","title":"System requirements"},{"location":"hardware.html#system-requirements","text":"The recommended system requirements for running the Nimbus beacon node are: What Recommended Operating system Linux 64-bit , Windows 64-bit, macOS X 10.14+ Memory 4GB Disk space 200GB Network Reliable broadband Execution client In addtion to the beacon node, you will need to run an execution client - check the documentation of the client of choice and add them to the above requirements. Broadly, to run both an execution and a consensus client on the same machine, we recommend a 2 TB SSD drive and 8 GB RAM. Minimal requirements Nimbus has been optimized to also run well on hardware significantly less powerful than the recommended system requirements - the more validators you run on the same node, the more hardware resources and network bandwidth will it will use.","title":"System requirements"},{"location":"health.html","text":"Monitor the health of your node The most important thing for the the health, performance and stablity of your node and the overall network is the strength of your node's network connectivity / peer count. See here for our networking related tips and tricks. Keep track of your attestation effectiveness Attestation effectiveness is a metric that directly affects your validator rewards. In simple terms, an attestation is more valuable the sooner it is put into a block and included in the chain. This interval is called the inclusion distance of an attestation. The smaller it is, the more profitable your validator will be. For a deeper understanding we highly recommend reading Attestant's wonderful blog post on the matter. You can verify your validator's effectiveness on the beaconcha.in website. Ideally you want to see a value above 80%. While attestation effectiveness depends on a variety of factors - attestation network propagation, your network connectivity, and the peers you are connected to - your network connectivity is likely the most important factors you can control to improve this metric. Apart from the tips outlined on this guide, you could also experiment with subscribing to all subnets . Monitor your system's network I/O usage If you're a Linux user and want to track how much network I/O your system uses over time, you can install a nice utility called vnstat . To install, run: sudo apt install vnstat To run it: TBC -See here for more","title":"Monitor the health of your node"},{"location":"health.html#monitor-the-health-of-your-node","text":"The most important thing for the the health, performance and stablity of your node and the overall network is the strength of your node's network connectivity / peer count. See here for our networking related tips and tricks.","title":"Monitor the health of your node"},{"location":"health.html#keep-track-of-your-attestation-effectiveness","text":"Attestation effectiveness is a metric that directly affects your validator rewards. In simple terms, an attestation is more valuable the sooner it is put into a block and included in the chain. This interval is called the inclusion distance of an attestation. The smaller it is, the more profitable your validator will be. For a deeper understanding we highly recommend reading Attestant's wonderful blog post on the matter. You can verify your validator's effectiveness on the beaconcha.in website. Ideally you want to see a value above 80%. While attestation effectiveness depends on a variety of factors - attestation network propagation, your network connectivity, and the peers you are connected to - your network connectivity is likely the most important factors you can control to improve this metric. Apart from the tips outlined on this guide, you could also experiment with subscribing to all subnets .","title":"Keep track of your attestation effectiveness"},{"location":"health.html#monitor-your-systems-network-io-usage","text":"If you're a Linux user and want to track how much network I/O your system uses over time, you can install a nice utility called vnstat . To install, run: sudo apt install vnstat To run it: TBC -See here for more","title":"Monitor your system's network I/O usage"},{"location":"infura-guide.html","text":"Setting up an infura account \u26a0\ufe0f After The Merge, you will need to run your own execution client . In a nutshell, Infura is a hosted ethereum node cluster that lets you make requests to the eth1 blockchain without requiring you to set up your own eth1 node. While we do support Infura to process incoming validator deposits, we recommend running your own eth1 node to avoid relying on a third-party-service. Note: Nimbus currently supports remote Infura nodes and local execution nodes . In the future, we plan on having our own eth1 client -- Nimbus 1 -- be the recommended default. 1. Visit Infura.io Go to: https://infura.io/ and click on Get Started For Free 2. Sign up Enter your email address and create a password 3. Verify email address You should have received an email from Infura in your inbox. Open up it up and click on Confirm Email Address 4. Go to dashboard This will take you to your Infura dashboard (https://infura.io/dashboard/) 5. Create your first project Click on the first option ( create your first project ) under Let's Get Started Choose a name for your project You'll be directed to the settings page of your newly created project 6. Select endpoint \u26a0\ufe0f If you're connecting to mainnet, you should skip this step If you're connecting to a testnet, in the KEYS section, click on the dropdown menu to the right of ENDPOINTS , and select G\u00d6RLI 7. Copy one of the endpoints You can use either endpoint but we recommend you copy the wss 8. Run the beacon node Launch the beacon node on your favourite testnet, passing in your websocket endpoint as the Web3 provider URL . 9. Check stats Visit your project's stats page to see a summary of your eth1 related activity and method calls That's all there is to it :)","title":"Setting up an infura account"},{"location":"infura-guide.html#setting-up-an-infura-account","text":"\u26a0\ufe0f After The Merge, you will need to run your own execution client . In a nutshell, Infura is a hosted ethereum node cluster that lets you make requests to the eth1 blockchain without requiring you to set up your own eth1 node. While we do support Infura to process incoming validator deposits, we recommend running your own eth1 node to avoid relying on a third-party-service. Note: Nimbus currently supports remote Infura nodes and local execution nodes . In the future, we plan on having our own eth1 client -- Nimbus 1 -- be the recommended default.","title":"Setting up an infura account"},{"location":"infura-guide.html#1-visit-infuraio","text":"Go to: https://infura.io/ and click on Get Started For Free","title":"1. Visit Infura.io"},{"location":"infura-guide.html#2-sign-up","text":"Enter your email address and create a password","title":"2. Sign up"},{"location":"infura-guide.html#3-verify-email-address","text":"You should have received an email from Infura in your inbox. Open up it up and click on Confirm Email Address","title":"3. Verify email address"},{"location":"infura-guide.html#4-go-to-dashboard","text":"This will take you to your Infura dashboard (https://infura.io/dashboard/)","title":"4. Go to dashboard"},{"location":"infura-guide.html#5-create-your-first-project","text":"Click on the first option ( create your first project ) under Let's Get Started Choose a name for your project You'll be directed to the settings page of your newly created project","title":"5. Create your first project"},{"location":"infura-guide.html#6-select-endpoint","text":"\u26a0\ufe0f If you're connecting to mainnet, you should skip this step If you're connecting to a testnet, in the KEYS section, click on the dropdown menu to the right of ENDPOINTS , and select G\u00d6RLI","title":"6. Select endpoint"},{"location":"infura-guide.html#7-copy-one-of-the-endpoints","text":"You can use either endpoint but we recommend you copy the wss","title":"7. Copy one of the endpoints"},{"location":"infura-guide.html#8-run-the-beacon-node","text":"Launch the beacon node on your favourite testnet, passing in your websocket endpoint as the Web3 provider URL .","title":"8. Run the beacon node"},{"location":"infura-guide.html#9-check-stats","text":"Visit your project's stats page to see a summary of your eth1 related activity and method calls That's all there is to it :)","title":"9. Check stats"},{"location":"install.html","text":"Prepare your machine The Nimbus beacon node runs on Linux, macOS, Windows, and Android. System requirements Check that your machine matches the minimal system requirements . Time The beacon chain relies on your computer having the correct time set (\u00b10.5 seconds). It is important that you periodically synchronize the time with an NTP server. If the above sounds like latin to you, don't worry. You should be fine as long as you haven't changed the time and date settings on your computer (they should be set automatically). Linux Windows, macOS On Linux, it is recommended to install chrony . To install it: # Debian and Ubuntu sudo apt-get install -y chrony # Fedora sudo dnf install chrony # Archlinux, using an AUR manager yourAURmanager chrony Make sure that the options for setting time automatically are enabled.","title":"Prepare your machine"},{"location":"install.html#prepare-your-machine","text":"The Nimbus beacon node runs on Linux, macOS, Windows, and Android.","title":"Prepare your machine"},{"location":"install.html#system-requirements","text":"Check that your machine matches the minimal system requirements .","title":"System requirements"},{"location":"install.html#time","text":"The beacon chain relies on your computer having the correct time set (\u00b10.5 seconds). It is important that you periodically synchronize the time with an NTP server. If the above sounds like latin to you, don't worry. You should be fine as long as you haven't changed the time and date settings on your computer (they should be set automatically). Linux Windows, macOS On Linux, it is recommended to install chrony . To install it: # Debian and Ubuntu sudo apt-get install -y chrony # Fedora sudo dnf install chrony # Archlinux, using an AUR manager yourAURmanager chrony Make sure that the options for setting time automatically are enabled.","title":"Time"},{"location":"intro.html","text":"Moved","title":"Intro"},{"location":"keep-an-eye.html","text":"Keep an eye on your validator The best way to keep track of your validator's status is using the beaconcha.in explorer (click on the orange magnifying glass at the very top and paste in your validator's public key): Mainnet: beaconcha.in Testnet: prater.beaconcha.in When you make a deposit, your validator(s) will be put in a queue based on deposit time, and will slowly be inducted into the validator set. Getting through the queue may take up to a few days, depending on the length of the deposit queue. You can even create an account ( testnet link , mainnet link ) to add alerts and keep track of your validator's performance ( testnet link , mainnet link ). Make sure your validator is attached On startup, you should see a log message that reads Local validator attached . This has a pubkey field which should the public key of your validator. Keep track of your syncing progress To keep track of your sync progress, pay attention to the Slot start messages in your logs: INF 2022-06-16 13:23:11.008+02:00 Slot start topics=\"beacnde\" slot=4046214 epoch=126444 sync=\"00h37m (99.38%) 11.0476slots/s (DDQQDDDPDD:4021215)\" peers=55 head=5d59aba3:4021234 finalized=125661:82616f78 delay=8ms245us608ns Where: slot is the current time on the beacon chain, measured in \"slots\" epoch shows the current epoch - each epoch has 32 slots, and each validator performs one attestation per epoch peers tells you how many peers you're currently connected to - depending on the number of attached validators, you may need anywhere from 10 to 60 peers connected sync tells you if your client is synced and can perform duties, or how long it will take to get there - in the case of trusted node sync it may also show backfill in which case duties are being performed but more bandwidth than usual is being used to download historical blocks head tells you the most recent block you've synced to so far ( 5d59aba3 is the first part of the block hash, 4021234 is the slot number) finalized tells you the most recent finalized epoch you've synced to so far ( 125661 is the epoch, 82616f78 is the checkpoint hash) The string of letters -- what we call the sync worker map (in the above case represented by DDQQDDDPDD ) represents the peers you are syncing from, where: s - sleeping (idle), w - waiting for a peer from PeerPool, R - requesting blocks from peer D - downloading blocks from peer Q - queued/waiting for ancestor blocks P - processing/verifying blocks U - updating peer's status information Tip You can also use you calls outlined in the REST API page to retrieve similar information.","title":"Keep an eye on your validator"},{"location":"keep-an-eye.html#keep-an-eye-on-your-validator","text":"The best way to keep track of your validator's status is using the beaconcha.in explorer (click on the orange magnifying glass at the very top and paste in your validator's public key): Mainnet: beaconcha.in Testnet: prater.beaconcha.in When you make a deposit, your validator(s) will be put in a queue based on deposit time, and will slowly be inducted into the validator set. Getting through the queue may take up to a few days, depending on the length of the deposit queue. You can even create an account ( testnet link , mainnet link ) to add alerts and keep track of your validator's performance ( testnet link , mainnet link ).","title":"Keep an eye on your validator"},{"location":"keep-an-eye.html#make-sure-your-validator-is-attached","text":"On startup, you should see a log message that reads Local validator attached . This has a pubkey field which should the public key of your validator.","title":"Make sure your validator is attached"},{"location":"keep-an-eye.html#keep-track-of-your-syncing-progress","text":"To keep track of your sync progress, pay attention to the Slot start messages in your logs: INF 2022-06-16 13:23:11.008+02:00 Slot start topics=\"beacnde\" slot=4046214 epoch=126444 sync=\"00h37m (99.38%) 11.0476slots/s (DDQQDDDPDD:4021215)\" peers=55 head=5d59aba3:4021234 finalized=125661:82616f78 delay=8ms245us608ns Where: slot is the current time on the beacon chain, measured in \"slots\" epoch shows the current epoch - each epoch has 32 slots, and each validator performs one attestation per epoch peers tells you how many peers you're currently connected to - depending on the number of attached validators, you may need anywhere from 10 to 60 peers connected sync tells you if your client is synced and can perform duties, or how long it will take to get there - in the case of trusted node sync it may also show backfill in which case duties are being performed but more bandwidth than usual is being used to download historical blocks head tells you the most recent block you've synced to so far ( 5d59aba3 is the first part of the block hash, 4021234 is the slot number) finalized tells you the most recent finalized epoch you've synced to so far ( 125661 is the epoch, 82616f78 is the checkpoint hash) The string of letters -- what we call the sync worker map (in the above case represented by DDQQDDDPDD ) represents the peers you are syncing from, where: s - sleeping (idle), w - waiting for a peer from PeerPool, R - requesting blocks from peer D - downloading blocks from peer Q - queued/waiting for ancestor blocks P - processing/verifying blocks U - updating peer's status information Tip You can also use you calls outlined in the REST API page to retrieve similar information.","title":"Keep track of your syncing progress"},{"location":"keep-updated.html","text":"Upgrade / downgrade Make sure you stay on the lookout for any critical updates to Nimbus. This best way to do so is through the announcements channel on our discord . The release page can be found here . Note If your beacon node is already running, you'll need to restart it for the changes to take effect. To update to the latest version, either download the binary or compile the beacon node release (see below). Tip To check which version of Nimbus you're currently running, run build/nimbus_beacon_node --version Binaries Open the latest Nimbus release and download the file that corresponds to your operation system and machine. Once downloaded, unpack the binaries in the same folder as your current version, overwriting the existing files. wget <insert download link here> tar -xzf nimbus-eth2_Linux_arm64v8*.tar.gz --strip-components 1 -C nimbus-eth2 rm nimbus-eth2_Linux_arm64v8*.tar.gz Build from source Upgrading Nimbus when built from source is similar to the installation process. Run: # Download the updated source code git pull && make update Followed by: make -j4 nimbus_beacon_node Now, restart your node. Tip In order to minimise downtime, we recommend updating and rebuilding the beacon node before restarting . Urgency guidelines As of v1.4.0 , releases are marked with the following tags: low-urgency : update at your own convenience, sometime within our normal update cycle of two weeks medium-urgency : may contain an important stability fix, it is better to update sooner rather than later high-urgency : update as soon as you can, this is a critical update required for Nimbus to function correctly Install a specific version Occassionally you may need to either upgrade or downgrade to a specific version of Nimbus. To pull a specific version of Nimbus (e.g. v1.3.0 ), run: git checkout v1.3.0 && make update Followed by: make nimbus_beacon_node Now, restart your node. Note Alternatively, you can grab the appropriate binary release - create a backup of your build folder, then download the appropriate binary from here: https://github.com/status-im/nimbus-eth2/releases/tag/v1.3.0 Go back to stable If you need to go back to the latest (stable) version, run: git checkout stable && make update Followed by make nimbus_beacon_node Don't forget to restart your node.","title":"Upgrade / downgrade"},{"location":"keep-updated.html#upgrade-downgrade","text":"Make sure you stay on the lookout for any critical updates to Nimbus. This best way to do so is through the announcements channel on our discord . The release page can be found here . Note If your beacon node is already running, you'll need to restart it for the changes to take effect. To update to the latest version, either download the binary or compile the beacon node release (see below). Tip To check which version of Nimbus you're currently running, run build/nimbus_beacon_node --version","title":"Upgrade / downgrade"},{"location":"keep-updated.html#binaries","text":"Open the latest Nimbus release and download the file that corresponds to your operation system and machine. Once downloaded, unpack the binaries in the same folder as your current version, overwriting the existing files. wget <insert download link here> tar -xzf nimbus-eth2_Linux_arm64v8*.tar.gz --strip-components 1 -C nimbus-eth2 rm nimbus-eth2_Linux_arm64v8*.tar.gz","title":"Binaries"},{"location":"keep-updated.html#build-from-source","text":"Upgrading Nimbus when built from source is similar to the installation process. Run: # Download the updated source code git pull && make update Followed by: make -j4 nimbus_beacon_node Now, restart your node. Tip In order to minimise downtime, we recommend updating and rebuilding the beacon node before restarting .","title":"Build from source"},{"location":"keep-updated.html#urgency-guidelines","text":"As of v1.4.0 , releases are marked with the following tags: low-urgency : update at your own convenience, sometime within our normal update cycle of two weeks medium-urgency : may contain an important stability fix, it is better to update sooner rather than later high-urgency : update as soon as you can, this is a critical update required for Nimbus to function correctly","title":"Urgency guidelines"},{"location":"keep-updated.html#install-a-specific-version","text":"Occassionally you may need to either upgrade or downgrade to a specific version of Nimbus. To pull a specific version of Nimbus (e.g. v1.3.0 ), run: git checkout v1.3.0 && make update Followed by: make nimbus_beacon_node Now, restart your node. Note Alternatively, you can grab the appropriate binary release - create a backup of your build folder, then download the appropriate binary from here: https://github.com/status-im/nimbus-eth2/releases/tag/v1.3.0","title":"Install a specific version"},{"location":"keep-updated.html#go-back-to-stable","text":"If you need to go back to the latest (stable) version, run: git checkout stable && make update Followed by make nimbus_beacon_node Don't forget to restart your node.","title":"Go back to stable"},{"location":"keymanager-api.html","text":"Keymanager API Warning This feature is currently in BETA - we are still testing it and implementation details may change in response to community feedback. We strongly advise against using it on mainnet - your validators may get slashed The standardized Keymanager API can be used to add, remove, or migrate validators on the fly while the beacon node is running. As of v1.7.0 it supports web3signer keystores. Configuration By default, we disable the Keymanager API. To enable it, start the beacon node with the --keymanager option enabled: ./run-prater-beacon-node.sh --keymanager Once the node is running, you'll be able to access the API from http://localhost:5052/ Authorization: Bearer scheme All requests must be authorized through the Authorization: Bearer scheme with a token matching the contents of a file provided at the start of the node through the --keymanager-token-file parameter. Enabling connections from outside machines By default, only connections from the same machine are entertained. If you wish to change this you can configure the port and listening address with the --keymanager-port and --keymanager-address options respectively. \u26a0\ufe0f The Keymanager API port should only be exposed through a secure channel (e.g. HTTPS, an SSH tunnel, a VPN, etc.) Specification The specification is documented here . The README is also extremely useful and is documented here .","title":"Keymanager API"},{"location":"keymanager-api.html#keymanager-api","text":"Warning This feature is currently in BETA - we are still testing it and implementation details may change in response to community feedback. We strongly advise against using it on mainnet - your validators may get slashed The standardized Keymanager API can be used to add, remove, or migrate validators on the fly while the beacon node is running. As of v1.7.0 it supports web3signer keystores.","title":"Keymanager API"},{"location":"keymanager-api.html#configuration","text":"By default, we disable the Keymanager API. To enable it, start the beacon node with the --keymanager option enabled: ./run-prater-beacon-node.sh --keymanager Once the node is running, you'll be able to access the API from http://localhost:5052/","title":"Configuration"},{"location":"keymanager-api.html#authorization-bearer-scheme","text":"All requests must be authorized through the Authorization: Bearer scheme with a token matching the contents of a file provided at the start of the node through the --keymanager-token-file parameter.","title":"Authorization: Bearer scheme"},{"location":"keymanager-api.html#enabling-connections-from-outside-machines","text":"By default, only connections from the same machine are entertained. If you wish to change this you can configure the port and listening address with the --keymanager-port and --keymanager-address options respectively. \u26a0\ufe0f The Keymanager API port should only be exposed through a secure channel (e.g. HTTPS, an SSH tunnel, a VPN, etc.)","title":"Enabling connections from outside machines"},{"location":"keymanager-api.html#specification","text":"The specification is documented here . The README is also extremely useful and is documented here .","title":"Specification"},{"location":"keys.html","text":"Import your validator keys Tip systemd service file users will want to follow the service file guide instead! Having followed the deposit guide, you will have a validator_keys folder containing several .json files in the nimbus-eth2 directory. We'll import the signing key of each validator to the data directory using the deposits import command: Mainnet Prater build/nimbus_beacon_node deposits import --data-dir = build/data/shared_mainnet_0 build/nimbus_beacon_node deposits import --data-dir = build/data/shared_prater_0 You'll be asked to enter the password you created to encrypt your keystore(s). If your validator_keys folder is stored elsewhere, you can pass its location to the import command: Mainnet Prater build/nimbus_beacon_node deposits import \\ --data-dir = build/data/shared_mainnet_0 \\ /path/to/keys build/nimbus_beacon_node deposits import \\ --data-dir = build/data/shared_prater_0 \\ /path/to/keys Replacing /path/to/keys with the full pathname of where the validator_keys directory is found. On success, a message will be printed that your keys have been imported: NOT 2022-07-19 17:36:37.578+02:00 Keystore imported NOT is short for NOTICE and not not :) After importing keys, it's time to restart the node and check that the keys have been picked up by the beacon node. Tip You can read more about the different types of keys here - the deposit import command will import the signing key only. Troubleshooting If you come across an error, make sure that: You are using the correct data directory for systemd users, look for the --data-dir option in the .service file You are running the command as the correct user for systemd users, look for the User= option in the .service . Assuming the user is called nimbus , prefix all commands with: sudo -u nimbus Permissions for the data directory are wrong See folder permissions for how to fix this.","title":"Import your validator keys"},{"location":"keys.html#import-your-validator-keys","text":"Tip systemd service file users will want to follow the service file guide instead! Having followed the deposit guide, you will have a validator_keys folder containing several .json files in the nimbus-eth2 directory. We'll import the signing key of each validator to the data directory using the deposits import command: Mainnet Prater build/nimbus_beacon_node deposits import --data-dir = build/data/shared_mainnet_0 build/nimbus_beacon_node deposits import --data-dir = build/data/shared_prater_0 You'll be asked to enter the password you created to encrypt your keystore(s). If your validator_keys folder is stored elsewhere, you can pass its location to the import command: Mainnet Prater build/nimbus_beacon_node deposits import \\ --data-dir = build/data/shared_mainnet_0 \\ /path/to/keys build/nimbus_beacon_node deposits import \\ --data-dir = build/data/shared_prater_0 \\ /path/to/keys Replacing /path/to/keys with the full pathname of where the validator_keys directory is found. On success, a message will be printed that your keys have been imported: NOT 2022-07-19 17:36:37.578+02:00 Keystore imported NOT is short for NOTICE and not not :) After importing keys, it's time to restart the node and check that the keys have been picked up by the beacon node. Tip You can read more about the different types of keys here - the deposit import command will import the signing key only.","title":"Import your validator keys"},{"location":"keys.html#troubleshooting","text":"If you come across an error, make sure that: You are using the correct data directory for systemd users, look for the --data-dir option in the .service file You are running the command as the correct user for systemd users, look for the User= option in the .service . Assuming the user is called nimbus , prefix all commands with: sudo -u nimbus Permissions for the data directory are wrong See folder permissions for how to fix this.","title":"Troubleshooting"},{"location":"kiln.html","text":"Run Kiln Kiln is the latest long-running merge testnet. It provides the perfect opportunity to verify your setup works as expected through the proof-of-stake transition and in a post-merge context. If you come across any issues, please report them here . N.B. Post merge, Node runners will need to run both a consensus and execution layer client. 1. Preparation 1.1 Download configs To download the merge testnet configurations, run: git clone https://github.com/eth-clients/merge-testnets.git cd merge-testnets/kiln 1.2 Generate secret To generate and write the JWT secret to a file, run: openssl rand -hex 32 | tr -d \"\\n\" > \"/tmp/jwtsecret\" You will need to pass this file to both the Execution Client and the Consensus Client (the JWT secret is an authentication mechanism between CL/EL). 2. Execution client We recommend running either Nethermind or Geth with Nimbus Nethermind 2.1N Clone and build Clone and build Nethermind: git clone --recursive https://github.com/NethermindEth/nethermind.git cd nethermind/src/Nethermind dotnet build Nethermind.sln -c Release 2.2N Start the client Start Nethermind: cd nethermind/src/Nethermind/Nethermind.Runner dotnet run -c Release -- --config kiln --JsonRpc.Host=0.0.0.0 --JsonRpc.JwtSecretFile=/tmp/jwtsecret Geth 2.1G Clone and build Clone and build Geth: git clone https://github.com/ethereum/go-ethereum.git cd go-ethereum make geth cd .. 2.2G Start the client Start Geth: cd kiln ./go-ethereum/build/bin/geth init genesis.json --datadir \"geth-datadir\" ./go-ethereum/build/bin/geth --datadir \"geth-datadir\" --http --http.api=\"engine,eth,web3,net,debug\" --ws --ws.api=\"engine,eth,web3,net,debug\" --http.corsdomain \"*\" --networkid=1337802 --syncmode=full --authrpc.jwtsecret=/tmp/jwtsecret --bootnodes \"enode://c354db99124f0faf677ff0e75c3cbbd568b2febc186af664e0c51ac435609badedc67a18a63adb64dacc1780a28dcefebfc29b83fd1a3f4aa3c0eb161364cf94@164.92.130.5:30303\" console 3. Nimbus 3.1 Clone and build Nimbus from source Clone and build Nimbus from source from the kiln-dev-auth branch: git clone --branch=kiln-dev-auth https://github.com/status-im/nimbus-eth2.git cd nimbus-eth2 make update OVERRIDE=1 make nimbus_beacon_node cd .. 3.2 Start the client Start Nimbus: nimbus-eth2/build/nimbus_beacon_node \\ --network=merge-testnets/kiln \\ --web3-url=ws://127.0.0.1:8551 \\ --rest \\ --metrics \\ --log-level=DEBUG \\ --terminal-total-difficulty-override=20000000000000 \\ --jwt-secret=\"/tmp/jwtsecret\" Useful resources Kiln landing page : add the network to your browser wallet, view block explorers, request funds from the faucet, and connect to a JSON RPC endpoint. Kiln validator launchpad : make a deposit for your validator. EF launchpad notes : how to run a node on Kiln Ethereum On Arm Kiln RP4 image : Run Nimbus on a raspberry pi or using an AWS AMI","title":"Run Kiln"},{"location":"kiln.html#run-kiln","text":"Kiln is the latest long-running merge testnet. It provides the perfect opportunity to verify your setup works as expected through the proof-of-stake transition and in a post-merge context. If you come across any issues, please report them here . N.B. Post merge, Node runners will need to run both a consensus and execution layer client.","title":"Run Kiln"},{"location":"kiln.html#1-preparation","text":"","title":"1. Preparation"},{"location":"kiln.html#11-download-configs","text":"To download the merge testnet configurations, run: git clone https://github.com/eth-clients/merge-testnets.git cd merge-testnets/kiln","title":"1.1 Download configs"},{"location":"kiln.html#12-generate-secret","text":"To generate and write the JWT secret to a file, run: openssl rand -hex 32 | tr -d \"\\n\" > \"/tmp/jwtsecret\" You will need to pass this file to both the Execution Client and the Consensus Client (the JWT secret is an authentication mechanism between CL/EL).","title":"1.2 Generate secret"},{"location":"kiln.html#2-execution-client","text":"We recommend running either Nethermind or Geth with Nimbus","title":"2. Execution client"},{"location":"kiln.html#nethermind","text":"","title":"Nethermind"},{"location":"kiln.html#21n-clone-and-build","text":"Clone and build Nethermind: git clone --recursive https://github.com/NethermindEth/nethermind.git cd nethermind/src/Nethermind dotnet build Nethermind.sln -c Release","title":"2.1N Clone and build"},{"location":"kiln.html#22n-start-the-client","text":"Start Nethermind: cd nethermind/src/Nethermind/Nethermind.Runner dotnet run -c Release -- --config kiln --JsonRpc.Host=0.0.0.0 --JsonRpc.JwtSecretFile=/tmp/jwtsecret","title":"2.2N Start the client"},{"location":"kiln.html#geth","text":"","title":"Geth"},{"location":"kiln.html#21g-clone-and-build","text":"Clone and build Geth: git clone https://github.com/ethereum/go-ethereum.git cd go-ethereum make geth cd ..","title":"2.1G Clone and build"},{"location":"kiln.html#22g-start-the-client","text":"Start Geth: cd kiln ./go-ethereum/build/bin/geth init genesis.json --datadir \"geth-datadir\" ./go-ethereum/build/bin/geth --datadir \"geth-datadir\" --http --http.api=\"engine,eth,web3,net,debug\" --ws --ws.api=\"engine,eth,web3,net,debug\" --http.corsdomain \"*\" --networkid=1337802 --syncmode=full --authrpc.jwtsecret=/tmp/jwtsecret --bootnodes \"enode://c354db99124f0faf677ff0e75c3cbbd568b2febc186af664e0c51ac435609badedc67a18a63adb64dacc1780a28dcefebfc29b83fd1a3f4aa3c0eb161364cf94@164.92.130.5:30303\" console","title":"2.2G Start the client"},{"location":"kiln.html#3-nimbus","text":"","title":"3. Nimbus"},{"location":"kiln.html#31-clone-and-build-nimbus-from-source","text":"Clone and build Nimbus from source from the kiln-dev-auth branch: git clone --branch=kiln-dev-auth https://github.com/status-im/nimbus-eth2.git cd nimbus-eth2 make update OVERRIDE=1 make nimbus_beacon_node cd ..","title":"3.1 Clone and build Nimbus from source"},{"location":"kiln.html#32-start-the-client","text":"Start Nimbus: nimbus-eth2/build/nimbus_beacon_node \\ --network=merge-testnets/kiln \\ --web3-url=ws://127.0.0.1:8551 \\ --rest \\ --metrics \\ --log-level=DEBUG \\ --terminal-total-difficulty-override=20000000000000 \\ --jwt-secret=\"/tmp/jwtsecret\"","title":"3.2 Start the client"},{"location":"kiln.html#useful-resources","text":"Kiln landing page : add the network to your browser wallet, view block explorers, request funds from the faucet, and connect to a JSON RPC endpoint. Kiln validator launchpad : make a deposit for your validator. EF launchpad notes : how to run a node on Kiln Ethereum On Arm Kiln RP4 image : Run Nimbus on a raspberry pi or using an AWS AMI","title":"Useful resources"},{"location":"log-levels.html","text":"This information has moved to logging .","title":"Log levels"},{"location":"log-rotate.html","text":"Log rotation Nimbus logs are written to stdout , and can be redirected to a file. Writing to a file for a long-running process may lead to difficulties when the file grows large. This is typically solved with a log rotator . A log rotator is responsible for switching the written-to file, as well as compressing and removing old logs. Using logrotate logrotate provides log rotation and compression. The corresponding package will install its Cron hooks (or Systemd timer) -- all you have to do is add a configuration file for Nimbus in \"/etc/logrotate.d/nimbus-eth2\": /var/log/nimbus-eth2/*.log { compress missingok copytruncate } The above assumes you've configured Nimbus to write its logs to \"/var/log/nimbus-eth2/\" (usually by redirecting stdout and stderr from your init script). \"copytruncate\" is required because, when it comes to moving the log file, logrotate 's default behaviour requires application support for re-opening that log file at runtime (something which is currently lacking). So, instead of a move, we tell logrotate to do a copy and a truncation of the existing file. A few log lines may be lost in the process. You can control rotation frequency and the maximum number of log files kept by using the global configuration file - \"/etc/logrotate.conf\": # rotate daily daily # only keep logs from the last 7 days rotate 7 Using rotatelogs rotatelogs captures stdout logging and redirects it to a file, rotating and compressing on the fly. It is available on most servers and can be used with Docker , Systemd and manual setups to write rotated logs files. In particular, when systemd and its accompanying journald log daemon are used, this setup avoids clogging the system log by keeping the Nimbus logs in a separate location. Compression rotatelogs works by reading stdin and redirecting it to a file based on a name pattern. Whenever the log is about to be rotated, the application invokes a shell script with the old and new log files. Our aim is to compress the log file to save space. The Nimbus-eth2 repo provides a helper script that does this: # Create a rotation script for rotatelogs cat << EOF > rotatelogs-compress.sh #!/bin/sh # Helper script for Apache rotatelogs to compress log files on rotation - `$2` contains the old log file name if [ -f \"$2\" ]; then # \"nice\" prevents hogging the CPU with this low-priority task nice gzip -9 \"$2\" fi EOF chmod +x rotatelogs-compress.sh Run The final step is to redirect logs to rotatelogs using a pipe when starting Nimbus: build/nimbus_beacon_node \\ --network:prater \\ --web3-url = \" $WEB3URL \" \\ --data-dir: $DATADIR 2 > & 1 | rotatelogs -L \" $DATADIR /nbc_bn.log\" -p \"/path/to/rotatelogs-compress.sh\" -D -f -c \" $DATADIR /log/nbc_bn_%Y%m%d%H%M%S.log\" 3600 The options used in this example do the following: -L nbc_bn.log - symlinks to the latest log file, for use with tail -F -p \"/path/to/rotatelogs-compress.sh\" - runs rotatelogs-compress.sh when rotation is about to happen -D - creates the log directory if needed -f - opens the log immediately when starting rotatelogs -c \"$DATADIR/log/nbc_bn_%Y%m%d%H%M%S.log\" - includes timestamp in log filename 3600 - rotates logs every hour (3600 seconds) Deleting old logs rotatelogs will not do this for you, so you'll need a Cron script (or Systemd timer): # delete log files older than 7 days find \" $DATADIR /log\" -name 'nbc_bn_*.log' -mtime +7 -exec rm '{}' \\+","title":"Log rotation"},{"location":"log-rotate.html#log-rotation","text":"Nimbus logs are written to stdout , and can be redirected to a file. Writing to a file for a long-running process may lead to difficulties when the file grows large. This is typically solved with a log rotator . A log rotator is responsible for switching the written-to file, as well as compressing and removing old logs.","title":"Log rotation"},{"location":"log-rotate.html#using-logrotate","text":"logrotate provides log rotation and compression. The corresponding package will install its Cron hooks (or Systemd timer) -- all you have to do is add a configuration file for Nimbus in \"/etc/logrotate.d/nimbus-eth2\": /var/log/nimbus-eth2/*.log { compress missingok copytruncate } The above assumes you've configured Nimbus to write its logs to \"/var/log/nimbus-eth2/\" (usually by redirecting stdout and stderr from your init script). \"copytruncate\" is required because, when it comes to moving the log file, logrotate 's default behaviour requires application support for re-opening that log file at runtime (something which is currently lacking). So, instead of a move, we tell logrotate to do a copy and a truncation of the existing file. A few log lines may be lost in the process. You can control rotation frequency and the maximum number of log files kept by using the global configuration file - \"/etc/logrotate.conf\": # rotate daily daily # only keep logs from the last 7 days rotate 7","title":"Using logrotate"},{"location":"log-rotate.html#using-rotatelogs","text":"rotatelogs captures stdout logging and redirects it to a file, rotating and compressing on the fly. It is available on most servers and can be used with Docker , Systemd and manual setups to write rotated logs files. In particular, when systemd and its accompanying journald log daemon are used, this setup avoids clogging the system log by keeping the Nimbus logs in a separate location.","title":"Using rotatelogs"},{"location":"log-rotate.html#compression","text":"rotatelogs works by reading stdin and redirecting it to a file based on a name pattern. Whenever the log is about to be rotated, the application invokes a shell script with the old and new log files. Our aim is to compress the log file to save space. The Nimbus-eth2 repo provides a helper script that does this: # Create a rotation script for rotatelogs cat << EOF > rotatelogs-compress.sh #!/bin/sh # Helper script for Apache rotatelogs to compress log files on rotation - `$2` contains the old log file name if [ -f \"$2\" ]; then # \"nice\" prevents hogging the CPU with this low-priority task nice gzip -9 \"$2\" fi EOF chmod +x rotatelogs-compress.sh","title":"Compression"},{"location":"log-rotate.html#run","text":"The final step is to redirect logs to rotatelogs using a pipe when starting Nimbus: build/nimbus_beacon_node \\ --network:prater \\ --web3-url = \" $WEB3URL \" \\ --data-dir: $DATADIR 2 > & 1 | rotatelogs -L \" $DATADIR /nbc_bn.log\" -p \"/path/to/rotatelogs-compress.sh\" -D -f -c \" $DATADIR /log/nbc_bn_%Y%m%d%H%M%S.log\" 3600 The options used in this example do the following: -L nbc_bn.log - symlinks to the latest log file, for use with tail -F -p \"/path/to/rotatelogs-compress.sh\" - runs rotatelogs-compress.sh when rotation is about to happen -D - creates the log directory if needed -f - opens the log immediately when starting rotatelogs -c \"$DATADIR/log/nbc_bn_%Y%m%d%H%M%S.log\" - includes timestamp in log filename 3600 - rotates logs every hour (3600 seconds)","title":"Run"},{"location":"log-rotate.html#deleting-old-logs","text":"rotatelogs will not do this for you, so you'll need a Cron script (or Systemd timer): # delete log files older than 7 days find \" $DATADIR /log\" -name 'nbc_bn_*.log' -mtime +7 -exec rm '{}' \\+","title":"Deleting old logs"},{"location":"logging.html","text":"Logging options :warning: The logging options outlined here are based on a preview feature, and are subject to change Nimbus offers several options for logging - by default, logs are written to stdout using the chronicles textlines format which is convenient to read and can be used with tooling for heroku/logfmt . Tip NOT at the beginning of a log line means 'NOTICE` Change log level You can customise Nimbus' verbosity with the --log-level option. For example: ./run-mainnet-beacon-node.sh --log-level=WARN The default value is INFO . Possible values (in order of decreasing verbosity) are: TRACE DEBUG INFO NOTICE WARN ERROR FATAL NONE Change logging style Nimbus supports three log formats: colors , nocolors and json . In auto mode, logs will be printed using either colors or nocolors . You can choose a log format with the --log-format option, which also understands auto and none : ./run-mainnet-beacon-node.sh --log-format=none # disable logging to std out ./run-mainnet-beacon-node.sh --log-format=json # print json logs, one line per item Logging to a file To send logs to a file, you can redirect the stdout logs: # log json to filename.jsonl ./run-mainnet-beacon-node.sh --log-format=json > filename.jsonl We recommend keeping an eye on the growth of this file with a log rotator . Logs are written in the \"JSON Lines\" format - one json entry per line.","title":"Logging options"},{"location":"logging.html#logging-options","text":":warning: The logging options outlined here are based on a preview feature, and are subject to change Nimbus offers several options for logging - by default, logs are written to stdout using the chronicles textlines format which is convenient to read and can be used with tooling for heroku/logfmt . Tip NOT at the beginning of a log line means 'NOTICE`","title":"Logging options"},{"location":"logging.html#change-log-level","text":"You can customise Nimbus' verbosity with the --log-level option. For example: ./run-mainnet-beacon-node.sh --log-level=WARN The default value is INFO . Possible values (in order of decreasing verbosity) are: TRACE DEBUG INFO NOTICE WARN ERROR FATAL NONE","title":"Change log level"},{"location":"logging.html#change-logging-style","text":"Nimbus supports three log formats: colors , nocolors and json . In auto mode, logs will be printed using either colors or nocolors . You can choose a log format with the --log-format option, which also understands auto and none : ./run-mainnet-beacon-node.sh --log-format=none # disable logging to std out ./run-mainnet-beacon-node.sh --log-format=json # print json logs, one line per item","title":"Change logging style"},{"location":"logging.html#logging-to-a-file","text":"To send logs to a file, you can redirect the stdout logs: # log json to filename.jsonl ./run-mainnet-beacon-node.sh --log-format=json > filename.jsonl We recommend keeping an eye on the growth of this file with a log rotator . Logs are written in the \"JSON Lines\" format - one json entry per line.","title":"Logging to a file"},{"location":"merge.html","text":"The merge The Ethereum network is preparing for a major upgrade to merge the beacon chain with the existing proof-of-work execution network, thus transitioning to proof-of-stake. To read more about the merge, see https://ethereum.org/en/upgrades/merge/. Preparing for the merge The merge is in its final phase of testing on testnets and is expected to happen later during the year. Bookmark this page! As the merge draws near, we will continue to update this page with the latest information and instructions. Keep Nimbus up to date Leading up to the merge, it is important to keep Nimbus up to date . Before the merge, the exact version of Nimbus required to participate will be announced, but stakers should be prepared to upgrade their nodes on short notice. Run an execution client As a node operator, you will need to run both an execution client and a consensus client after the merge. If you were previously using a third-party web3 provider (such as Infura or Pocket), you will need to set up an execution client . Prepare a suggested fee recipient After the merge, validators that propose blocks are eligible to recieve transaction fees - read more about fee recipients here .","title":"The merge"},{"location":"merge.html#the-merge","text":"The Ethereum network is preparing for a major upgrade to merge the beacon chain with the existing proof-of-work execution network, thus transitioning to proof-of-stake. To read more about the merge, see https://ethereum.org/en/upgrades/merge/.","title":"The merge"},{"location":"merge.html#preparing-for-the-merge","text":"The merge is in its final phase of testing on testnets and is expected to happen later during the year.","title":"Preparing for the merge"},{"location":"merge.html#bookmark-this-page","text":"As the merge draws near, we will continue to update this page with the latest information and instructions.","title":"Bookmark this page!"},{"location":"merge.html#keep-nimbus-up-to-date","text":"Leading up to the merge, it is important to keep Nimbus up to date . Before the merge, the exact version of Nimbus required to participate will be announced, but stakers should be prepared to upgrade their nodes on short notice.","title":"Keep Nimbus up to date"},{"location":"merge.html#run-an-execution-client","text":"As a node operator, you will need to run both an execution client and a consensus client after the merge. If you were previously using a third-party web3 provider (such as Infura or Pocket), you will need to set up an execution client .","title":"Run an execution client"},{"location":"merge.html#prepare-a-suggested-fee-recipient","text":"After the merge, validators that propose blocks are eligible to recieve transaction fees - read more about fee recipients here .","title":"Prepare a suggested fee recipient"},{"location":"metrics-pretty-pictures.html","text":"Grafana and Prometheus In this page we'll cover how to use Grafana and Prometheus to help you visualise important real-time metrics concerning your validator and/or beacon node. Prometheus is an open-source systems monitoring and alerting toolkit. It runs as a service on your computer and its job is to capture metrics. You can find more information about Prometheus here . Grafana is a tool for beautiful dashboard monitoring that works well with Prometheus. You can learn more about Grafana here . Simple metrics To enable the metrics server, run the beacon node with the --metrics flag: ./run-prater-beacon-node.sh --metrics Visit http://127.0.0.1:8008/metrics with a browser or curl . You should see a plaintext page that looks something like this: # HELP nim_runtime_info Nim runtime info # TYPE nim_runtime_info gauge nim_gc_mem_bytes 6275072.0 nim_gc_mem_occupied_bytes 1881384.0 nim_gc_heap_instance_occupied_bytes{type_name=\"KeyValuePairSeq[digest.Eth2Digest, block_pools_types.BlockRef]\"} 25165856.0 nim_gc_heap_instance_occupied_bytes{type_name=\"BlockRef\"} 17284608.0 nim_gc_heap_instance_occupied_bytes{type_name=\"string\"} 6264507.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[SelectorKey[asyncdispatch.AsyncData]]\"} 409632.0 nim_gc_heap_instance_occupied_bytes{type_name=\"OrderedKeyValuePairSeq[Labels, seq[Metric]]\"} 122720.0 nim_gc_heap_instance_occupied_bytes{type_name=\"Future[system.void]\"} 79848.0 nim_gc_heap_instance_occupied_bytes{type_name=\"anon ref object from /Users/hackingresearch/nimbus/clone/nim-beacon-chain/vendor/nimbus-build-system/vendor/Nim/lib/pure/asyncmacro.nim(319, 33)\"} 65664.0 nim_gc_heap_instance_occupied_bytes{type_name=\"anon ref object from /Users/hackingresearch/nimbus/clone/nim-beacon-chain/vendor/nimbus-build-system/vendor/Nim/lib/pure/asyncnet.nim(506, 11)\"} 43776.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[byte]\"} 37236.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[TrustedAttestation]\"} 29728.0 ... Note: Metrics are by default only accessible from the same machine as the beacon node is running on - to fetch metrics from a remote machine, an SSH tunnel is recommended. The metrics server offers one snapshot in time of the state of the beacon node -- metrics however are at their most useful when collected over time -- for this, we'll need to set up two more pieces of software -- Prometheus and Grafana. Prometheus and Grafana The following steps will take you through how to use Prometheus and Grafana to spin up a beautiful and useful monitoring dashboard for your validator and beacon node. Steps 1. Download Prometheus Use your favourite package manager to download Prometheus -- for example apt-get install prometheus on Ubuntu, or brew install prometheus on MacOS, should do the trick. If you don't use a package manager, you can download the latest release of directly from Prometheus website. To extract it, run: tar xvfz prometheus-*.tar.gz cd prometheus-* 2. Copy the binary The Prometheus server is a single binary called prometheus (or prometheus.exe on Microsoft Windows). Copy it over to /usr/local/bin cp prometheus-2.20.1.linux-amd64/prometheus /usr/local/bin/ 3. Run Prometheus with the default configuration file Prometheus relies on a YAML configuration file to let it know where, and how often, to scrape data. Example config file: global: scrape_interval: 12s scrape_configs: - job_name: \"nimbus\" static_configs: - targets: ['127.0.0.1:8008'] Save the above as prometheus.yml in the nimbus-eth2 repo. Then run Prometheus: prometheus --config.file=./prometheus.yml --storage.tsdb.path=./prometheus You should see the following confirmation in the logs: level=info ts=2021-01-22T14:52:10.604Z caller=main.go:673 msg=\"Server is ready to receive web requests.\" 4. Download Grafana Download the latest release of Grafana for your platform. You need version 7.2 or newer. Note: If you use a package manager, you can also download Grafana that way -- for example apt-get install grafana on Ubuntu, or brew install grafana on MacOS, should do the trick. 5. Install and start Grafana Follow the instructions for your platform to install and start Grafana. 6. Configure login Go to http://localhost:3000/ , you should see a Grafana login screen that looks like this Type in admin for both the username and password. You'll be asked to change the password (we recommend you do so). 7. Add a data source Hover your mouse over the gear icon in the left menu bar, and click on the Data Sources option in the sub-menu that pops up. Now click on the Add Data Source button in the center of the screen Select Prometheus Enter http://localhost:9090 in the URL field Set the \"Scrape interval\" field to the same value you used in the Prometheus config (\"12\" in our example above). Scroll to the bottom and click on Save and Test If everything is working correctly you should see a green Data source is working box pop up 8. Import a dashboard Now, let's import a dashboard; hover your mouse over the + icon in the left menu bar and select import from the pop-up menu Click on Upload JSON file Select the beacon_nodes_Grafana_dashboard.json from the nimbus-eth2/grafana/ folder and click on Import You'll be directed to the dashboard where you'll be able to gain insights into the performance of nimbus-eth2 and your validators Note: the dashboard is very much a work in progress. Some of the highlights right now include received and proposed blocks, received and sent attestations, peers, memory and cpu usage stats. But keep an eye out for additional metrics in the near future. And voila! That's all there is to it :) Community dashboards Joe Clapis Joe \u2013 who\u2019s done some brilliant work integrating Nimbus with Rocket Pool \u2013 has created a wonderful guide where he takes you through how to set up a Grafana server on your Pi \u2013 using his dashboard as an example. In his words: This captures just about every metric I think I\u2019d like to see at a glance. Whether or not you're running a Pi, we recommend you check out his guide here . Metanull A dashboard aimed primarily at users rather than developers. Note that this dashboard does rely heavily on three prometheus exporter tools: node_exporter for system metrics, json_exporter for ETH price, and blackbox_exporter for ping times. The good news is that you don't need to use all these tools, as long as you take care of removing the related panels. See here for a detailed guide explaining how to use it. Enabling mobile alerts Telegram TODO","title":"Grafana and Prometheus"},{"location":"metrics-pretty-pictures.html#grafana-and-prometheus","text":"In this page we'll cover how to use Grafana and Prometheus to help you visualise important real-time metrics concerning your validator and/or beacon node. Prometheus is an open-source systems monitoring and alerting toolkit. It runs as a service on your computer and its job is to capture metrics. You can find more information about Prometheus here . Grafana is a tool for beautiful dashboard monitoring that works well with Prometheus. You can learn more about Grafana here .","title":"Grafana and Prometheus"},{"location":"metrics-pretty-pictures.html#simple-metrics","text":"To enable the metrics server, run the beacon node with the --metrics flag: ./run-prater-beacon-node.sh --metrics Visit http://127.0.0.1:8008/metrics with a browser or curl . You should see a plaintext page that looks something like this: # HELP nim_runtime_info Nim runtime info # TYPE nim_runtime_info gauge nim_gc_mem_bytes 6275072.0 nim_gc_mem_occupied_bytes 1881384.0 nim_gc_heap_instance_occupied_bytes{type_name=\"KeyValuePairSeq[digest.Eth2Digest, block_pools_types.BlockRef]\"} 25165856.0 nim_gc_heap_instance_occupied_bytes{type_name=\"BlockRef\"} 17284608.0 nim_gc_heap_instance_occupied_bytes{type_name=\"string\"} 6264507.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[SelectorKey[asyncdispatch.AsyncData]]\"} 409632.0 nim_gc_heap_instance_occupied_bytes{type_name=\"OrderedKeyValuePairSeq[Labels, seq[Metric]]\"} 122720.0 nim_gc_heap_instance_occupied_bytes{type_name=\"Future[system.void]\"} 79848.0 nim_gc_heap_instance_occupied_bytes{type_name=\"anon ref object from /Users/hackingresearch/nimbus/clone/nim-beacon-chain/vendor/nimbus-build-system/vendor/Nim/lib/pure/asyncmacro.nim(319, 33)\"} 65664.0 nim_gc_heap_instance_occupied_bytes{type_name=\"anon ref object from /Users/hackingresearch/nimbus/clone/nim-beacon-chain/vendor/nimbus-build-system/vendor/Nim/lib/pure/asyncnet.nim(506, 11)\"} 43776.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[byte]\"} 37236.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[TrustedAttestation]\"} 29728.0 ... Note: Metrics are by default only accessible from the same machine as the beacon node is running on - to fetch metrics from a remote machine, an SSH tunnel is recommended. The metrics server offers one snapshot in time of the state of the beacon node -- metrics however are at their most useful when collected over time -- for this, we'll need to set up two more pieces of software -- Prometheus and Grafana.","title":"Simple metrics"},{"location":"metrics-pretty-pictures.html#prometheus-and-grafana","text":"The following steps will take you through how to use Prometheus and Grafana to spin up a beautiful and useful monitoring dashboard for your validator and beacon node.","title":"Prometheus and Grafana"},{"location":"metrics-pretty-pictures.html#steps","text":"","title":"Steps"},{"location":"metrics-pretty-pictures.html#1-download-prometheus","text":"Use your favourite package manager to download Prometheus -- for example apt-get install prometheus on Ubuntu, or brew install prometheus on MacOS, should do the trick. If you don't use a package manager, you can download the latest release of directly from Prometheus website. To extract it, run: tar xvfz prometheus-*.tar.gz cd prometheus-*","title":"1. Download Prometheus"},{"location":"metrics-pretty-pictures.html#2-copy-the-binary","text":"The Prometheus server is a single binary called prometheus (or prometheus.exe on Microsoft Windows). Copy it over to /usr/local/bin cp prometheus-2.20.1.linux-amd64/prometheus /usr/local/bin/","title":"2. Copy the binary"},{"location":"metrics-pretty-pictures.html#3-run-prometheus-with-the-default-configuration-file","text":"Prometheus relies on a YAML configuration file to let it know where, and how often, to scrape data. Example config file: global: scrape_interval: 12s scrape_configs: - job_name: \"nimbus\" static_configs: - targets: ['127.0.0.1:8008'] Save the above as prometheus.yml in the nimbus-eth2 repo. Then run Prometheus: prometheus --config.file=./prometheus.yml --storage.tsdb.path=./prometheus You should see the following confirmation in the logs: level=info ts=2021-01-22T14:52:10.604Z caller=main.go:673 msg=\"Server is ready to receive web requests.\"","title":"3. Run Prometheus with the default configuration file"},{"location":"metrics-pretty-pictures.html#4-download-grafana","text":"Download the latest release of Grafana for your platform. You need version 7.2 or newer. Note: If you use a package manager, you can also download Grafana that way -- for example apt-get install grafana on Ubuntu, or brew install grafana on MacOS, should do the trick.","title":"4. Download Grafana"},{"location":"metrics-pretty-pictures.html#5-install-and-start-grafana","text":"Follow the instructions for your platform to install and start Grafana.","title":"5. Install and start Grafana"},{"location":"metrics-pretty-pictures.html#6-configure-login","text":"Go to http://localhost:3000/ , you should see a Grafana login screen that looks like this Type in admin for both the username and password. You'll be asked to change the password (we recommend you do so).","title":"6. Configure login"},{"location":"metrics-pretty-pictures.html#7-add-a-data-source","text":"Hover your mouse over the gear icon in the left menu bar, and click on the Data Sources option in the sub-menu that pops up. Now click on the Add Data Source button in the center of the screen Select Prometheus Enter http://localhost:9090 in the URL field Set the \"Scrape interval\" field to the same value you used in the Prometheus config (\"12\" in our example above). Scroll to the bottom and click on Save and Test If everything is working correctly you should see a green Data source is working box pop up","title":"7. Add a data source"},{"location":"metrics-pretty-pictures.html#8-import-a-dashboard","text":"Now, let's import a dashboard; hover your mouse over the + icon in the left menu bar and select import from the pop-up menu Click on Upload JSON file Select the beacon_nodes_Grafana_dashboard.json from the nimbus-eth2/grafana/ folder and click on Import You'll be directed to the dashboard where you'll be able to gain insights into the performance of nimbus-eth2 and your validators Note: the dashboard is very much a work in progress. Some of the highlights right now include received and proposed blocks, received and sent attestations, peers, memory and cpu usage stats. But keep an eye out for additional metrics in the near future. And voila! That's all there is to it :)","title":"8. Import a dashboard"},{"location":"metrics-pretty-pictures.html#community-dashboards","text":"","title":"Community dashboards"},{"location":"metrics-pretty-pictures.html#joe-clapis","text":"Joe \u2013 who\u2019s done some brilliant work integrating Nimbus with Rocket Pool \u2013 has created a wonderful guide where he takes you through how to set up a Grafana server on your Pi \u2013 using his dashboard as an example. In his words: This captures just about every metric I think I\u2019d like to see at a glance. Whether or not you're running a Pi, we recommend you check out his guide here .","title":"Joe Clapis"},{"location":"metrics-pretty-pictures.html#metanull","text":"A dashboard aimed primarily at users rather than developers. Note that this dashboard does rely heavily on three prometheus exporter tools: node_exporter for system metrics, json_exporter for ETH price, and blackbox_exporter for ping times. The good news is that you don't need to use all these tools, as long as you take care of removing the related panels. See here for a detailed guide explaining how to use it.","title":"Metanull"},{"location":"metrics-pretty-pictures.html#enabling-mobile-alerts","text":"","title":"Enabling mobile alerts"},{"location":"metrics-pretty-pictures.html#telegram","text":"TODO","title":"Telegram"},{"location":"migration-options.html","text":"Advanced client migration The main migration guide is located here . Here we document a couple of advanced options you can use if you wish to have more fine-grained control. Export validators The default command for exporting your slashing protection history is: build/nimbus_beacon_node slashingdb export database.json This will export your history in the correct format to database.json . On success you will have a message similar to: Exported slashing protection DB to 'database.json' Export finished: '$HOME/.cache/nimbus/BeaconNode/validators/slashing_protection.sqlite3' into 'interchange.json' Export from a specific validators directory The validator directory contains your validator's setup. build/nimbus_beacon_node slashingdb export database.json --validators-dir = path/to/validatorsdir/ Export from a specific data directory The data directory ( data-dir ) contains your beacon node setup. build/nimbus_beacon_node slashingdb export database.json --data-dir = path/to/datadir/ Partial exports You can perform a partial export by specifying the public key of the relevant validator you wish to export. build/nimbus_beacon_node slashingdb export database.json --validator = 0xb5da853a51d935da6f3bd46934c719fcca1bbf0b493264d3d9e7c35a1023b73c703b56d598edf0239663820af36ec615 If you wish to export multiple validators, you must specify the --validator option multiple times. Import validators The default command for importing your validator's slashing protection history into the database is: build/nimbus_beacon_node slashingdb import database.json Import to a specific validators directory The validator directory contains your validator's setup. build/nimbus_beacon_node slashingdb import database.json --validators-dir = path/to/validatorsdir/ Import to a specific data directory The data directory contains your beacon node's setup. build/nimbus_beacon_node slashingdb import database.json --data-dir = path/to/datadir/","title":"Advanced client migration"},{"location":"migration-options.html#advanced-client-migration","text":"The main migration guide is located here . Here we document a couple of advanced options you can use if you wish to have more fine-grained control.","title":"Advanced client migration"},{"location":"migration-options.html#export-validators","text":"The default command for exporting your slashing protection history is: build/nimbus_beacon_node slashingdb export database.json This will export your history in the correct format to database.json . On success you will have a message similar to: Exported slashing protection DB to 'database.json' Export finished: '$HOME/.cache/nimbus/BeaconNode/validators/slashing_protection.sqlite3' into 'interchange.json'","title":"Export validators"},{"location":"migration-options.html#export-from-a-specific-validators-directory","text":"The validator directory contains your validator's setup. build/nimbus_beacon_node slashingdb export database.json --validators-dir = path/to/validatorsdir/","title":"Export from a specific validators directory"},{"location":"migration-options.html#export-from-a-specific-data-directory","text":"The data directory ( data-dir ) contains your beacon node setup. build/nimbus_beacon_node slashingdb export database.json --data-dir = path/to/datadir/","title":"Export from a specific data directory"},{"location":"migration-options.html#partial-exports","text":"You can perform a partial export by specifying the public key of the relevant validator you wish to export. build/nimbus_beacon_node slashingdb export database.json --validator = 0xb5da853a51d935da6f3bd46934c719fcca1bbf0b493264d3d9e7c35a1023b73c703b56d598edf0239663820af36ec615 If you wish to export multiple validators, you must specify the --validator option multiple times.","title":"Partial exports"},{"location":"migration-options.html#import-validators","text":"The default command for importing your validator's slashing protection history into the database is: build/nimbus_beacon_node slashingdb import database.json","title":"Import validators"},{"location":"migration-options.html#import-to-a-specific-validators-directory","text":"The validator directory contains your validator's setup. build/nimbus_beacon_node slashingdb import database.json --validators-dir = path/to/validatorsdir/","title":"Import to a specific validators directory"},{"location":"migration-options.html#import-to-a-specific-data-directory","text":"The data directory contains your beacon node's setup. build/nimbus_beacon_node slashingdb import database.json --data-dir = path/to/datadir/","title":"Import to a specific data directory"},{"location":"migration.html","text":"Migrate from another client This guide will take you through the basics of how to migrate to Nimbus from another client. See here for advanced options . The main pain point involves the exporting and importing of the slashing protection database , since each client takes a slightly different approach here. Warning The most important takeaway is that you ensure that two clients will never validate with the same keys at the same time. In other words, you must ensure that your original client is stopped, and no longer validating, before importing your keys into Nimbus. Please take your time to get this right. Don't hesitate to reach out to us in the #helpdesk channel of our discord if you come across a stumbling block. We are more than happy to help guide you through the migration process. Given what's at stake, there is no such thing as a stupid question. Step 1 - Sync the Nimbus beacon node No matter which client you are migrating over from, the first step is to sync the Nimbus beacon node. The easiest way to do this is to follow the beacon node quick start guide . Syncing the beacon node might take up to 30 hours depending on your hardware - you should keep validating using your current setup until it completes. Once your Nimbus beacon node has synced and you're satisfied that it's working, move to Step 2 . Tip: See here for how to keep track of your syncing progress . Alternatively, If you run the Nimbus beacon node with the --rest option enabled (e.g. ./run-mainnet-beacon-node.sh --rest ), you can obtain your node's syncing status by running: curl -X GET http://localhost:5052/eth/v1/node/syncing Look for an \"is_syncing\":false in the response to confirm that your node has synced. Step 2 - Stop your existing client and export your slashing protection history Prysm Lighthouse Teku Nimbus 1. Disable the Prysm validator client Stop and disable the Prysm validator client (you can also stop the Prysm beacon node if you wish). If you're using systemd and your service is called prysmvalidator , run the following commands to stop and disable the service: sudo systemctl stop prysmvalidator.service sudo systemctl disable prysmvalidator.service It's important that you disable the Prysm validator as well as stopping it, to prevent it from starting up again on reboot. 2. Export slashing protection history Run the following to export your Prysm validator's slashing protection history: prysm.sh validator slashing-protection-history export \\ --datadir = /your/prysm/wallet \\ --slashing-protection-export-dir = /path/to/export_dir You will then find the slashing-protection.json file in your specified /path/to/export_dir folder. Tip To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check it's recent history on beaconcha.in ). Then go to step 3 . 1. Disable the Lighthouse validator client The validator client needs to be stopped in order to export, to guarantee that the data exported is up to date. If you're using systemd and your service is called lighthousevalidator , run the following command to stop and disable the service: sudo systemctl stop lighthousevalidator sudo systemctl disable lighthousevalidator You may also wish to stop the beacon node: sudo systemctl stop lighthousebeacon sudo systemctl disable lighthousebeacon It's important that you disable the service as well as stopping it, to prevent it from starting up again on reboot. 2. Export slashing protection history You can export Lighthouse's database with this command: lighthouse account validator slashing-protection export slashing-protection.json This will export your history in the correct format to slashing-protection.json . Tip To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check it's recent history on beaconcha.in ). Then go to step 3 . 1. Disable Teku If you're using systemd and your service is called teku , run the following command to stop and disable the service: sudo systemctl stop teku sudo systemctl disable teku It's important that you disable the service as well as stopping it, to prevent it from starting up again on reboot. 2. Export slashing protection history You can export Teku's database with this command: teku slashing-protection export --data-path = /home/me/me_node --to = /home/slash/slashing-protection.json Where: --data-path specifies the location of the Teku data directory. --to specifies the file to export the slashing-protection data to (in this case /home/slash/slashing-protection.json ). Tip To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check it's recent history on beaconcha.in ). Then go to step 3 . 1. Disable the Nimbus validator client Once your Nimbus beacon node on your new setup has synced and you're satisfied that it's working, stop and disable the Nimbus validator client on your current setup. If you're using systemd and your service is called nimbus-eth2-mainnet , run the following commands to stop and disable the service: sudo systemctl stop nimbus-eth2-mainnet.service sudo systemctl disable nimbus-eth2-mainnet.service It's important that you disable the service as well as stopping it, to prevent it from starting up again on reboot. 2. Export slashing protection history Run the following to export your Nimbus validator's slashing protection history: build/nimbus_beacon_node slashingdb export slashing-protection.json This will export your history in the correct format to slashing-protection.json . Tip: To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check it's recent history on beaconcha.in ). Then go to step 3 . Step 3 - Import your validator key(s) into Nimbus To import you validator key(s), follow the instructions outlined here . To check that your key(s) has been successfully imported, look for a file named after your public key in build/data/shared_mainet_0/secrets/ . If you run into an error at this stage, it's probably because the wrong permissions have been set on either a folder or file. See here for how to fix this. Step 4 - Import your slashing protection history To import the slashing protection history you exported in step 2 , from the nimbus-eth2 directory run: build/nimbus_beacon_node slashingdb import path/to/export_dir/slashing-protection.json Replacing /path/to/export_dir with the file/directory you specified when you exported your slashing protection history. Step 5 - Start the Nimbus validator Follow the instructions here to start your validator using our pre-built binaries . If you prefer to use Docker, see here For a quick guide on how to set up a systemd service, see here Final thoughts If you are unsure of the safety of a step, please get in touch with us directly on discord . Additionally, we recommend testing the migration works correctly on a testnet before going ahead on mainnet.","title":"Migrate from another client"},{"location":"migration.html#migrate-from-another-client","text":"This guide will take you through the basics of how to migrate to Nimbus from another client. See here for advanced options . The main pain point involves the exporting and importing of the slashing protection database , since each client takes a slightly different approach here. Warning The most important takeaway is that you ensure that two clients will never validate with the same keys at the same time. In other words, you must ensure that your original client is stopped, and no longer validating, before importing your keys into Nimbus. Please take your time to get this right. Don't hesitate to reach out to us in the #helpdesk channel of our discord if you come across a stumbling block. We are more than happy to help guide you through the migration process. Given what's at stake, there is no such thing as a stupid question.","title":"Migrate from another client"},{"location":"migration.html#step-1-sync-the-nimbus-beacon-node","text":"No matter which client you are migrating over from, the first step is to sync the Nimbus beacon node. The easiest way to do this is to follow the beacon node quick start guide . Syncing the beacon node might take up to 30 hours depending on your hardware - you should keep validating using your current setup until it completes. Once your Nimbus beacon node has synced and you're satisfied that it's working, move to Step 2 . Tip: See here for how to keep track of your syncing progress . Alternatively, If you run the Nimbus beacon node with the --rest option enabled (e.g. ./run-mainnet-beacon-node.sh --rest ), you can obtain your node's syncing status by running: curl -X GET http://localhost:5052/eth/v1/node/syncing Look for an \"is_syncing\":false in the response to confirm that your node has synced.","title":"Step 1 - Sync the Nimbus beacon node"},{"location":"migration.html#step-2-stop-your-existing-client-and-export-your-slashing-protection-history","text":"Prysm Lighthouse Teku Nimbus","title":"Step 2 - Stop your existing client and export your slashing protection history"},{"location":"migration.html#1-disable-the-prysm-validator-client","text":"Stop and disable the Prysm validator client (you can also stop the Prysm beacon node if you wish). If you're using systemd and your service is called prysmvalidator , run the following commands to stop and disable the service: sudo systemctl stop prysmvalidator.service sudo systemctl disable prysmvalidator.service It's important that you disable the Prysm validator as well as stopping it, to prevent it from starting up again on reboot.","title":"1. Disable the Prysm validator client"},{"location":"migration.html#2-export-slashing-protection-history","text":"Run the following to export your Prysm validator's slashing protection history: prysm.sh validator slashing-protection-history export \\ --datadir = /your/prysm/wallet \\ --slashing-protection-export-dir = /path/to/export_dir You will then find the slashing-protection.json file in your specified /path/to/export_dir folder. Tip To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check it's recent history on beaconcha.in ). Then go to step 3 .","title":"2. Export slashing protection history"},{"location":"migration.html#1-disable-the-lighthouse-validator-client","text":"The validator client needs to be stopped in order to export, to guarantee that the data exported is up to date. If you're using systemd and your service is called lighthousevalidator , run the following command to stop and disable the service: sudo systemctl stop lighthousevalidator sudo systemctl disable lighthousevalidator You may also wish to stop the beacon node: sudo systemctl stop lighthousebeacon sudo systemctl disable lighthousebeacon It's important that you disable the service as well as stopping it, to prevent it from starting up again on reboot.","title":"1. Disable the Lighthouse validator client"},{"location":"migration.html#2-export-slashing-protection-history_1","text":"You can export Lighthouse's database with this command: lighthouse account validator slashing-protection export slashing-protection.json This will export your history in the correct format to slashing-protection.json . Tip To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check it's recent history on beaconcha.in ). Then go to step 3 .","title":"2. Export slashing protection history"},{"location":"migration.html#1-disable-teku","text":"If you're using systemd and your service is called teku , run the following command to stop and disable the service: sudo systemctl stop teku sudo systemctl disable teku It's important that you disable the service as well as stopping it, to prevent it from starting up again on reboot.","title":"1. Disable Teku"},{"location":"migration.html#2-export-slashing-protection-history_2","text":"You can export Teku's database with this command: teku slashing-protection export --data-path = /home/me/me_node --to = /home/slash/slashing-protection.json Where: --data-path specifies the location of the Teku data directory. --to specifies the file to export the slashing-protection data to (in this case /home/slash/slashing-protection.json ). Tip To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check it's recent history on beaconcha.in ). Then go to step 3 .","title":"2. Export slashing protection history"},{"location":"migration.html#1-disable-the-nimbus-validator-client","text":"Once your Nimbus beacon node on your new setup has synced and you're satisfied that it's working, stop and disable the Nimbus validator client on your current setup. If you're using systemd and your service is called nimbus-eth2-mainnet , run the following commands to stop and disable the service: sudo systemctl stop nimbus-eth2-mainnet.service sudo systemctl disable nimbus-eth2-mainnet.service It's important that you disable the service as well as stopping it, to prevent it from starting up again on reboot.","title":"1. Disable the Nimbus validator client"},{"location":"migration.html#2-export-slashing-protection-history_3","text":"Run the following to export your Nimbus validator's slashing protection history: build/nimbus_beacon_node slashingdb export slashing-protection.json This will export your history in the correct format to slashing-protection.json . Tip: To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check it's recent history on beaconcha.in ). Then go to step 3 .","title":"2. Export slashing protection history"},{"location":"migration.html#step-3-import-your-validator-keys-into-nimbus","text":"To import you validator key(s), follow the instructions outlined here . To check that your key(s) has been successfully imported, look for a file named after your public key in build/data/shared_mainet_0/secrets/ . If you run into an error at this stage, it's probably because the wrong permissions have been set on either a folder or file. See here for how to fix this.","title":"Step 3 - Import your validator key(s) into Nimbus"},{"location":"migration.html#step-4-import-your-slashing-protection-history","text":"To import the slashing protection history you exported in step 2 , from the nimbus-eth2 directory run: build/nimbus_beacon_node slashingdb import path/to/export_dir/slashing-protection.json Replacing /path/to/export_dir with the file/directory you specified when you exported your slashing protection history.","title":"Step 4 - Import your slashing protection history"},{"location":"migration.html#step-5-start-the-nimbus-validator","text":"Follow the instructions here to start your validator using our pre-built binaries . If you prefer to use Docker, see here For a quick guide on how to set up a systemd service, see here","title":"Step 5 - Start the Nimbus validator"},{"location":"migration.html#final-thoughts","text":"If you are unsure of the safety of a step, please get in touch with us directly on discord . Additionally, we recommend testing the migration works correctly on a testnet before going ahead on mainnet.","title":"Final thoughts"},{"location":"more-keys.html","text":"Recover lost keys and generate new ones When generating your first deposit you will be asked to save a mnemonic in a safe location. This mnemonic can be used to recover lost keys and generate new ones. Every time you generate a keystore from your mnemomic, that keystore is assigned an index. The first keystore you generate has index 0, the second index 1, etc. You can recover any key using your mnemonic and that key's index. For more on how keys are derived, see this excellent post . To stay consistent with the rest of the book, we'll take you though how to do this using the deposit-cli's binary executable . Specifically, we'll be using the existing-mnemonic command. Here's a description of the command from the deposit-cli's README : This command is used to re-generate or derive new keys from your existing mnemonic. Use this command, if (i) you have already generated keys with this CLI before, (ii) you want to reuse your mnemonic that you know is secure that you generated elsewhere (reusing your eth1 mnemonic .etc), or (iii) you lost your keystores and need to recover your keys. Recover existing key Warning Recovering validator keys from a mnemonic should only be used as a last resort. Exposing your mnemonic to a computer at any time puts it at risk of being compromised. Your mnemonic is not encrypted and if leaked, can be used to steal your funds. Note The commands below assume you are trying to recover the first key you created, hence --validator_start_index has been set to 0 . Run the following command from the directory which contains the deposit executable: Mainnet Prater ./deposit existing-mnemonic \\ --validator_start_index 0 \\ --num_validators 1 \\ --chain mainnet ./deposit existing-mnemonic \\ --validator_start_index 0 \\ --num_validators 1 \\ --chain prater You'll be prompted to enter your mnemonic, and a new password for your keystore. Check that the validator_keys directory contains your keystore. Copy the validator_keys directory to nimbus-eth2 and then follow the instructions here . Your key will be added to your node on next restart. Generate another key Warning If you wish to use your new key with a separate client instance, make sure not to include your first key in the second setup - doing so will lead to it being slashed! Note The commands below assume you already have one key and wish to generate a second, hence --validator_start_index has been set to 1 (as 0 would be the original key) Run the following command from the directory which contains the deposit executable: Mainnet Prater ./deposit existing-mnemonic \\ --validator_start_index 1 \\ --num_validators 1 \\ --chain mainnet ./deposit existing-mnemonic \\ --validator_start_index 1 \\ --num_validators 1 \\ --chain prater You'll be prompted to enter your mnemonic, and a new password for your keystore. Check that the validator_keys directory contains an extra keystore. Copy the validator_keys directory to nimbus-eth2 . Make sure you've made a deposit for your new keystore, and then follow the instructions here . Your key will be added to your node on next restart.","title":"Recover lost keys and generate new ones"},{"location":"more-keys.html#recover-lost-keys-and-generate-new-ones","text":"When generating your first deposit you will be asked to save a mnemonic in a safe location. This mnemonic can be used to recover lost keys and generate new ones. Every time you generate a keystore from your mnemomic, that keystore is assigned an index. The first keystore you generate has index 0, the second index 1, etc. You can recover any key using your mnemonic and that key's index. For more on how keys are derived, see this excellent post . To stay consistent with the rest of the book, we'll take you though how to do this using the deposit-cli's binary executable . Specifically, we'll be using the existing-mnemonic command. Here's a description of the command from the deposit-cli's README : This command is used to re-generate or derive new keys from your existing mnemonic. Use this command, if (i) you have already generated keys with this CLI before, (ii) you want to reuse your mnemonic that you know is secure that you generated elsewhere (reusing your eth1 mnemonic .etc), or (iii) you lost your keystores and need to recover your keys.","title":"Recover lost keys and generate new ones"},{"location":"more-keys.html#recover-existing-key","text":"Warning Recovering validator keys from a mnemonic should only be used as a last resort. Exposing your mnemonic to a computer at any time puts it at risk of being compromised. Your mnemonic is not encrypted and if leaked, can be used to steal your funds. Note The commands below assume you are trying to recover the first key you created, hence --validator_start_index has been set to 0 . Run the following command from the directory which contains the deposit executable: Mainnet Prater ./deposit existing-mnemonic \\ --validator_start_index 0 \\ --num_validators 1 \\ --chain mainnet ./deposit existing-mnemonic \\ --validator_start_index 0 \\ --num_validators 1 \\ --chain prater You'll be prompted to enter your mnemonic, and a new password for your keystore. Check that the validator_keys directory contains your keystore. Copy the validator_keys directory to nimbus-eth2 and then follow the instructions here . Your key will be added to your node on next restart.","title":"Recover existing key"},{"location":"more-keys.html#generate-another-key","text":"Warning If you wish to use your new key with a separate client instance, make sure not to include your first key in the second setup - doing so will lead to it being slashed! Note The commands below assume you already have one key and wish to generate a second, hence --validator_start_index has been set to 1 (as 0 would be the original key) Run the following command from the directory which contains the deposit executable: Mainnet Prater ./deposit existing-mnemonic \\ --validator_start_index 1 \\ --num_validators 1 \\ --chain mainnet ./deposit existing-mnemonic \\ --validator_start_index 1 \\ --num_validators 1 \\ --chain prater You'll be prompted to enter your mnemonic, and a new password for your keystore. Check that the validator_keys directory contains an extra keystore. Copy the validator_keys directory to nimbus-eth2 . Make sure you've made a deposit for your new keystore, and then follow the instructions here . Your key will be added to your node on next restart.","title":"Generate another key"},{"location":"networking.html","text":"Networking options Nimbus will automatically connect to peers based on the health and quality of peers that it's already connected to. Depending on the network and the number of validators attached to the node, Nimbus may need anywhere from 10 to 60 peers connected to operate well. In addition to making outgoing connections, the beacon node node works best when others can connect to it - this speeds up the process of finding good peers. To allow incoming connections, the node must be reachable via a public IP address. It must also be aware of this address, so that it can advertise it to its peers. UPnP By default, Nimbus uses UPnP to set up port forwarding and detect your external IP address. If you do not have UPnP enabled, you may need to pass additional command-line options to the node, as explained in subsequent sections. Enabling UPnP is usually as simple as checking a box in your router's configuration. Unless it's a FRITZ!Box router, that is. With this brand, you will also need to edit individual connections - in \"Home Network\" -> \"Network\" -> edit icon -> \"Permit independent port sharing for this device\". You might also want to enable \"Always assign this network device the same IPv4 address\", in case the setting is associated with IPs instead of MACs. Monitor your Peer count Note: As of v1.7.0 , peer scoring has been fine-tuned. As such --max-peers should not be set below 70. Note that Lowering max-peers does not significantly improve bandwidth usage, but does increase the risk of missed attestations. If your Peer count is low (less than 15 ) and/or you repeatedly see either of the following warnings: Peer count low, no new peers discovered... or No peers for topic, skipping publish... It means that Nimbus is unable to find a sufficient number of peers to guarantee stable operation, and you may miss attestations and blocks as a result. Most commonly, this happens when your computer is not reachable from the outside and therefore won't be able to accept any incoming peer connections. If you're on a home network, the fix here is to set up port forwarding (this may require you to pass the extip option and set enr-auto-update ). The first step however, is to check for incoming connections. Check for incoming connections To check if you have incoming connections set, run: curl -s http://localhost:8008/metrics | grep libp2p_open_streams In the output, look for a line that looks like: libp2p_open_streams{type=\"ChronosStream\",dir=\"in\"} If there are no dir=in ChronosStreams , incoming connections are not working. N.B you need to run the client with the --metrics option enabled in order for this to work Pass the extip option If you have a static public IP address, use the --nat:extip:$EXT_IP_ADDRESS option to pass it to the client, where $EXT_IP_ADDRESS is your public IP (see here for how to determine your public IP address). For example, if your public IP address is 1.2.3.4 , you'd run: ./run-prater-beacon-node.sh --nat:extip:1.2.3.4 Note that this should also work with a dynamic IP address. But you will probably also need to pass enr-auto-update as an option to the client. Set ENR auto update The --enr-auto-update feature keeps your external IP address up to date based on information received from other peers on the network. This option is useful with ISPs that assign IP addresses dynamically. In practice this means relaunching the beacon node with --enr-auto-update:true (pass it as an option in the command line). Set up port forwarding If you're running on a home network and want to ensure you are able to receive incoming connections you may need to set up port forwarding (though some routers automagically set this up for you). Note: If you are running your node on a virtual public server (VPS) instance, you can safely ignore this section. While the specific steps required vary based on your router, they can be summarised as follows: Determine your public IP address Determine your private IP address Browse to the management website for your home router ( http://192.168.1.1 for most routers, https://192.168.178.1 for FRITZ!Box) Log in as admin Find the section to configure port forwarding Configure a port forwarding rule with the following values: External port: 9000 Internal port: 9000 Protocol: TCP IP Address: Private IP address of the computer running Nimbus Configure a second port forwarding rule with the following values: External port: 9000 Internal port: 9000 Protocol: UDP IP Address: Private IP address of the computer running Nimbus Determine your public IP address To determine your public IP address, visit http://v4.ident.me/ or run this command: curl v4.ident.me Determine your private IP address To determine your private IP address, run the appropriate command for your OS: Linux: ip addr show | grep \"inet \" | grep -v 127.0.0.1 Windows: ipconfig | findstr /i \"IPv4 Address\" macOS: ifconfig | grep \"inet \" | grep -v 127.0.0.1 Check open ports on your connection Use this tool to check your external (public) IP address and detect open ports on your connection (Nimbus TCP and UDP ports are both set to 9000 by default). Reading the logs No peers for topic, skipping publish... This is printed when the client lacks quality peers to publish attestations to - this is the most important indication that the node is having trouble keeping up. If you see this, you are missing attestations. Peer count low, no new peers discovered... This is a sign that you may be missing attestations. No external IP provided for the ENR... This message basically means that the software did not manage to find a public IP address (by either looking at your routed interface IP address, and/or by attempting to get it from your gateway through UPnP or NAT-PMP). Discovered new external address but ENR auto update is off... It's possible that your ISP has changed your IP address without you knowing. The first thing to do it to try relaunching the beacon node with with --enr-auto-update:true (pass it as an option in the command line). If this doesn't fix the problem, the next thing to do is to check your external (public) IP address and detect open ports on your connection - you can use this site . Note that Nimbus TCP and UDP ports are both set to 9000 by default. See above for how to set up port forwarding.","title":"Networking options"},{"location":"networking.html#networking-options","text":"Nimbus will automatically connect to peers based on the health and quality of peers that it's already connected to. Depending on the network and the number of validators attached to the node, Nimbus may need anywhere from 10 to 60 peers connected to operate well. In addition to making outgoing connections, the beacon node node works best when others can connect to it - this speeds up the process of finding good peers. To allow incoming connections, the node must be reachable via a public IP address. It must also be aware of this address, so that it can advertise it to its peers.","title":"Networking options"},{"location":"networking.html#upnp","text":"By default, Nimbus uses UPnP to set up port forwarding and detect your external IP address. If you do not have UPnP enabled, you may need to pass additional command-line options to the node, as explained in subsequent sections. Enabling UPnP is usually as simple as checking a box in your router's configuration. Unless it's a FRITZ!Box router, that is. With this brand, you will also need to edit individual connections - in \"Home Network\" -> \"Network\" -> edit icon -> \"Permit independent port sharing for this device\". You might also want to enable \"Always assign this network device the same IPv4 address\", in case the setting is associated with IPs instead of MACs.","title":"UPnP"},{"location":"networking.html#monitor-your-peer-count","text":"Note: As of v1.7.0 , peer scoring has been fine-tuned. As such --max-peers should not be set below 70. Note that Lowering max-peers does not significantly improve bandwidth usage, but does increase the risk of missed attestations. If your Peer count is low (less than 15 ) and/or you repeatedly see either of the following warnings: Peer count low, no new peers discovered... or No peers for topic, skipping publish... It means that Nimbus is unable to find a sufficient number of peers to guarantee stable operation, and you may miss attestations and blocks as a result. Most commonly, this happens when your computer is not reachable from the outside and therefore won't be able to accept any incoming peer connections. If you're on a home network, the fix here is to set up port forwarding (this may require you to pass the extip option and set enr-auto-update ). The first step however, is to check for incoming connections.","title":"Monitor your Peer count"},{"location":"networking.html#check-for-incoming-connections","text":"To check if you have incoming connections set, run: curl -s http://localhost:8008/metrics | grep libp2p_open_streams In the output, look for a line that looks like: libp2p_open_streams{type=\"ChronosStream\",dir=\"in\"} If there are no dir=in ChronosStreams , incoming connections are not working. N.B you need to run the client with the --metrics option enabled in order for this to work","title":"Check for incoming connections"},{"location":"networking.html#pass-the-extip-option","text":"If you have a static public IP address, use the --nat:extip:$EXT_IP_ADDRESS option to pass it to the client, where $EXT_IP_ADDRESS is your public IP (see here for how to determine your public IP address). For example, if your public IP address is 1.2.3.4 , you'd run: ./run-prater-beacon-node.sh --nat:extip:1.2.3.4 Note that this should also work with a dynamic IP address. But you will probably also need to pass enr-auto-update as an option to the client.","title":"Pass the extip option"},{"location":"networking.html#set-enr-auto-update","text":"The --enr-auto-update feature keeps your external IP address up to date based on information received from other peers on the network. This option is useful with ISPs that assign IP addresses dynamically. In practice this means relaunching the beacon node with --enr-auto-update:true (pass it as an option in the command line).","title":"Set ENR auto update"},{"location":"networking.html#set-up-port-forwarding","text":"If you're running on a home network and want to ensure you are able to receive incoming connections you may need to set up port forwarding (though some routers automagically set this up for you). Note: If you are running your node on a virtual public server (VPS) instance, you can safely ignore this section. While the specific steps required vary based on your router, they can be summarised as follows: Determine your public IP address Determine your private IP address Browse to the management website for your home router ( http://192.168.1.1 for most routers, https://192.168.178.1 for FRITZ!Box) Log in as admin Find the section to configure port forwarding Configure a port forwarding rule with the following values: External port: 9000 Internal port: 9000 Protocol: TCP IP Address: Private IP address of the computer running Nimbus Configure a second port forwarding rule with the following values: External port: 9000 Internal port: 9000 Protocol: UDP IP Address: Private IP address of the computer running Nimbus","title":"Set up port forwarding"},{"location":"networking.html#determine-your-public-ip-address","text":"To determine your public IP address, visit http://v4.ident.me/ or run this command: curl v4.ident.me","title":"Determine your public IP address"},{"location":"networking.html#determine-your-private-ip-address","text":"To determine your private IP address, run the appropriate command for your OS: Linux: ip addr show | grep \"inet \" | grep -v 127.0.0.1 Windows: ipconfig | findstr /i \"IPv4 Address\" macOS: ifconfig | grep \"inet \" | grep -v 127.0.0.1","title":"Determine your private IP address"},{"location":"networking.html#check-open-ports-on-your-connection","text":"Use this tool to check your external (public) IP address and detect open ports on your connection (Nimbus TCP and UDP ports are both set to 9000 by default).","title":"Check open ports on your connection"},{"location":"networking.html#reading-the-logs","text":"No peers for topic, skipping publish... This is printed when the client lacks quality peers to publish attestations to - this is the most important indication that the node is having trouble keeping up. If you see this, you are missing attestations. Peer count low, no new peers discovered... This is a sign that you may be missing attestations. No external IP provided for the ENR... This message basically means that the software did not manage to find a public IP address (by either looking at your routed interface IP address, and/or by attempting to get it from your gateway through UPnP or NAT-PMP). Discovered new external address but ENR auto update is off... It's possible that your ISP has changed your IP address without you knowing. The first thing to do it to try relaunching the beacon node with with --enr-auto-update:true (pass it as an option in the command line). If this doesn't fix the problem, the next thing to do is to check your external (public) IP address and detect open ports on your connection - you can use this site . Note that Nimbus TCP and UDP ports are both set to 9000 by default. See above for how to set up port forwarding.","title":"Reading the logs"},{"location":"options.html","text":"Command line options Command line options allow you to customize the way your beacon node operates. You pass options to the beacon node by adding them to the command line. For example, if you want to launch Nimbus on mainnet with different base ports than the default 9000/udp and 9000/tcp , say 9100/udp and 9100/tcp , run: ./run-mainnet-beacon-node.sh --tcp-port = 9100 --udp-port = 9100 Available options To see the full list of command line options availabe to you, with descriptions, run: build/nimbus_beacon_node --help You should see the following output: Usage: nimbus_beacon_node [OPTIONS]... command The following options are available: --config-file Loads the configuration from a TOML file. --log-level Sets the log level for process and topics (e.g. \"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\") [=INFO]. --log-file Specifies a path for the written Json log file (deprecated). --network The Eth2 network to join [=mainnet]. -d, --data-dir The directory where nimbus will store all blockchain data. --validators-dir A directory containing validator keystores. --secrets-dir A directory containing validator keystore passwords. --wallets-dir A directory containing wallet files. --web3-url One or more Web3 provider URLs used for obtaining deposit contract data. --non-interactive Do not display interative prompts. Quit on missing configuration. --netkey-file Source of network (secp256k1) private key file (random|<path>) [=random]. --insecure-netkey-password Use pre-generated INSECURE password for network private key file [=false]. --agent-string Node agent string which is used as identifier in network [=nimbus]. --subscribe-all-subnets Subscribe to all subnet topics when gossiping [=false]. --num-threads Number of worker threads (\"0\" = use as many threads as there are CPU cores available) [=0]. -b, --bootstrap-node Specifies one or more bootstrap nodes to use when connecting to the network. --bootstrap-file Specifies a line-delimited file of bootstrap Ethereum network addresses. --listen-address Listening address for the Ethereum LibP2P and Discovery v5 traffic [=0.0.0.0]. --tcp-port Listening TCP port for Ethereum LibP2P traffic [=9000]. --udp-port Listening UDP port for node discovery [=9000]. --max-peers The maximum number of peers to connect to [=160]. --nat Specify method to use for determining public address. Must be one of: any, none, upnp, pmp, extip:<IP> [=any]. --enr-auto-update Discovery can automatically update its ENR with the IP address and UDP port as seen by other nodes it communicates with. This option allows to enable/disable this functionality [=false]. --weak-subjectivity-checkpoint Weak subjectivity checkpoint in the format block_root:epoch_number. --finalized-checkpoint-state SSZ file specifying a recent finalized state. --finalized-checkpoint-block SSZ file specifying a recent finalized block. --node-name A name for this node that will appear in the logs. If you set this to 'auto', a persistent automatically generated ID will be selected for each --data-dir folder. --graffiti The graffiti value that will appear in proposed blocks. You can use a 0x-prefixed hex encoded string to specify raw bytes. --metrics Enable the metrics server [=false]. --metrics-address Listening address of the metrics server [=127.0.0.1]. --metrics-port Listening HTTP port of the metrics server [=8008]. --status-bar Display a status bar at the bottom of the terminal screen [=true]. --status-bar-contents Textual template for the contents of the status bar. --rest Enable the REST server [=false]. --rest-port Port for the REST server [=5052]. --rest-address Listening address of the REST server [=127.0.0.1]. --rest-allow-origin Limit the access to the REST API to a particular hostname (for CORS-enabled clients such as browsers). --rest-statecache-size The maximum number of recently accessed states that are kept in memory. Speeds up requests obtaining information for consecutive slots or epochs. [=3]. --rest-statecache-ttl The number of seconds to keep recently accessed states in memory [=60]. --rest-request-timeout The number of seconds to wait until complete REST request will be received [=infinite]. --rest-max-body-size Maximum size of REST request body (kilobytes) [=16384]. --rest-max-headers-size Maximum size of REST request headers (kilobytes) [=64]. --keymanager Enable the REST keymanager API (BETA version) [=false]. --keymanager-port Listening port for the REST keymanager API [=5052]. --keymanager-address Listening port for the REST keymanager API [=127.0.0.1]. --keymanager-allow-origin Limit the access to the Keymanager API to a particular hostname (for CORS-enabled clients such as browsers). --keymanager-token-file A file specifying the authorization token required for accessing the keymanager API. --in-process-validators Disable the push model (the beacon node tells a signing process with the private keys of the validators what to sign and when) and load the validators in the beacon node itself [=true]. --discv5 Enable Discovery v5 [=true]. --dump Write SSZ dumps of blocks, attestations and states to data dir [=false]. --direct-peer The list of priviledged, secure and known peers to connect and maintain the connection to, this requires a not random netkey-file. In the complete multiaddress format like: /ip4/<address>/tcp/<port>/p2p/<peerId-public-key>. Peering agreements are established out of band and must be reciprocal.. --doppelganger-detection If enabled, the beacon node prudently listens for 2 epochs for attestations from a validator with the same index (a doppelganger), before sending an attestation itself. This protects against slashing (due to double-voting) but means you will miss two attestations when restarting. [=true]. --validator-monitor-auto Automatically monitor locally active validators (BETA) [=false]. --validator-monitor-pubkey One or more validators to monitor - works best when --subscribe-all-subnets is enabled (BETA). --validator-monitor-totals Publish metrics to single 'totals' label for better collection performance when monitoring many validators (BETA) [=false]. ... Configuration files All command line options can also be provided in a TOML config file specified through the --config-file flag. Within the config file, you need to use the long names of all options. Please note that certain options such as web3-url , bootstrap-node , direct-peer , and validator-monitor-pubkey can be supplied more than once on the command line - in the TOML file, you need to supply them as arrays. There are also some minor differences in the parsing of certain option values in the TOML files in order to conform more closely to existing TOML standards. For example, you can freely use keywords such as on , off , yes and no on the command-line as synonyms for the canonical values true and false which are mandatory to use in TOML. Options affecting Nimbus sub-commands should appear in a section of the file matching the sub-command name. Here is an example config file illustrating all of the above: nimbus-eth2.toml # Comments look like this doppelganger-detection = true web3-url = [ \"ws://192.168.1.10:8000\" ] num-threads = 0 [trustedNodeSync] trusted-node-url = \"http://192.168.1.20:5052\" Exit Codes Exit code Description 0 Successful exit 1 Generic failure or unspecified error 1031 Doppelganger detection; one might prefer not to restart automatically","title":"Command line options"},{"location":"options.html#command-line-options","text":"Command line options allow you to customize the way your beacon node operates. You pass options to the beacon node by adding them to the command line. For example, if you want to launch Nimbus on mainnet with different base ports than the default 9000/udp and 9000/tcp , say 9100/udp and 9100/tcp , run: ./run-mainnet-beacon-node.sh --tcp-port = 9100 --udp-port = 9100","title":"Command line options"},{"location":"options.html#available-options","text":"To see the full list of command line options availabe to you, with descriptions, run: build/nimbus_beacon_node --help You should see the following output: Usage: nimbus_beacon_node [OPTIONS]... command The following options are available: --config-file Loads the configuration from a TOML file. --log-level Sets the log level for process and topics (e.g. \"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\") [=INFO]. --log-file Specifies a path for the written Json log file (deprecated). --network The Eth2 network to join [=mainnet]. -d, --data-dir The directory where nimbus will store all blockchain data. --validators-dir A directory containing validator keystores. --secrets-dir A directory containing validator keystore passwords. --wallets-dir A directory containing wallet files. --web3-url One or more Web3 provider URLs used for obtaining deposit contract data. --non-interactive Do not display interative prompts. Quit on missing configuration. --netkey-file Source of network (secp256k1) private key file (random|<path>) [=random]. --insecure-netkey-password Use pre-generated INSECURE password for network private key file [=false]. --agent-string Node agent string which is used as identifier in network [=nimbus]. --subscribe-all-subnets Subscribe to all subnet topics when gossiping [=false]. --num-threads Number of worker threads (\"0\" = use as many threads as there are CPU cores available) [=0]. -b, --bootstrap-node Specifies one or more bootstrap nodes to use when connecting to the network. --bootstrap-file Specifies a line-delimited file of bootstrap Ethereum network addresses. --listen-address Listening address for the Ethereum LibP2P and Discovery v5 traffic [=0.0.0.0]. --tcp-port Listening TCP port for Ethereum LibP2P traffic [=9000]. --udp-port Listening UDP port for node discovery [=9000]. --max-peers The maximum number of peers to connect to [=160]. --nat Specify method to use for determining public address. Must be one of: any, none, upnp, pmp, extip:<IP> [=any]. --enr-auto-update Discovery can automatically update its ENR with the IP address and UDP port as seen by other nodes it communicates with. This option allows to enable/disable this functionality [=false]. --weak-subjectivity-checkpoint Weak subjectivity checkpoint in the format block_root:epoch_number. --finalized-checkpoint-state SSZ file specifying a recent finalized state. --finalized-checkpoint-block SSZ file specifying a recent finalized block. --node-name A name for this node that will appear in the logs. If you set this to 'auto', a persistent automatically generated ID will be selected for each --data-dir folder. --graffiti The graffiti value that will appear in proposed blocks. You can use a 0x-prefixed hex encoded string to specify raw bytes. --metrics Enable the metrics server [=false]. --metrics-address Listening address of the metrics server [=127.0.0.1]. --metrics-port Listening HTTP port of the metrics server [=8008]. --status-bar Display a status bar at the bottom of the terminal screen [=true]. --status-bar-contents Textual template for the contents of the status bar. --rest Enable the REST server [=false]. --rest-port Port for the REST server [=5052]. --rest-address Listening address of the REST server [=127.0.0.1]. --rest-allow-origin Limit the access to the REST API to a particular hostname (for CORS-enabled clients such as browsers). --rest-statecache-size The maximum number of recently accessed states that are kept in memory. Speeds up requests obtaining information for consecutive slots or epochs. [=3]. --rest-statecache-ttl The number of seconds to keep recently accessed states in memory [=60]. --rest-request-timeout The number of seconds to wait until complete REST request will be received [=infinite]. --rest-max-body-size Maximum size of REST request body (kilobytes) [=16384]. --rest-max-headers-size Maximum size of REST request headers (kilobytes) [=64]. --keymanager Enable the REST keymanager API (BETA version) [=false]. --keymanager-port Listening port for the REST keymanager API [=5052]. --keymanager-address Listening port for the REST keymanager API [=127.0.0.1]. --keymanager-allow-origin Limit the access to the Keymanager API to a particular hostname (for CORS-enabled clients such as browsers). --keymanager-token-file A file specifying the authorization token required for accessing the keymanager API. --in-process-validators Disable the push model (the beacon node tells a signing process with the private keys of the validators what to sign and when) and load the validators in the beacon node itself [=true]. --discv5 Enable Discovery v5 [=true]. --dump Write SSZ dumps of blocks, attestations and states to data dir [=false]. --direct-peer The list of priviledged, secure and known peers to connect and maintain the connection to, this requires a not random netkey-file. In the complete multiaddress format like: /ip4/<address>/tcp/<port>/p2p/<peerId-public-key>. Peering agreements are established out of band and must be reciprocal.. --doppelganger-detection If enabled, the beacon node prudently listens for 2 epochs for attestations from a validator with the same index (a doppelganger), before sending an attestation itself. This protects against slashing (due to double-voting) but means you will miss two attestations when restarting. [=true]. --validator-monitor-auto Automatically monitor locally active validators (BETA) [=false]. --validator-monitor-pubkey One or more validators to monitor - works best when --subscribe-all-subnets is enabled (BETA). --validator-monitor-totals Publish metrics to single 'totals' label for better collection performance when monitoring many validators (BETA) [=false]. ...","title":"Available options"},{"location":"options.html#configuration-files","text":"All command line options can also be provided in a TOML config file specified through the --config-file flag. Within the config file, you need to use the long names of all options. Please note that certain options such as web3-url , bootstrap-node , direct-peer , and validator-monitor-pubkey can be supplied more than once on the command line - in the TOML file, you need to supply them as arrays. There are also some minor differences in the parsing of certain option values in the TOML files in order to conform more closely to existing TOML standards. For example, you can freely use keywords such as on , off , yes and no on the command-line as synonyms for the canonical values true and false which are mandatory to use in TOML. Options affecting Nimbus sub-commands should appear in a section of the file matching the sub-command name. Here is an example config file illustrating all of the above: nimbus-eth2.toml # Comments look like this doppelganger-detection = true web3-url = [ \"ws://192.168.1.10:8000\" ] num-threads = 0 [trustedNodeSync] trusted-node-url = \"http://192.168.1.20:5052\"","title":"Configuration files"},{"location":"options.html#exit-codes","text":"Exit code Description 0 Successful exit 1 Generic failure or unspecified error 1031 Doppelganger detection; one might prefer not to restart automatically","title":"Exit Codes"},{"location":"philosophy.html","text":"Design goals One of our most important design goals is an application architecture that makes it simple to embed Nimbus into other software. Another is to minimize reliance on third-party software. A third is for the application binary to be as lightweight as possible in terms of resources used. Integration with Status I can't wait to run Nimbus straight from Status Desktop #hyped \u2014 JARRA\u00d0 HOP\u039e (@jarradhope) August 12, 2020 As part of our first design goal, our primary objective here is for Nimbus to be tightly integrated into the Status messaging app . Our dream is for you to be able to run and monitor your validator straight from Status desktop.","title":"Design goals"},{"location":"philosophy.html#design-goals","text":"One of our most important design goals is an application architecture that makes it simple to embed Nimbus into other software. Another is to minimize reliance on third-party software. A third is for the application binary to be as lightweight as possible in terms of resources used.","title":"Design goals"},{"location":"philosophy.html#integration-with-status","text":"I can't wait to run Nimbus straight from Status Desktop #hyped \u2014 JARRA\u00d0 HOP\u039e (@jarradhope) August 12, 2020 As part of our first design goal, our primary objective here is for Nimbus to be tightly integrated into the Status messaging app . Our dream is for you to be able to run and monitor your validator straight from Status desktop.","title":"Integration with Status"},{"location":"pi-guide.html","text":"Validate with a Raspberry Pi: Guide I expect the new Raspberry Pi 4 (4GB RAM option, external SSD) to handle an Eth2 validator node without breaking a sweat. That's $100 of hardware running at 10 Watts to support a 32 ETH node (currently ~$10K stake). \u2014 Justin \u00d0rake (@drakefjustin) June 24, 2019 In addition to this guide, we highly recommend this wonderful and complementary resource by community member Joe Clapis. Introduction This page will take you through how to use your laptop to program your Raspberry Pi, get Nimbus running, and connect to the Prater testnet . One of the most important aspects of the Raspberry Pi experience is trying to make it as easy as possible to get started. As such, we try our best to explain things from first-principles. Prerequisites Raspberry Pi 4 4GB (8GB recommended if also running execution client) 64GB microSD Card microSD USB adapter 5V 3A USB-C charger Reliable Wifi connection Laptop Basic understanding of the command line 200GB SSD (2TB recommended if also running execution client) Note You will need an SSD to run the Nimbus - mechanical hard drives are typically too slow to run an Ethereum node. You have two options: Use an USB portable SSD disk such as the Samsung T5 Portable SSD. Use an USB 3.0 External Hard Drive Case with a SSD Disk. For example, Ethereum on Arm use an Inateck 2.5 Hard Drive Enclosure FE2011. Make sure to buy a case with an UASP compliant chip, particularly, one of these: JMicron (JMS567 or JMS578) or ASMedia (ASM1153E). In both cases, avoid low quality SSD disks (the SSD is a key component of your node and can drastically affect both the performance and sync time). Keep in mind that you need to plug the disk to an USB 3.0 port (the blue port). Note If you have a Raspberry Pi 4 and are getting bad speeds transferring data to/from USB3.0 SSDs, please read this recommended fix. 1. Download Raspberry Pi Imager Raspberry Pi Imager is a new imaging utility that makes it simple to manage your microSD card with Raspbian (the free Pi operating system based on Debian). You can find the download link for your operating system here: Windows , macOS , Ubuntu . 2. Download Raspian 64-bit OS (Beta) You can find the latest version, here . 3. Plug in SD card Use your microSD to USB adapter to plug the SD card into your computer. 4. Download Raspberry Pi OS Open Raspberry Pi Imager and click on CHOOSE OS Scroll down and click on Use custom Find the OS you downloaded in step 2 4b. Write to SD card Click on CHOOSE SD CARD . You should see a menu pop-up with your SD card listed -- Select it Click on WRITE Click YES Make a cup of coffee :) 5. Set up wireless LAN Since you have loaded Raspberry Pi OS onto a blank SD card, you will have two partitions. The first one, which is the smaller one, is the boot partition. Create a wpa_supplicant configuration file in the boot partition with the following content: # wpa_supplicant.conf ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 country=<Insert 2 letter ISO 3166-1 country code here> network={ ssid=\"<Insert your Wifi network's name here>\" psk=\"<Insert your Wifi network's password here>\" } Note: Don't forget to replace the placeholder country , ssid , and psk values. See Wikipedia for a list of 2 letter ISO 3166-1 country codes. 6. Enable SSH (using Linux or macOS) You can access the command line of a Raspberry Pi remotely from another computer or device on the same network using SSH . While SSH is not enabled by default, you can enable it by placing a file named ssh , without any extension, onto the boot partition of the SD card. When the Pi boots, it will look for the ssh file. If it is found, SSH is enabled and the file is deleted. The content of the file does not matter; it can contain text, or nothing at all. To create an empty ssh file, from the home directory of the boot partition file, run: touch ssh 7. Find your Pi's IP address Since Raspberry Pi OS supports Multicast_DNS out of the box, you can reach your Raspberry Pi by using its hostname and the .local suffix. The default hostname on a fresh Raspberry Pi OS install is raspberrypi , so any Raspberry Pi running Raspberry Pi OS should respond to: ping raspberrypi.local The output should look more or less as follows: PING raspberrypi.local (195.177.101.93): 56 data bytes 64 bytes from 195.177.101.93: icmp_seq=0 ttl=64 time=13.272 ms 64 bytes from 195.177.101.93: icmp_seq=1 ttl=64 time=16.773 ms 64 bytes from 195.177.101.93: icmp_seq=2 ttl=64 time=10.828 ms ... Keep note of your Pi's IP address. In the above case, that's 195.177.101.93 8. SSH (using Linux or macOS) Connect to your Pi by running: ssh pi@195.177.101.93 You'll be prompted to enter a password: pi@195.177.101.93's password: Enter the Pi's default password: raspberry You should see a message that looks like the following: Linux raspberrypi 5.4.51-v8+ #1333 SMP PREEMPT Mon Aug 10 16:58:35 BST 2020 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Thu Aug 20 12:59:01 2020 SSH is enabled and the default password for the 'pi' user has not been changed. This is a security risk - please login as the 'pi' user and type 'passwd' to set a new password. Followed by a command-line prompt indicating a successful connection: pi@raspberrypi:~ $ 9. Increase swap size to 2GB The first step is to increase the swap size to 2GB (2048MB). Note: Swap acts as a breather to your system when the RAM is exhausted. When the RAM is exhausted, your Linux system uses part of the hard disk memory and allocates it to the running application. Use the Pi's built-in text editor nano to open up the swap file: sudo nano /etc/dphys-swapfile Change the value assigned to CONF_SWAPSIZE from 100 to 2048 : ... # set size to absolute value, leaving empty (default) then uses computed value # you most likely don't want this, unless you have an special disk situation CONF_SWAPSIZE=2048 ... Save ( Ctrl+S ) and exit ( Ctrl+X ). 10. Reboot Reboot your Pi to have the above changes take effect: sudo reboot This will cause your connection to close. So you'll need to ssh into your Pi again: ssh pi@195.177.101.93 Note: Remember to replace 195.177.101.93 with the IP address of your Pi. 10b. Boot from external SSD Follow this guide to copy the contents of your SD card over to your SSD, and boot your Pi from your SSD. Tips: Make sure you connect your SSD the Pi's USB 3 port (the blue port). If your Pi is headless (no monitor attached) you can use the rpi-clone repository to copy the contents of the SD over to the SSD; in a nutshell, replace steps 14 and 15 of the above guide with the following commands (which you should run from the Pi's home directory): git clone https://github.com/billw2/rpi-clone.git cd rpi-clone sudo cp rpi-clone rpi-clone-setup /usr/local/sbin sudo rpi-clone-setup -t testhostname rpi-clone sda For more on raspi-config , see here . To shutdown your Pi safely, run sudo shutdown -h now Once you're done, ssh back into your Pi. 11. Install the beacon node Open the Nimbus eth2 releases page and copy the link for the file that starts with nimbus-eth2_Linux_arm64v8 . Run this in your home directory to download nimbus-eth2: mkdir nimbus-eth2 wget <insert download link here> tar -xzf nimbus-eth2_Linux_arm64v8*.tar.gz -C nimbus-eth2 rm nimbus-eth2_Linux_arm64v8*.tar.gz Now you can find the software in the nimbus-eth2 directory. 12. Copy signing key over to Pi Note: If you haven't generated your validator key(s) and/or made your deposit yet, follow the instructions on this page before carrying on. We'll use the scp command to send files over SSH. It allows you to copy files between computers, say from your Raspberry Pi to your desktop/laptop, or vice-versa. Copy the folder containing your validator key(s) from your computer to your pi 's homefolder by opening up a new terminal window and running the following command: scp -r <VALIDATOR_KEYS_DIRECTORY> pi@195.177.101.93: Note: Don't forget the colon (:) at the end of the command! As usual, replace 195.177.101.93 with your Pi's IP address, and <VALIDATOR_KEYS_DIRECTORY> with the full pathname of your validator_keys directory (if you used the Launchpad command line app this would have been created for you when you generated your keys). Tip: run pwd in your validator_keys directory to print the full pathname to the console. 13. Import signing key into Nimbus To import your signing key into Nimbus, from the nimbus-eth2 directory run: build/nimbus_beacon_node deposits import --data-dir=build/data/shared_prater_0 ../validator_keys You'll be asked to enter the password you created to encrypt your keystore(s). Don't worry, this is entirely normal. Your validator client needs both your signing keystore(s) and the password encrypting it to import your key (since it needs to decrypt the keystore in order to be able to use it to sign on your behalf). 14. Connect to Prater We're finally ready to connect to the Prater testnet! Note: If you haven't already, we recommend registering for, and running, your own eth1 node in parallel. For instruction on how to do so, see this page . To connect to Prater, run: ./run-prater-beacon-node.sh You'll be prompted to enter a web3-provider url: To monitor the Eth1 validator deposit contract, you'll need to pair the Nimbus beacon node with a Web3 provider capable of serving Eth1 event logs. This could be a locally running Eth1 client such as Geth or a cloud service such as Infura. For more information please see our setup guide: https://status-im.github.io/nimbus-eth2/eth1.html Please enter a Web3 provider URL: Enter your web3 endpoint . 15. Check for successful connection If you look near the top of the logs printed to your console, you should see confirmation that your beacon node has started, with your local validator attached: INF 2020-12-01 11:25:33.487+01:00 Launching beacon node ... INF 2020-12-01 11:25:34.556+01:00 Loading block dag from database topics=\"beacnde\" tid=19985314 file=nimbus_beacon_node.nim:198 path=build/data/shared_prater_0/db INF 2020-12-01 11:25:35.921+01:00 Block dag initialized INF 2020-12-01 11:25:37.073+01:00 Generating new networking key ... NOT 2020-12-01 11:25:45.267+00:00 Local validator attached tid=22009 file=validator_pool.nim:33 pubkey=95e3cbe88c71ab2d0e3053b7b12ead329a37e9fb8358bdb4e56251993ab68e46b9f9fa61035fe4cf2abf4c07dfad6c45 validator=95e3cbe8 ... NOT 2020-12-01 11:25:59.512+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 file=eth1_monitor.nim:705 blockNumber=3836397 depositsProcessed=106147 NOT 2020-12-01 11:26:02.574+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 file=eth1_monitor.nim:705 blockNumber=3841412 depositsProcessed=106391 ... INF 2020-12-01 11:26:31.000+00:00 Slot start topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:505 lastSlot=96566 scheduledSlot=96567 beaconTime=1w6d9h53m24s944us774ns peers=7 head=b54486c4:96563 headEpoch=3017 finalized=2f5d12e4:96479 finalizedEpoch=3014 INF 2020-12-01 11:26:36.285+00:00 Slot end topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:593 slot=96567 nextSlot=96568 head=b54486c4:96563 headEpoch=3017 finalizedHead=2f5d12e4:96479 finalizedEpoch=3014 To keep track of your syncing progress, have a look at the output at the very bottom of the terminal window in which your validator is running. You should see something like: peers: 15 \u276f finalized: ada7228a:8765 \u276f head: b2fe11cd:8767:2 \u276f time: 9900:7 (316807) \u276f sync: wPwwwwwDwwDPwPPPwwww:7:1.2313:1.0627:12h01m(280512) Keep an eye on the number of peers your currently connected to (in the above case that's 15 ), as well as your sync progress . Note: 15 - 20 peers and an average sync speed of 0.5 - 1.0 blocks per second is normal on Prater with a Pi. If you're sync speed is much slower than this, the root of the problem may be your USB3.0 to SSD adapter. See this post for a recommended workaround. Mainnet advice Whether or not your Pi is up to the task will depend on a number of factors such as SSD speed, network connectivity, etc. As such, it's best to verify performance on a testnet first. The best thing you can do is to set your Pi to run Prater. If you have no trouble syncing and attesting on Prater, your setup should be more than good enough for mainnet as well (Mainnet is expected to use fewer resources). We've been running lots of PIs and NanoPCs 24/7 for 3 years and never got a hardware fail. It is easy (and cheap) to get redundancy of components (even spare PIs in different locations, more of this to come). \u2014 Ethereum on ARM (@EthereumOnARM) November 28, 2020 Although we don't expect a modern Pi to fail, we recommend buying a spare Pi, and enterprise grade SSD, on the off-chance it does; keep your original SD around, to make it easy for you to copy the image over. Systemd Now that you have Nimbus up and running, we recommend setting up a systemd service with an autorestart on boot (should you experience an unexpected power outage, this will ensure your validator restarts correctly). Systemd will also ensure your validator keeps running when you exit your ssh session ( Ctrl-C ) and/or switch off your laptop. For the details on how to do this, see this page . Overclocking While you shouldn't need to, if you're feeling adventurous and want to try and squeeze out some extra performance out of your Pi's CPU, see this guide by Joe Clapis. Note: we have since improved performance in several ways which should make a vanilla Pi perform well. However, overclocking may still give some benefits, in particular you have more performance to deal with anomalies (like spamming etc).","title":"Validate with a Raspberry Pi: Guide"},{"location":"pi-guide.html#validate-with-a-raspberry-pi-guide","text":"I expect the new Raspberry Pi 4 (4GB RAM option, external SSD) to handle an Eth2 validator node without breaking a sweat. That's $100 of hardware running at 10 Watts to support a 32 ETH node (currently ~$10K stake). \u2014 Justin \u00d0rake (@drakefjustin) June 24, 2019 In addition to this guide, we highly recommend this wonderful and complementary resource by community member Joe Clapis.","title":"Validate with a Raspberry Pi: Guide"},{"location":"pi-guide.html#introduction","text":"This page will take you through how to use your laptop to program your Raspberry Pi, get Nimbus running, and connect to the Prater testnet . One of the most important aspects of the Raspberry Pi experience is trying to make it as easy as possible to get started. As such, we try our best to explain things from first-principles.","title":"Introduction"},{"location":"pi-guide.html#prerequisites","text":"Raspberry Pi 4 4GB (8GB recommended if also running execution client) 64GB microSD Card microSD USB adapter 5V 3A USB-C charger Reliable Wifi connection Laptop Basic understanding of the command line 200GB SSD (2TB recommended if also running execution client) Note You will need an SSD to run the Nimbus - mechanical hard drives are typically too slow to run an Ethereum node. You have two options: Use an USB portable SSD disk such as the Samsung T5 Portable SSD. Use an USB 3.0 External Hard Drive Case with a SSD Disk. For example, Ethereum on Arm use an Inateck 2.5 Hard Drive Enclosure FE2011. Make sure to buy a case with an UASP compliant chip, particularly, one of these: JMicron (JMS567 or JMS578) or ASMedia (ASM1153E). In both cases, avoid low quality SSD disks (the SSD is a key component of your node and can drastically affect both the performance and sync time). Keep in mind that you need to plug the disk to an USB 3.0 port (the blue port). Note If you have a Raspberry Pi 4 and are getting bad speeds transferring data to/from USB3.0 SSDs, please read this recommended fix.","title":"Prerequisites"},{"location":"pi-guide.html#1-download-raspberry-pi-imager","text":"Raspberry Pi Imager is a new imaging utility that makes it simple to manage your microSD card with Raspbian (the free Pi operating system based on Debian). You can find the download link for your operating system here: Windows , macOS , Ubuntu .","title":"1. Download Raspberry Pi Imager"},{"location":"pi-guide.html#2-download-raspian-64-bit-os-beta","text":"You can find the latest version, here .","title":"2. Download Raspian 64-bit OS (Beta)"},{"location":"pi-guide.html#3-plug-in-sd-card","text":"Use your microSD to USB adapter to plug the SD card into your computer.","title":"3. Plug in SD card"},{"location":"pi-guide.html#4-download-raspberry-pi-os","text":"Open Raspberry Pi Imager and click on CHOOSE OS Scroll down and click on Use custom Find the OS you downloaded in step 2","title":"4. Download Raspberry Pi OS"},{"location":"pi-guide.html#4b-write-to-sd-card","text":"Click on CHOOSE SD CARD . You should see a menu pop-up with your SD card listed -- Select it Click on WRITE Click YES Make a cup of coffee :)","title":"4b. Write to SD card"},{"location":"pi-guide.html#5-set-up-wireless-lan","text":"Since you have loaded Raspberry Pi OS onto a blank SD card, you will have two partitions. The first one, which is the smaller one, is the boot partition. Create a wpa_supplicant configuration file in the boot partition with the following content: # wpa_supplicant.conf ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 country=<Insert 2 letter ISO 3166-1 country code here> network={ ssid=\"<Insert your Wifi network's name here>\" psk=\"<Insert your Wifi network's password here>\" } Note: Don't forget to replace the placeholder country , ssid , and psk values. See Wikipedia for a list of 2 letter ISO 3166-1 country codes.","title":"5. Set up wireless LAN"},{"location":"pi-guide.html#6-enable-ssh-using-linux-or-macos","text":"You can access the command line of a Raspberry Pi remotely from another computer or device on the same network using SSH . While SSH is not enabled by default, you can enable it by placing a file named ssh , without any extension, onto the boot partition of the SD card. When the Pi boots, it will look for the ssh file. If it is found, SSH is enabled and the file is deleted. The content of the file does not matter; it can contain text, or nothing at all. To create an empty ssh file, from the home directory of the boot partition file, run: touch ssh","title":"6. Enable SSH (using Linux or macOS)"},{"location":"pi-guide.html#7-find-your-pis-ip-address","text":"Since Raspberry Pi OS supports Multicast_DNS out of the box, you can reach your Raspberry Pi by using its hostname and the .local suffix. The default hostname on a fresh Raspberry Pi OS install is raspberrypi , so any Raspberry Pi running Raspberry Pi OS should respond to: ping raspberrypi.local The output should look more or less as follows: PING raspberrypi.local (195.177.101.93): 56 data bytes 64 bytes from 195.177.101.93: icmp_seq=0 ttl=64 time=13.272 ms 64 bytes from 195.177.101.93: icmp_seq=1 ttl=64 time=16.773 ms 64 bytes from 195.177.101.93: icmp_seq=2 ttl=64 time=10.828 ms ... Keep note of your Pi's IP address. In the above case, that's 195.177.101.93","title":"7. Find your Pi's IP address"},{"location":"pi-guide.html#8-ssh-using-linux-or-macos","text":"Connect to your Pi by running: ssh pi@195.177.101.93 You'll be prompted to enter a password: pi@195.177.101.93's password: Enter the Pi's default password: raspberry You should see a message that looks like the following: Linux raspberrypi 5.4.51-v8+ #1333 SMP PREEMPT Mon Aug 10 16:58:35 BST 2020 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Thu Aug 20 12:59:01 2020 SSH is enabled and the default password for the 'pi' user has not been changed. This is a security risk - please login as the 'pi' user and type 'passwd' to set a new password. Followed by a command-line prompt indicating a successful connection: pi@raspberrypi:~ $","title":"8. SSH (using Linux or macOS)"},{"location":"pi-guide.html#9-increase-swap-size-to-2gb","text":"The first step is to increase the swap size to 2GB (2048MB). Note: Swap acts as a breather to your system when the RAM is exhausted. When the RAM is exhausted, your Linux system uses part of the hard disk memory and allocates it to the running application. Use the Pi's built-in text editor nano to open up the swap file: sudo nano /etc/dphys-swapfile Change the value assigned to CONF_SWAPSIZE from 100 to 2048 : ... # set size to absolute value, leaving empty (default) then uses computed value # you most likely don't want this, unless you have an special disk situation CONF_SWAPSIZE=2048 ... Save ( Ctrl+S ) and exit ( Ctrl+X ).","title":"9. Increase swap size to 2GB"},{"location":"pi-guide.html#10-reboot","text":"Reboot your Pi to have the above changes take effect: sudo reboot This will cause your connection to close. So you'll need to ssh into your Pi again: ssh pi@195.177.101.93 Note: Remember to replace 195.177.101.93 with the IP address of your Pi.","title":"10. Reboot"},{"location":"pi-guide.html#10b-boot-from-external-ssd","text":"Follow this guide to copy the contents of your SD card over to your SSD, and boot your Pi from your SSD. Tips: Make sure you connect your SSD the Pi's USB 3 port (the blue port). If your Pi is headless (no monitor attached) you can use the rpi-clone repository to copy the contents of the SD over to the SSD; in a nutshell, replace steps 14 and 15 of the above guide with the following commands (which you should run from the Pi's home directory): git clone https://github.com/billw2/rpi-clone.git cd rpi-clone sudo cp rpi-clone rpi-clone-setup /usr/local/sbin sudo rpi-clone-setup -t testhostname rpi-clone sda For more on raspi-config , see here . To shutdown your Pi safely, run sudo shutdown -h now Once you're done, ssh back into your Pi.","title":"10b. Boot from external SSD"},{"location":"pi-guide.html#11-install-the-beacon-node","text":"Open the Nimbus eth2 releases page and copy the link for the file that starts with nimbus-eth2_Linux_arm64v8 . Run this in your home directory to download nimbus-eth2: mkdir nimbus-eth2 wget <insert download link here> tar -xzf nimbus-eth2_Linux_arm64v8*.tar.gz -C nimbus-eth2 rm nimbus-eth2_Linux_arm64v8*.tar.gz Now you can find the software in the nimbus-eth2 directory.","title":"11. Install the beacon node"},{"location":"pi-guide.html#12-copy-signing-key-over-to-pi","text":"Note: If you haven't generated your validator key(s) and/or made your deposit yet, follow the instructions on this page before carrying on. We'll use the scp command to send files over SSH. It allows you to copy files between computers, say from your Raspberry Pi to your desktop/laptop, or vice-versa. Copy the folder containing your validator key(s) from your computer to your pi 's homefolder by opening up a new terminal window and running the following command: scp -r <VALIDATOR_KEYS_DIRECTORY> pi@195.177.101.93: Note: Don't forget the colon (:) at the end of the command! As usual, replace 195.177.101.93 with your Pi's IP address, and <VALIDATOR_KEYS_DIRECTORY> with the full pathname of your validator_keys directory (if you used the Launchpad command line app this would have been created for you when you generated your keys). Tip: run pwd in your validator_keys directory to print the full pathname to the console.","title":"12. Copy signing key over to Pi"},{"location":"pi-guide.html#13-import-signing-key-into-nimbus","text":"To import your signing key into Nimbus, from the nimbus-eth2 directory run: build/nimbus_beacon_node deposits import --data-dir=build/data/shared_prater_0 ../validator_keys You'll be asked to enter the password you created to encrypt your keystore(s). Don't worry, this is entirely normal. Your validator client needs both your signing keystore(s) and the password encrypting it to import your key (since it needs to decrypt the keystore in order to be able to use it to sign on your behalf).","title":"13. Import signing key into Nimbus"},{"location":"pi-guide.html#14-connect-to-prater","text":"We're finally ready to connect to the Prater testnet! Note: If you haven't already, we recommend registering for, and running, your own eth1 node in parallel. For instruction on how to do so, see this page . To connect to Prater, run: ./run-prater-beacon-node.sh You'll be prompted to enter a web3-provider url: To monitor the Eth1 validator deposit contract, you'll need to pair the Nimbus beacon node with a Web3 provider capable of serving Eth1 event logs. This could be a locally running Eth1 client such as Geth or a cloud service such as Infura. For more information please see our setup guide: https://status-im.github.io/nimbus-eth2/eth1.html Please enter a Web3 provider URL: Enter your web3 endpoint .","title":"14. Connect to Prater"},{"location":"pi-guide.html#15-check-for-successful-connection","text":"If you look near the top of the logs printed to your console, you should see confirmation that your beacon node has started, with your local validator attached: INF 2020-12-01 11:25:33.487+01:00 Launching beacon node ... INF 2020-12-01 11:25:34.556+01:00 Loading block dag from database topics=\"beacnde\" tid=19985314 file=nimbus_beacon_node.nim:198 path=build/data/shared_prater_0/db INF 2020-12-01 11:25:35.921+01:00 Block dag initialized INF 2020-12-01 11:25:37.073+01:00 Generating new networking key ... NOT 2020-12-01 11:25:45.267+00:00 Local validator attached tid=22009 file=validator_pool.nim:33 pubkey=95e3cbe88c71ab2d0e3053b7b12ead329a37e9fb8358bdb4e56251993ab68e46b9f9fa61035fe4cf2abf4c07dfad6c45 validator=95e3cbe8 ... NOT 2020-12-01 11:25:59.512+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 file=eth1_monitor.nim:705 blockNumber=3836397 depositsProcessed=106147 NOT 2020-12-01 11:26:02.574+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 file=eth1_monitor.nim:705 blockNumber=3841412 depositsProcessed=106391 ... INF 2020-12-01 11:26:31.000+00:00 Slot start topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:505 lastSlot=96566 scheduledSlot=96567 beaconTime=1w6d9h53m24s944us774ns peers=7 head=b54486c4:96563 headEpoch=3017 finalized=2f5d12e4:96479 finalizedEpoch=3014 INF 2020-12-01 11:26:36.285+00:00 Slot end topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:593 slot=96567 nextSlot=96568 head=b54486c4:96563 headEpoch=3017 finalizedHead=2f5d12e4:96479 finalizedEpoch=3014 To keep track of your syncing progress, have a look at the output at the very bottom of the terminal window in which your validator is running. You should see something like: peers: 15 \u276f finalized: ada7228a:8765 \u276f head: b2fe11cd:8767:2 \u276f time: 9900:7 (316807) \u276f sync: wPwwwwwDwwDPwPPPwwww:7:1.2313:1.0627:12h01m(280512) Keep an eye on the number of peers your currently connected to (in the above case that's 15 ), as well as your sync progress . Note: 15 - 20 peers and an average sync speed of 0.5 - 1.0 blocks per second is normal on Prater with a Pi. If you're sync speed is much slower than this, the root of the problem may be your USB3.0 to SSD adapter. See this post for a recommended workaround.","title":"15. Check for successful connection"},{"location":"pi-guide.html#mainnet-advice","text":"Whether or not your Pi is up to the task will depend on a number of factors such as SSD speed, network connectivity, etc. As such, it's best to verify performance on a testnet first. The best thing you can do is to set your Pi to run Prater. If you have no trouble syncing and attesting on Prater, your setup should be more than good enough for mainnet as well (Mainnet is expected to use fewer resources). We've been running lots of PIs and NanoPCs 24/7 for 3 years and never got a hardware fail. It is easy (and cheap) to get redundancy of components (even spare PIs in different locations, more of this to come). \u2014 Ethereum on ARM (@EthereumOnARM) November 28, 2020 Although we don't expect a modern Pi to fail, we recommend buying a spare Pi, and enterprise grade SSD, on the off-chance it does; keep your original SD around, to make it easy for you to copy the image over.","title":"Mainnet advice"},{"location":"pi-guide.html#systemd","text":"Now that you have Nimbus up and running, we recommend setting up a systemd service with an autorestart on boot (should you experience an unexpected power outage, this will ensure your validator restarts correctly). Systemd will also ensure your validator keeps running when you exit your ssh session ( Ctrl-C ) and/or switch off your laptop. For the details on how to do this, see this page .","title":"Systemd"},{"location":"pi-guide.html#overclocking","text":"While you shouldn't need to, if you're feeling adventurous and want to try and squeeze out some extra performance out of your Pi's CPU, see this guide by Joe Clapis. Note: we have since improved performance in several ways which should make a vanilla Pi perform well. However, overclocking may still give some benefits, in particular you have more performance to deal with anomalies (like spamming etc).","title":"Overclocking"},{"location":"prater.html","text":"Prater testnet prater is a testnet that you can use to verify that your setup is ready for mainnet, as well as safely practise node operations such as adding and removing validators, migrating between clients and performing upgrades and backups. The prater testnet is run by client teams, the Ethereum Foundation and community members. Connecting to prater and setting up a validator follows the same procedure as a normal mainnet node with the following modifications: Validator deposits are done on the goerli testnet via the Prater launchpad To run a Prater node after making a deposit, update Nimbus and then execute ./run-prater-beacon-node.sh or use the --network:prater command line option. Custom testnets You can connect to any network provided that you have a configuration and genesis file, using the network option: build/nimbus_beacon_node --network:path/to/network --data-dir:path/to/data The network directory must have the same layout as the eth2-networks repository testnets. Other testnets Historical testnets can be found here . pyrmont - deprecated in favour of prater due to its small validator count compared to mainnet insecura - a spin-off of prater to demonstrate the weak subjectivity attack medalla - one of the first multi-client testnets, deprecated in favour of pyrmont to capture the latest 1.0 spec changes","title":"Prater testnet"},{"location":"prater.html#prater-testnet","text":"prater is a testnet that you can use to verify that your setup is ready for mainnet, as well as safely practise node operations such as adding and removing validators, migrating between clients and performing upgrades and backups. The prater testnet is run by client teams, the Ethereum Foundation and community members. Connecting to prater and setting up a validator follows the same procedure as a normal mainnet node with the following modifications: Validator deposits are done on the goerli testnet via the Prater launchpad To run a Prater node after making a deposit, update Nimbus and then execute ./run-prater-beacon-node.sh or use the --network:prater command line option.","title":"Prater testnet"},{"location":"prater.html#custom-testnets","text":"You can connect to any network provided that you have a configuration and genesis file, using the network option: build/nimbus_beacon_node --network:path/to/network --data-dir:path/to/data The network directory must have the same layout as the eth2-networks repository testnets.","title":"Custom testnets"},{"location":"prater.html#other-testnets","text":"Historical testnets can be found here . pyrmont - deprecated in favour of prater due to its small validator count compared to mainnet insecura - a spin-off of prater to demonstrate the weak subjectivity attack medalla - one of the first multi-client testnets, deprecated in favour of pyrmont to capture the latest 1.0 spec changes","title":"Other testnets"},{"location":"preparation.html","text":"Mainnet checklist Latest software Please check that you are running the latest stable Nimbus software release . In order to stay on top of new releases you should subscribe to our mailing list . More than 15 peers Please check that your node has at least 15 peers. To monitor your peer count, pay attention to the Slot start messages in your logs . See the networking page for more tips. Validator attached Please check that your validator is attached to your node. Systemd We recommend setting up a systemd service with an autorestart on boot (should you experience an unexpected power outage, this will ensure your validator restarts correctly). Systemd will also ensure your validator keeps running when you exit your ssh session ( Ctrl-C ) and/or switch off your laptop. Ethereum Foundation's Checklist As a final check, we recommend you also go through the EF'S staker checklist .","title":"Mainnet checklist"},{"location":"preparation.html#mainnet-checklist","text":"","title":"Mainnet checklist"},{"location":"preparation.html#latest-software","text":"Please check that you are running the latest stable Nimbus software release . In order to stay on top of new releases you should subscribe to our mailing list .","title":"Latest software"},{"location":"preparation.html#more-than-15-peers","text":"Please check that your node has at least 15 peers. To monitor your peer count, pay attention to the Slot start messages in your logs . See the networking page for more tips.","title":"More than 15 peers"},{"location":"preparation.html#validator-attached","text":"Please check that your validator is attached to your node.","title":"Validator attached"},{"location":"preparation.html#systemd","text":"We recommend setting up a systemd service with an autorestart on boot (should you experience an unexpected power outage, this will ensure your validator restarts correctly). Systemd will also ensure your validator keeps running when you exit your ssh session ( Ctrl-C ) and/or switch off your laptop.","title":"Systemd"},{"location":"preparation.html#ethereum-foundations-checklist","text":"As a final check, we recommend you also go through the EF'S staker checklist .","title":"Ethereum Foundation's Checklist"},{"location":"profits.html","text":"Optimise for profitability Key insights: - Profitability depends heavily on the network and peer quality - While block proposals are more lucrative than attestations, they are much rarer Check for next action before restarting To see when your validator is next due to make an attestation or proposal pay attention to the Slot end messages in your logs: INF 2021-05-31 17:46:11.094+02:00 Slot end topics=\"beacnde\" tid=213670 file=nimbus_beacon_node.nim:932 slot=1304329 nextSlot=1304330 head=cffee454:38460 headEpoch=1201 finalizedHead=077da232:38368 finalizedEpoch=1199 nextAttestationSlot=338638 nextProposalSlot=-1 nextActionWait=4m35s874ms405us837ns Specifically, have a look at nextActionWait time. If you're concerned about missing an attestation or proposal, wait until nextActionWait is greater than 4 minutes or so before restarting Nimbus. You can also use the nimbus-eth2 API . For example, to check if your validator has a next Proposal slot assigned, run: curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_duties_proposer\",\"params\":[${HEAD_EPOCH_NUMBER}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq \".result[]\" | grep ${PATTERN_WHICH_MATCHES_VALIDATOR_PUBLIC_KEYS} Subscribe to all subnets Launching the beacon node with the --subscribe-all-subnets option increases bandwidth and cpu usage, but helps the network and makes the block production algorithm perform slightly better. To elaborate a little, without this option enabled Nimbus only listens to a subset of the attestation traffic - in particular, Nimbus doesn't listen to all unaggregated traffic but instead relies on peers to aggregate attestations on the subnets it doesn't subscribe to. With this option enabled, Nimbus listens to all unaggregated channels (subscribes to all subnets). Practically speaking, this means that when producing a block, Nimbus can \"top up\" the aggregates that other peers have made with it's own unaggregated attestations. This can lead to better packing in some cases, which can lead to slightly greater rewards. Useful resources The journey of a validator balance Validator rewards in practice","title":"Optimise for profitability"},{"location":"profits.html#optimise-for-profitability","text":"Key insights: - Profitability depends heavily on the network and peer quality - While block proposals are more lucrative than attestations, they are much rarer","title":"Optimise for profitability"},{"location":"profits.html#check-for-next-action-before-restarting","text":"To see when your validator is next due to make an attestation or proposal pay attention to the Slot end messages in your logs: INF 2021-05-31 17:46:11.094+02:00 Slot end topics=\"beacnde\" tid=213670 file=nimbus_beacon_node.nim:932 slot=1304329 nextSlot=1304330 head=cffee454:38460 headEpoch=1201 finalizedHead=077da232:38368 finalizedEpoch=1199 nextAttestationSlot=338638 nextProposalSlot=-1 nextActionWait=4m35s874ms405us837ns Specifically, have a look at nextActionWait time. If you're concerned about missing an attestation or proposal, wait until nextActionWait is greater than 4 minutes or so before restarting Nimbus. You can also use the nimbus-eth2 API . For example, to check if your validator has a next Proposal slot assigned, run: curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_duties_proposer\",\"params\":[${HEAD_EPOCH_NUMBER}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq \".result[]\" | grep ${PATTERN_WHICH_MATCHES_VALIDATOR_PUBLIC_KEYS}","title":"Check for next action before restarting"},{"location":"profits.html#subscribe-to-all-subnets","text":"Launching the beacon node with the --subscribe-all-subnets option increases bandwidth and cpu usage, but helps the network and makes the block production algorithm perform slightly better. To elaborate a little, without this option enabled Nimbus only listens to a subset of the attestation traffic - in particular, Nimbus doesn't listen to all unaggregated traffic but instead relies on peers to aggregate attestations on the subnets it doesn't subscribe to. With this option enabled, Nimbus listens to all unaggregated channels (subscribes to all subnets). Practically speaking, this means that when producing a block, Nimbus can \"top up\" the aggregates that other peers have made with it's own unaggregated attestations. This can lead to better packing in some cases, which can lead to slightly greater rewards.","title":"Subscribe to all subnets"},{"location":"profits.html#useful-resources","text":"The journey of a validator balance Validator rewards in practice","title":"Useful resources"},{"location":"quick-start.html","text":"Run the beacon node This page takes you through the steps of getting a standard setup the Nimbus beacon node up and running. The quickstart setup involves running two nodes: an execution client and a beacon node - both are needed to run a full Ethereum setup. The beacon node connects to the beacon chain network, syncs historical data and provides API's to monitor and interact with the beacon chain. Running a beacon node is a worthwhile endeavor even if your are not planning on validating yourself! The guide assumes Ubuntu Linux is being used, and therefore some familiarity with the linux command line is needed. Note To become a validator, you will first need to be running a beacon node. Tip You can practice running the node safely on the Prater testnet - throughout, we'll provide instructions for both Prater and Mainnet. 1. Prepare Prepare your machine by installing Nimbus' dependencies . 2. Set up an execution client To run a beacon node, you need to have access to an execution client exposing the web3 API - throughout, we'll assume an execution client is running on the same machine as the beacon node, but this is not required. See the execution client guide for instructions on how to pick and install an execution client! 3. Install Nimbus Next, download the latest release and install it by unpacking the archive. Using a command line terminal: # Create a directory that can hold the beacon chain data and applications - this should be a fast SSD mkdir -p nimbus-eth2 # Download the latest release - replace the link with the latest release on the download page! wget https://github.com/status-im/nimbus-eth2/releases/download/v22.6.1/nimbus-eth2_Linux_amd64_22.6.1_2444e994.tar.gz # Unpack the archive into the `nimbus-eth2` directory you just created tar xvf nimbus-eth2_Linux_amd64_22.6.1_2444e994.tar.gz --strip-components 1 -C nimbus-eth2 Tip Advanced users looking to take advantage of hardware-specific features and optimization may wish to build from source instead! 4. Start the node Once you've installed the binaries, you can start the node which will initiate the sync process. cd nimbus-eth2 Mainnet Prater # Start a mainnet node ./run-mainnet-beacon-node.sh # Start a prater testnet node ./run-prater-beacon-node.sh Once the beacon node starts, you'll see it logging information to the console, like so: INF 2022 -07-19 15 :42:58.145+02:00 Launching beacon node topics = \"beacnde\" version = v22.6.1-2444e9-stateofus ... Congratulations! Your beacon node is up and running, and syncing the network! What next? If you will be running the node on a regular basis, it is recommended you set up a systemd service that automatically restarts your node if the computer reboots. If you wish to stake, continue your journey by following the validator quick start . The monitoring page contains information about how to keep your node healthy","title":"Run the beacon node"},{"location":"quick-start.html#run-the-beacon-node","text":"This page takes you through the steps of getting a standard setup the Nimbus beacon node up and running. The quickstart setup involves running two nodes: an execution client and a beacon node - both are needed to run a full Ethereum setup. The beacon node connects to the beacon chain network, syncs historical data and provides API's to monitor and interact with the beacon chain. Running a beacon node is a worthwhile endeavor even if your are not planning on validating yourself! The guide assumes Ubuntu Linux is being used, and therefore some familiarity with the linux command line is needed. Note To become a validator, you will first need to be running a beacon node. Tip You can practice running the node safely on the Prater testnet - throughout, we'll provide instructions for both Prater and Mainnet.","title":"Run the beacon node"},{"location":"quick-start.html#1-prepare","text":"Prepare your machine by installing Nimbus' dependencies .","title":"1. Prepare"},{"location":"quick-start.html#2-set-up-an-execution-client","text":"To run a beacon node, you need to have access to an execution client exposing the web3 API - throughout, we'll assume an execution client is running on the same machine as the beacon node, but this is not required. See the execution client guide for instructions on how to pick and install an execution client!","title":"2. Set up an execution client"},{"location":"quick-start.html#3-install-nimbus","text":"Next, download the latest release and install it by unpacking the archive. Using a command line terminal: # Create a directory that can hold the beacon chain data and applications - this should be a fast SSD mkdir -p nimbus-eth2 # Download the latest release - replace the link with the latest release on the download page! wget https://github.com/status-im/nimbus-eth2/releases/download/v22.6.1/nimbus-eth2_Linux_amd64_22.6.1_2444e994.tar.gz # Unpack the archive into the `nimbus-eth2` directory you just created tar xvf nimbus-eth2_Linux_amd64_22.6.1_2444e994.tar.gz --strip-components 1 -C nimbus-eth2 Tip Advanced users looking to take advantage of hardware-specific features and optimization may wish to build from source instead!","title":"3. Install Nimbus"},{"location":"quick-start.html#4-start-the-node","text":"Once you've installed the binaries, you can start the node which will initiate the sync process. cd nimbus-eth2 Mainnet Prater # Start a mainnet node ./run-mainnet-beacon-node.sh # Start a prater testnet node ./run-prater-beacon-node.sh Once the beacon node starts, you'll see it logging information to the console, like so: INF 2022 -07-19 15 :42:58.145+02:00 Launching beacon node topics = \"beacnde\" version = v22.6.1-2444e9-stateofus ... Congratulations! Your beacon node is up and running, and syncing the network! What next? If you will be running the node on a regular basis, it is recommended you set up a systemd service that automatically restarts your node if the computer reboots. If you wish to stake, continue your journey by following the validator quick start . The monitoring page contains information about how to keep your node healthy","title":"4. Start the node"},{"location":"resources.html","text":"Resources ethstaker discord : great place for tips and discussions Validator launchpad : to send deposits Beacon chain explorer : to monitor network health Nimbus discord : best place to ask questions and to stay up-to-date with critical updates Ethereum on ARM: Raspberry Pi 4 image + tutorial : turn your Raspberry Pi 4 into an eth1 or eth2 node just by flashing the MicroSD card","title":"Resources"},{"location":"resources.html#resources","text":"ethstaker discord : great place for tips and discussions Validator launchpad : to send deposits Beacon chain explorer : to monitor network health Nimbus discord : best place to ask questions and to stay up-to-date with critical updates Ethereum on ARM: Raspberry Pi 4 image + tutorial : turn your Raspberry Pi 4 into an eth1 or eth2 node just by flashing the MicroSD card","title":"Resources"},{"location":"rest-api.html","text":"REST API Nimbus exposes an extremely fast implementation of the standard Beacon Node API . The API allows you to use Nimbus together with third-party tooling such as validator clients, block explorers as well as your own monitoring infrastructure. The API is a REST interface accessed via HTTP . The API should not be exposed to the public Internet unless protected by additional security: it includes multiple endpoints which could open your node to denial-of-service (DoS) attacks. Warning: If you choose to run a public endpoint, do not use that same node for validation duties -- the load of the public REST endpoint is enough to interfere with your validator duties. Additionally, if you're running validators on your beacon node, and using the same instance for historical data queries (>2 epochs old), this may also interfere with your duties. Test your tooling against our servers The API is available from: http://testing.mainnet.beacon-api.nimbus.team/ http://unstable.mainnet.beacon-api.nimbus.team/ http://unstable.prater.beacon-api.nimbus.team/ You can make requests as follows (here we are requesting the version the Nimbus software version of the node in question): Mainnet testing branch curl -X GET http://testing.mainnet.beacon-api.nimbus.team/eth/v1/node/version Mainnet unstable branch curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/version Prater unstable branch curl -X GET http://unstable.prater.beacon-api.nimbus.team/eth/v1/node/version The test endpoints are part of pre-release testing and run an unstable version of Nimbus - we welcome reports about any problems you might have with them. They may also be unresponsive at times - so please do not rely on them for validation . We may also disable them at any time without warning. Configure your node to run a local REST server By default, the REST interface is disabled. To enable it, start the beacon node with the --rest option: ./run-mainnet-beacon-node.sh --rest Then access the API from http://localhost:5052/ . For example, to get the version of the Nimbus software your node is running: curl -X GET http://localhost:5052/eth/v1/node/version By default, only connections from the same machine are entertained. The port and listening address can be further configured through the options --rest-port and --rest-address . Warning: If you are using a validator client with a Nimbus beacon node, and running a Nimbus version prior to v1.5.5 , then you will need to launch the node with the --subscribe-all-subnets option enabled (in addition to the --rest option). Some useful commands Standard endpoints While these are all well documented in the official docs here are a handful of simple examples to get you started: Genesis Retrieve details of the chain's genesis which can be used to identify chain. With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/beacon/genesis With your own local server curl -X GET http://localhost:5052/eth/v1/beacon/genesis Deposit contract Get deposit contract address (retrieve Eth1 deposit contract address and chain ID). With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/config/deposit_contract With your own local server curl -X GET http://localhost:5052/eth/v1/config/deposit_contract Peer count Get peer count With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/peer_count With your own local server curl -X GET http://localhost:5052/eth/v1/node/peer_count Syncing status Get node syncing status (requests the beacon node to describe if it's currently syncing or not, and if it is, what block it is up to) With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/syncing With your own local server curl -X GET http://localhost:5052/eth/v1/node/syncing Fork schedule Get scheduled upcoming forks (retrieve all forks, past present and future, of which this node is aware) With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/config/fork_schedule With your own local server curl -X GET http://localhost:5052/eth/v1/config/fork_schedule Nimbus specific endpoints In addition to supporting the standard endpoints, Nimbus has a set of specific endpoints which augment the standard API. Check Graffiti String With our mainnet testing server curl -X GET http://testing.mainnet.beacon-api.nimbus.team/nimbus/v1/graffiti With your own local server curl -X GET http://localhost:5052/nimbus/v1/graffiti Set Graffiti String With your own local server curl -X POST http://localhost:5052/nimbus/v1/graffiti -H \"Content-Type: text/plain\" -d \"new graffiti\" Set Log Level TBA Specification The complete API specification is well documented here See the repository Readme here","title":"REST API"},{"location":"rest-api.html#rest-api","text":"Nimbus exposes an extremely fast implementation of the standard Beacon Node API . The API allows you to use Nimbus together with third-party tooling such as validator clients, block explorers as well as your own monitoring infrastructure. The API is a REST interface accessed via HTTP . The API should not be exposed to the public Internet unless protected by additional security: it includes multiple endpoints which could open your node to denial-of-service (DoS) attacks. Warning: If you choose to run a public endpoint, do not use that same node for validation duties -- the load of the public REST endpoint is enough to interfere with your validator duties. Additionally, if you're running validators on your beacon node, and using the same instance for historical data queries (>2 epochs old), this may also interfere with your duties.","title":"REST API"},{"location":"rest-api.html#test-your-tooling-against-our-servers","text":"The API is available from: http://testing.mainnet.beacon-api.nimbus.team/ http://unstable.mainnet.beacon-api.nimbus.team/ http://unstable.prater.beacon-api.nimbus.team/ You can make requests as follows (here we are requesting the version the Nimbus software version of the node in question):","title":"Test your tooling against our servers"},{"location":"rest-api.html#mainnet-testing-branch","text":"curl -X GET http://testing.mainnet.beacon-api.nimbus.team/eth/v1/node/version","title":"Mainnet testing branch"},{"location":"rest-api.html#mainnet-unstable-branch","text":"curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/version","title":"Mainnet unstable branch"},{"location":"rest-api.html#prater-unstable-branch","text":"curl -X GET http://unstable.prater.beacon-api.nimbus.team/eth/v1/node/version The test endpoints are part of pre-release testing and run an unstable version of Nimbus - we welcome reports about any problems you might have with them. They may also be unresponsive at times - so please do not rely on them for validation . We may also disable them at any time without warning.","title":"Prater unstable branch"},{"location":"rest-api.html#configure-your-node-to-run-a-local-rest-server","text":"By default, the REST interface is disabled. To enable it, start the beacon node with the --rest option: ./run-mainnet-beacon-node.sh --rest Then access the API from http://localhost:5052/ . For example, to get the version of the Nimbus software your node is running: curl -X GET http://localhost:5052/eth/v1/node/version By default, only connections from the same machine are entertained. The port and listening address can be further configured through the options --rest-port and --rest-address . Warning: If you are using a validator client with a Nimbus beacon node, and running a Nimbus version prior to v1.5.5 , then you will need to launch the node with the --subscribe-all-subnets option enabled (in addition to the --rest option).","title":"Configure your node to run a local REST server"},{"location":"rest-api.html#some-useful-commands","text":"","title":"Some useful commands"},{"location":"rest-api.html#standard-endpoints","text":"While these are all well documented in the official docs here are a handful of simple examples to get you started:","title":"Standard endpoints"},{"location":"rest-api.html#genesis","text":"Retrieve details of the chain's genesis which can be used to identify chain. With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/beacon/genesis With your own local server curl -X GET http://localhost:5052/eth/v1/beacon/genesis","title":"Genesis"},{"location":"rest-api.html#deposit-contract","text":"Get deposit contract address (retrieve Eth1 deposit contract address and chain ID). With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/config/deposit_contract With your own local server curl -X GET http://localhost:5052/eth/v1/config/deposit_contract","title":"Deposit contract"},{"location":"rest-api.html#peer-count","text":"Get peer count With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/peer_count With your own local server curl -X GET http://localhost:5052/eth/v1/node/peer_count","title":"Peer count"},{"location":"rest-api.html#syncing-status","text":"Get node syncing status (requests the beacon node to describe if it's currently syncing or not, and if it is, what block it is up to) With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/syncing With your own local server curl -X GET http://localhost:5052/eth/v1/node/syncing","title":"Syncing status"},{"location":"rest-api.html#fork-schedule","text":"Get scheduled upcoming forks (retrieve all forks, past present and future, of which this node is aware) With our mainnet testing server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/config/fork_schedule With your own local server curl -X GET http://localhost:5052/eth/v1/config/fork_schedule","title":"Fork schedule"},{"location":"rest-api.html#nimbus-specific-endpoints","text":"In addition to supporting the standard endpoints, Nimbus has a set of specific endpoints which augment the standard API.","title":"Nimbus specific endpoints"},{"location":"rest-api.html#check-graffiti-string","text":"With our mainnet testing server curl -X GET http://testing.mainnet.beacon-api.nimbus.team/nimbus/v1/graffiti With your own local server curl -X GET http://localhost:5052/nimbus/v1/graffiti","title":"Check Graffiti String"},{"location":"rest-api.html#set-graffiti-string","text":"With your own local server curl -X POST http://localhost:5052/nimbus/v1/graffiti -H \"Content-Type: text/plain\" -d \"new graffiti\"","title":"Set Graffiti String"},{"location":"rest-api.html#set-log-level","text":"TBA","title":"Set Log Level"},{"location":"rest-api.html#specification","text":"The complete API specification is well documented here See the repository Readme here","title":"Specification"},{"location":"rp-quick-start.html","text":"Rocket Pool: Introductory guide We believe decentralised staking pools like @Rocket_Pool and @DAppNode DAO are essential to ensuring @ethereum 's future as an unbreakable and censorship-resistant system. https://t.co/FXQQICZsfL \u2014 Nimbus (@ethnimbus) March 5, 2021 This guide offers a bare-bones introduction to getting up and running with Nimbus and Rocket Pool -- a trustless staking pool which matches those who wish to stake some ETH with those who wish to operate a node. Nota Bene: Rocket Pool is not only for node operators. Staking in Rocket Pool as a regular user is as easy as navigating to the Rocket Pool website , entering an amount of ETH to stake, and clicking Start! When you stake, you will immediately receive an amount of rETH with equivalent value to the ETH you deposit. This allows anyone, no matter how technical or wealthy, to help contribute to the decentralisation of the network. It assumes you are familiar with the basics of how Rocket Pool works. If that's not the case, we recommend reading through the following resources first: - Our introductory post - Rocket Pool explainer series: part 1 - Rocket Pool explainer series: part 2 - Beta Finale announcement If you're a Raspberry Pi user, we highly recommend this wonderful and complementary resouce by community member Joe Clapis. Note: Rocket Pool is currently running their Beta Finale on Pyrmont testnet, so this is the perfect time to get up to speed and play around with their stack. 1. Install Docker + Compose If you're using Ubuntu, Debian, CentOS or Fedora, please skip this step. To install Docker and Compose follow the instructions here and here . Note that Docker Desktop for Mac and Windows already include Compose, which means that if you're using a Mac or Windows device you can ignore the second link. 2. Install smart node client Background: The Rocket Pool smart node software stack provides all of the necessary infrastructure for running a node in the Rocket Pool network: it contains a smart node client, which provides a command-line interface for managing a smart node either locally or remotely (over SSH) and a smart node service; which provides an API for client communication and performs background node tasks (such as validator duties). You can install the smart node client with either curl or wget . To see which tool you have available, run: curl --version wget --version Once you know whether you have curl or wget available, you can find the relevant command for your operating system here . For example, if you're running MacOS with curl installed, you should run: curl -L https://github.com/rocket-pool/smartnode-install/releases/latest/download/rocketpool-cli-darwin-amd64 -o /usr/local/bin/rocketpool && chmod +x /usr/local/bin/rocketpool 3. Install smart node service To install the smart node service, run: rocketpool service install Note: If you\u2019re using Ubuntu, Debian, CentOS or Fedora, the above will automatically install docker engine and docker-compose on your system. If automatic dependency installation is not supported on your platform (this is the case for MacOS for example), run rocketpool service install -d instead. 4. Configure smart node client Now you're ready to configure the smart node client: rocketpool service config You\u2019ll be prompted to select an eth1 and eth2 client to run. If you like, you can use Infura instead of running an eth1 client. The default is to select a random client for you, so make sure you select Nimbus! 5. Start Rocket Pool To start Rocket Pool, open a new shell session and run: rocketpool service start You should see the following: Starting rocketpool_eth1 ... done Starting rocketpool_api ... done Starting rocketpool_eth2 ... done Starting rocketpool_watchtower ... done Starting rocketpool_node ... done Starting rocketpool_validator ... done Note: Docker will make sure that Rocket Pool keeps running, even if Nimbus crashes or you restart your computer. 6. Check Nimbus is running correctly To ensure Nimbus is running correctly, run: rocketpool service logs eth2 Nimbus will print lines that look like this: eth2_1 | INF 2021-02-21 06:35:43.302+00:00 Slot start topics=\"beacnde\" tid=1 file=nimbus_beacon_node.nim:940 lastSlot=682377 scheduledSlot=682378 delay=302ms641us581ns peers=47 head=f752f69a:745 headEpoch=23 finalized=2717f624:672 finalizedEpoch=21 sync=\"PPUPPPDDDD:10:2.0208:1.5333:01d20h29m (736)\" eth2_1 | INF 2021-02-21 06:35:43.568+00:00 Slot end The time towards the end ( 01d20h29m ) tells you how long Nimbus thinks it will be until you're fully synced. 7. Create a Rocket Pool wallet Now that Nimbus is syncing, you're ready to create a Rocket Pool wallet to create and hold your validator keys: rocketpool wallet init 8. Find your node address You'll need to find your node address in order to be able to request Goerli ETH: rocketpool node status 9. Request Goerli ETH Request 35 Goerli ETH from the faucet to the address you found in the previous step. Note: you'll need slightly more than 32 ETH since you'll also need to interact with the Rocket Pool smart contracts to request RPL. 10. Request Goerli RPL You'll also need some RPL. To request RPL directly from the Rocket Pool faucet, run: rocketpool faucet withdraw-rpl 11. Register your node Now you're finally ready to register your node with Rocket Pool: rocketpool node register 12. Make a deposit The final step is to deposit 32 ETH to initialise your validator (don't worry you'll get half of it back): rocketpool node deposit Note: You\u2019ll see a prompt that will ask you to select the amount of ETH you wish to deposit. Select 32 ETH to ensure you can start staking ASAP. At some point (shouldn't take more than 24 hours) you'll be assigned an additional 16 ETH to manage from Rocket Pool stakers: at this stage you'll be able to ask for a 16 ETH refund using rocketpool minipool refund . That\u2019s it! You\u2019re officially part of the Rocket Pool network! Tip: Once Nimbus is synced, you'll be able to check on the status of your minipool by running: rocketpool minipool status Key resources / further reading Node Operator\u2019s Guide: https://medium.com/rocket-pool/rocket-pool-v2-5-beta-node-operators-guide-77859891766b Smart node docs (for all things documentation related): https://rocket-pool.readthedocs.io/en/latest/smart-node/introduction.html Joe Clapis' guide (Excellent resource for Pi users): https://github.com/jclapis/rp-pi-guide/blob/main/Overview.md Rocket Pool's discord","title":"Rocket Pool: Introductory guide"},{"location":"rp-quick-start.html#rocket-pool-introductory-guide","text":"We believe decentralised staking pools like @Rocket_Pool and @DAppNode DAO are essential to ensuring @ethereum 's future as an unbreakable and censorship-resistant system. https://t.co/FXQQICZsfL \u2014 Nimbus (@ethnimbus) March 5, 2021 This guide offers a bare-bones introduction to getting up and running with Nimbus and Rocket Pool -- a trustless staking pool which matches those who wish to stake some ETH with those who wish to operate a node. Nota Bene: Rocket Pool is not only for node operators. Staking in Rocket Pool as a regular user is as easy as navigating to the Rocket Pool website , entering an amount of ETH to stake, and clicking Start! When you stake, you will immediately receive an amount of rETH with equivalent value to the ETH you deposit. This allows anyone, no matter how technical or wealthy, to help contribute to the decentralisation of the network. It assumes you are familiar with the basics of how Rocket Pool works. If that's not the case, we recommend reading through the following resources first: - Our introductory post - Rocket Pool explainer series: part 1 - Rocket Pool explainer series: part 2 - Beta Finale announcement If you're a Raspberry Pi user, we highly recommend this wonderful and complementary resouce by community member Joe Clapis. Note: Rocket Pool is currently running their Beta Finale on Pyrmont testnet, so this is the perfect time to get up to speed and play around with their stack.","title":"Rocket Pool: Introductory guide"},{"location":"rp-quick-start.html#1-install-docker-compose","text":"If you're using Ubuntu, Debian, CentOS or Fedora, please skip this step. To install Docker and Compose follow the instructions here and here . Note that Docker Desktop for Mac and Windows already include Compose, which means that if you're using a Mac or Windows device you can ignore the second link.","title":"1. Install Docker + Compose"},{"location":"rp-quick-start.html#2-install-smart-node-client","text":"Background: The Rocket Pool smart node software stack provides all of the necessary infrastructure for running a node in the Rocket Pool network: it contains a smart node client, which provides a command-line interface for managing a smart node either locally or remotely (over SSH) and a smart node service; which provides an API for client communication and performs background node tasks (such as validator duties). You can install the smart node client with either curl or wget . To see which tool you have available, run: curl --version wget --version Once you know whether you have curl or wget available, you can find the relevant command for your operating system here . For example, if you're running MacOS with curl installed, you should run: curl -L https://github.com/rocket-pool/smartnode-install/releases/latest/download/rocketpool-cli-darwin-amd64 -o /usr/local/bin/rocketpool && chmod +x /usr/local/bin/rocketpool","title":"2. Install smart node client"},{"location":"rp-quick-start.html#3-install-smart-node-service","text":"To install the smart node service, run: rocketpool service install Note: If you\u2019re using Ubuntu, Debian, CentOS or Fedora, the above will automatically install docker engine and docker-compose on your system. If automatic dependency installation is not supported on your platform (this is the case for MacOS for example), run rocketpool service install -d instead.","title":"3. Install smart node service"},{"location":"rp-quick-start.html#4-configure-smart-node-client","text":"Now you're ready to configure the smart node client: rocketpool service config You\u2019ll be prompted to select an eth1 and eth2 client to run. If you like, you can use Infura instead of running an eth1 client. The default is to select a random client for you, so make sure you select Nimbus!","title":"4. Configure smart node client"},{"location":"rp-quick-start.html#5-start-rocket-pool","text":"To start Rocket Pool, open a new shell session and run: rocketpool service start You should see the following: Starting rocketpool_eth1 ... done Starting rocketpool_api ... done Starting rocketpool_eth2 ... done Starting rocketpool_watchtower ... done Starting rocketpool_node ... done Starting rocketpool_validator ... done Note: Docker will make sure that Rocket Pool keeps running, even if Nimbus crashes or you restart your computer.","title":"5. Start Rocket Pool"},{"location":"rp-quick-start.html#6-check-nimbus-is-running-correctly","text":"To ensure Nimbus is running correctly, run: rocketpool service logs eth2 Nimbus will print lines that look like this: eth2_1 | INF 2021-02-21 06:35:43.302+00:00 Slot start topics=\"beacnde\" tid=1 file=nimbus_beacon_node.nim:940 lastSlot=682377 scheduledSlot=682378 delay=302ms641us581ns peers=47 head=f752f69a:745 headEpoch=23 finalized=2717f624:672 finalizedEpoch=21 sync=\"PPUPPPDDDD:10:2.0208:1.5333:01d20h29m (736)\" eth2_1 | INF 2021-02-21 06:35:43.568+00:00 Slot end The time towards the end ( 01d20h29m ) tells you how long Nimbus thinks it will be until you're fully synced.","title":"6. Check Nimbus is running correctly"},{"location":"rp-quick-start.html#7-create-a-rocket-pool-wallet","text":"Now that Nimbus is syncing, you're ready to create a Rocket Pool wallet to create and hold your validator keys: rocketpool wallet init","title":"7. Create a Rocket Pool wallet"},{"location":"rp-quick-start.html#8-find-your-node-address","text":"You'll need to find your node address in order to be able to request Goerli ETH: rocketpool node status","title":"8. Find your node address"},{"location":"rp-quick-start.html#9-request-goerli-eth","text":"Request 35 Goerli ETH from the faucet to the address you found in the previous step. Note: you'll need slightly more than 32 ETH since you'll also need to interact with the Rocket Pool smart contracts to request RPL.","title":"9. Request Goerli ETH"},{"location":"rp-quick-start.html#10-request-goerli-rpl","text":"You'll also need some RPL. To request RPL directly from the Rocket Pool faucet, run: rocketpool faucet withdraw-rpl","title":"10. Request Goerli RPL"},{"location":"rp-quick-start.html#11-register-your-node","text":"Now you're finally ready to register your node with Rocket Pool: rocketpool node register","title":"11. Register your node"},{"location":"rp-quick-start.html#12-make-a-deposit","text":"The final step is to deposit 32 ETH to initialise your validator (don't worry you'll get half of it back): rocketpool node deposit Note: You\u2019ll see a prompt that will ask you to select the amount of ETH you wish to deposit. Select 32 ETH to ensure you can start staking ASAP. At some point (shouldn't take more than 24 hours) you'll be assigned an additional 16 ETH to manage from Rocket Pool stakers: at this stage you'll be able to ask for a 16 ETH refund using rocketpool minipool refund . That\u2019s it! You\u2019re officially part of the Rocket Pool network! Tip: Once Nimbus is synced, you'll be able to check on the status of your minipool by running: rocketpool minipool status","title":"12. Make a deposit"},{"location":"rp-quick-start.html#key-resources-further-reading","text":"Node Operator\u2019s Guide: https://medium.com/rocket-pool/rocket-pool-v2-5-beta-node-operators-guide-77859891766b Smart node docs (for all things documentation related): https://rocket-pool.readthedocs.io/en/latest/smart-node/introduction.html Joe Clapis' guide (Excellent resource for Pi users): https://github.com/jclapis/rp-pi-guide/blob/main/Overview.md Rocket Pool's discord","title":"Key resources / further reading"},{"location":"run-a-validator.html","text":"Run a validator Once your beacon node is running and synced , the next step is to set up a validator. No validator client needed Unlike other beacon chain clients, Nimbus does not require setting up a separate validator client process - the beacon node can itself perform validator duties. This is a simple, safe and efficient way to get started. Advanced users may want to use a separate validator client process instead. 1. Deposit Make a deposit for your validator 2. Import Import your validator keys into Nimbus 3. Validate Start performing duties by restarting the node Congratulations - you're now set up to be earning a small amount of ETH every 6.4 minutes in return for keeping the Ethereum network secure! What next? While that's all there is to it, it is essential that you both keep an eye on your validator and keep Nimbus updated regularly \ud83d\udcab","title":"Run a validator"},{"location":"run-a-validator.html#run-a-validator","text":"Once your beacon node is running and synced , the next step is to set up a validator. No validator client needed Unlike other beacon chain clients, Nimbus does not require setting up a separate validator client process - the beacon node can itself perform validator duties. This is a simple, safe and efficient way to get started. Advanced users may want to use a separate validator client process instead.","title":"Run a validator"},{"location":"run-a-validator.html#1-deposit","text":"Make a deposit for your validator","title":"1. Deposit"},{"location":"run-a-validator.html#2-import","text":"Import your validator keys into Nimbus","title":"2. Import"},{"location":"run-a-validator.html#3-validate","text":"Start performing duties by restarting the node Congratulations - you're now set up to be earning a small amount of ETH every 6.4 minutes in return for keeping the Ethereum network secure! What next? While that's all there is to it, it is essential that you both keep an eye on your validator and keep Nimbus updated regularly \ud83d\udcab","title":"3. Validate"},{"location":"security_issues.html","text":"Security related issues For any security related issues, follow responsible disclosure standards. Do not file public issues. Please file a report at the ethereum bug bounty program in order to receive a reward for your findings. When in doubt, please send an encrypted email to security@status.im and ask ( gpg key ). Security related issues are (sufficient but not necessary criteria): Soundness of protocols (consensus model, p2p protocols): consensus liveness and integrity. Errors and failures in the cryptographic primitives RCE vulnerabilities Any issues causing consensus splits from the rest of the network Denial of service (DOS) vectors Broken Access Control Memory Errors Security Misconfiguration Vulnerable Dependencies Authentication Failures Data Integrity Failures Logging and Monitoring Vulnerabilities","title":"Security issues"},{"location":"security_issues.html#security-related-issues","text":"For any security related issues, follow responsible disclosure standards. Do not file public issues. Please file a report at the ethereum bug bounty program in order to receive a reward for your findings. When in doubt, please send an encrypted email to security@status.im and ask ( gpg key ). Security related issues are (sufficient but not necessary criteria): Soundness of protocols (consensus model, p2p protocols): consensus liveness and integrity. Errors and failures in the cryptographic primitives RCE vulnerabilities Any issues causing consensus splits from the rest of the network Denial of service (DOS) vectors Broken Access Control Memory Errors Security Misconfiguration Vulnerable Dependencies Authentication Failures Data Integrity Failures Logging and Monitoring Vulnerabilities","title":"Security related issues"},{"location":"start-syncing.html","text":"Sync your node Before you can use your node, it needs to sync with the network. Syncing starts automatically when you start your node, and may take several days depending on the performance of your hardware. If you are planning to become a validator, you should ensure that your beacon node is completely synced before submitting your deposit, or you might miss attestations and proposal duties until it has finished syncing. Tip To get started more quickly, you can perform a trusted node sync instead - this requires access to a synced node or a third-party service. Note You need need to run an execution client ( web3 provider ) together with the beacon node. See here for instructions on how to do so. Networks Using Nimbus, you can connect either to a testnet, or mainnet. Mainnet is the main ethereum network where real assets are at stake, while testnets are used by users and developers alike to test their node and setup before committing real assets. Tip If this is the first time you're setting up your node, it is recommended you run it on a testnet first. Later, when everything is working, you can easily switch to mainned. Testnet To start syncing the prater testnet , from the nimbus-eth2 repository, run: ./run-prater-beacon-node.sh Mainnet To start syncing the Ethereum beacon chain mainnet, run: ./run-mainnet-beacon-node.sh Log output You should see the following output: INF 2020-12-01 11:25:33.487+01:00 Launching beacon node ... INF 2020-12-01 11:25:34.556+01:00 Loading block dag from database topics=\"beacnde\" tid=19985314 file=nimbus_beacon_node.nim:198 path=build/data/shared_prater_0/db INF 2020-12-01 11:25:35.921+01:00 Block dag initialized INF 2020-12-01 11:25:37.073+01:00 Generating new networking key ... NOT 2020-12-01 11:25:59.512+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 file=eth1_monitor.nim:705 blockNumber=3836397 depositsProcessed=106147 NOT 2020-12-01 11:26:02.574+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 file=eth1_monitor.nim:705 blockNumber=3841412 depositsProcessed=106391 ... INF 2020-12-01 11:26:31.000+00:00 Slot start topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:505 lastSlot=96566 scheduledSlot=96567 beaconTime=1w6d9h53m24s944us774ns peers=7 head=b54486c4:96563 headEpoch=3017 finalized=2f5d12e4:96479 finalizedEpoch=3014 INF 2020-12-01 11:26:36.285+00:00 Slot end topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:593 slot=96567 nextSlot=96568 head=b54486c4:96563 headEpoch=3017 finalizedHead=2f5d12e4:96479 finalizedEpoch=3014 ... Data directory While running, the beacon node will store chain data and other information its data directory, which by default is found in build/data - for more information, see the data directory guide. Command line options You can add command line options to the startup command - for example, to change the port to 9100, use: ./run-prater-beacon-node.sh --tcp-port = 9100 --udp-port = 9100 To see a list of the command line options availabe to you, with descriptions, run: ./build/nimbus_beacon_node --help More information is available from the options page. Keep track of your sync progress See here for how to keep track of your sync progress.","title":"Sync your node"},{"location":"start-syncing.html#sync-your-node","text":"Before you can use your node, it needs to sync with the network. Syncing starts automatically when you start your node, and may take several days depending on the performance of your hardware. If you are planning to become a validator, you should ensure that your beacon node is completely synced before submitting your deposit, or you might miss attestations and proposal duties until it has finished syncing. Tip To get started more quickly, you can perform a trusted node sync instead - this requires access to a synced node or a third-party service. Note You need need to run an execution client ( web3 provider ) together with the beacon node. See here for instructions on how to do so.","title":"Sync your node"},{"location":"start-syncing.html#networks","text":"Using Nimbus, you can connect either to a testnet, or mainnet. Mainnet is the main ethereum network where real assets are at stake, while testnets are used by users and developers alike to test their node and setup before committing real assets. Tip If this is the first time you're setting up your node, it is recommended you run it on a testnet first. Later, when everything is working, you can easily switch to mainned.","title":"Networks"},{"location":"start-syncing.html#testnet","text":"To start syncing the prater testnet , from the nimbus-eth2 repository, run: ./run-prater-beacon-node.sh","title":"Testnet"},{"location":"start-syncing.html#mainnet","text":"To start syncing the Ethereum beacon chain mainnet, run: ./run-mainnet-beacon-node.sh","title":"Mainnet"},{"location":"start-syncing.html#log-output","text":"You should see the following output: INF 2020-12-01 11:25:33.487+01:00 Launching beacon node ... INF 2020-12-01 11:25:34.556+01:00 Loading block dag from database topics=\"beacnde\" tid=19985314 file=nimbus_beacon_node.nim:198 path=build/data/shared_prater_0/db INF 2020-12-01 11:25:35.921+01:00 Block dag initialized INF 2020-12-01 11:25:37.073+01:00 Generating new networking key ... NOT 2020-12-01 11:25:59.512+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 file=eth1_monitor.nim:705 blockNumber=3836397 depositsProcessed=106147 NOT 2020-12-01 11:26:02.574+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 file=eth1_monitor.nim:705 blockNumber=3841412 depositsProcessed=106391 ... INF 2020-12-01 11:26:31.000+00:00 Slot start topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:505 lastSlot=96566 scheduledSlot=96567 beaconTime=1w6d9h53m24s944us774ns peers=7 head=b54486c4:96563 headEpoch=3017 finalized=2f5d12e4:96479 finalizedEpoch=3014 INF 2020-12-01 11:26:36.285+00:00 Slot end topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:593 slot=96567 nextSlot=96568 head=b54486c4:96563 headEpoch=3017 finalizedHead=2f5d12e4:96479 finalizedEpoch=3014 ...","title":"Log output"},{"location":"start-syncing.html#data-directory","text":"While running, the beacon node will store chain data and other information its data directory, which by default is found in build/data - for more information, see the data directory guide.","title":"Data directory"},{"location":"start-syncing.html#command-line-options","text":"You can add command line options to the startup command - for example, to change the port to 9100, use: ./run-prater-beacon-node.sh --tcp-port = 9100 --udp-port = 9100 To see a list of the command line options availabe to you, with descriptions, run: ./build/nimbus_beacon_node --help More information is available from the options page.","title":"Command line options"},{"location":"start-syncing.html#keep-track-of-your-sync-progress","text":"See here for how to keep track of your sync progress.","title":"Keep track of your sync progress"},{"location":"suggested-fee-recipient.html","text":"Suggested Fee Recipient A suggested fee recipient offers an execution client, in a merged Ethereum network, a coinbase it might use. The execution client might not use this offered coinbase, unless one ensures that by running, controlling, and similarly configuring this execution client oneself. Nimbus offers two ways to a suggested fee recipient, the --suggested-fee-recipient option and a per-validator recipient set using the keymanager API. Any validator without a per-validator recipient set will fall back to a --suggested-fee-recipient if configured. In order, it selects from the first available, for each validator, of: the keymanager API per-validator suggested fee recipient --suggested-fee-recipient For example, nimbus_beacon_node --suggested-fee-recipient=0x79b53bc7a89347d3ab90789e99a0a9c58f2fea57 suggests to the execution client that 0x79b53bc7a89347d3ab90789e99a0a9c58f2fea57 might be the coinbase. If this Nimbus node has two validators, one of which has its own suggested fee recipient via the keymanager API and the other does not, the former would use its own per-validator suggested fee cipient while the latter would fall back to 0x79b53bc7a89347d3ab90789e99a0a9c58f2fea57 .","title":"Suggested Fee Recipient"},{"location":"suggested-fee-recipient.html#suggested-fee-recipient","text":"A suggested fee recipient offers an execution client, in a merged Ethereum network, a coinbase it might use. The execution client might not use this offered coinbase, unless one ensures that by running, controlling, and similarly configuring this execution client oneself. Nimbus offers two ways to a suggested fee recipient, the --suggested-fee-recipient option and a per-validator recipient set using the keymanager API. Any validator without a per-validator recipient set will fall back to a --suggested-fee-recipient if configured. In order, it selects from the first available, for each validator, of: the keymanager API per-validator suggested fee recipient --suggested-fee-recipient For example, nimbus_beacon_node --suggested-fee-recipient=0x79b53bc7a89347d3ab90789e99a0a9c58f2fea57 suggests to the execution client that 0x79b53bc7a89347d3ab90789e99a0a9c58f2fea57 might be the coinbase. If this Nimbus node has two validators, one of which has its own suggested fee recipient via the keymanager API and the other does not, the former would use its own per-validator suggested fee cipient while the latter would fall back to 0x79b53bc7a89347d3ab90789e99a0a9c58f2fea57 .","title":"Suggested Fee Recipient"},{"location":"troubleshooting.html","text":"Troubleshooting Note The commands on this page refer to mainnet. If you're running on prater or another testnet, replace mainnet accordingly We are continuously making improvements to both stability and resource usage. If you run into any problem with Nimbus and are not running the latest version, chances are they have already been fixed - see the update guide for instructions of how to upgrade. If you can't find a solution to your problem here, get in touch with us on our discord ! Note When installing Nimbus, you will typically be using the latest stable release. However, the latest changes happen in the unstable branch - if you're looking to test the chaings coming to the next Nimbus release, consider building Nimbus from source using the unstable branch. Networking A correctly configured network is key to getting good performance - the networking guide details everything you need to know! Low peer count If you see a message that looks like the following in your logs: Peer count low, no new peers discovered... Your node is finding it hard to find peers. It's possible that you may be behind a firewall. Try restarting your client and passing --nat:extip:$EXT_IP_ADDRESS as an option to ./run-mainnet-beacon-node.sh , where $EXT_IP_ADDRESS is your real IP. For example, if your real IP address is 1.2.3.4 , you'd run: ./run-mainnet-beacon-node.sh --nat:extip:1.2.3.4 If this doesn't improve things, you may need to set enr-auto-update and/or set up port forwarding . No peers for topic If you see a message that looks like the following in your logs: No peers for topic, skipping publish... This means you've missed an attestation because either your peer count is too low, or the quality of your peers is lacking. There can be several reasons behind why this is the case. The first thing to check is that your max peer count ( --max-peers ) hasn't been set too low. In order to ensure your attestations are published correctly, --max-peers should be set to 70, at the very least . Note that Nimbus manages peers slightly differently to other clients (we automatically connect to more peers than we actually use, in order not to have to do costly reconnects). As such, --max-peers is set to 160 by default. If this doesn't fix the problem, please double check your node is able to receive incoming connections . Misc Console hanging for too long on update To update and restart, run git pull , make update , followed by make nimbus_beacon_node : cd nimbus-eth2 git pull make update # Update dependencies make nimbus_beacon_node # Rebuild beacon node ./run-mainnet-beacon-node.sh # Restart using same keys as last run If you find that make update causes the console to hang for too long, try running make update V=1 or make update V=2 instead (these will print a more verbose output to the console which may make it easier to diagnose the problem). Note: rest assured that when you restart the beacon node, the software will resume from where it left off, using the validator keys you have already imported. Starting over after importing wrong keys Your keys and secrets are stored in the data directory (usually build/data/shared_mainnet_0 ). If you imported the wrong keys, simply remove them from validators and secrets found in the data directory. Sync problems If you\u2019re experiencing sync problems, make sure that your network is healthy and that you have a recent version installed. In rare cases, such as after an unclean shutdown, it may happen that the database has been corrupted and you need to restart the sync - to do so, remove the db folder from the data directory and restart the node. You can get re-synced faster using trusted node sync . noCommand does not accept arguments If, on start, you see The command 'noCommand' does not accept arguments Double check to see if your command line flags are in the correct format, i.e. --foo=bar , --baz , or --foo-bar=qux . Tip All options accepting values need a = between the option name and the value! Address already in use error If you're seeing an error that looks like: Error: unhandled exception: (98) Address already in use [TransportOsError] It means that you're running another node that is using the same port as the one you're trying to start (or that you're trying to start a second instance of the same node). To change the base port, run: ./run-mainnet-beacon-node.sh --tcp-port=9100 --udp-port=9100 (You can replace 9100 with a port of your choosing) Catching up on validator duties If you're being flooded with Catching up on validator duties messages, your CPU is probably too slow to run Nimbus. Please check that your setup matches our system requirements . Local timer is broken error If you cannot start your validator because you are seeing logs that look like the following: WRN 2021-01-08 06:32:46.975+00:00 Local timer is broken or peer's status information is invalid topics=\"beacnde\" tid=120491 file=sync_manager.nim:752 wall_clock_slot=271961 remote_head_slot=271962 local_head_slot=269254 peer=16U*mELUgu index=0 tolerance_value=0 peer_speed=2795.0 peer_score=200 This is likely due to the fact that your local clock is off. To compare your local time with a internet time, run: cat </dev/tcp/time.nist.gov/13 ; date -u The first line in the output will give you internet time. And the second line will give you the time according to your machine. These shouldn't be more than half a second apart. See the requirements page for more information on how to set automatic time synchronization. Eth1 chain monitor failure If you see an error that looks like the following: {\"lvl\":\"ERR\",\"ts\":\"2021-05-11 09:05:53.547+00:00\",\"msg\":\"Eth1 chain monitoring failure, restarting\",\"topics\":\"eth1\",\"tid\":1,\"file\":\"eth1_monitor.nim:1158\",\"err\":\"Trying to access value with err: Failed to setup web3 connection\"} It's because your node can't connect to the web3 provider you have specified. Please double check that you've correctly specified your provider. If you haven't done so already, we recommend adding a backup . Discovered new external address warning log WRN 2021-03-11 13:26:25.943-08:00 Discovered new external address but ENR auto update is off topics=\"discv5\" tid=77655 file=protocol.nim:940 majority=Some(\"myIPaddressHere\":9000) previous=None[Address] This message is displayed regularly when Nimbus canot detect your correct IP address. It may be a sign that you have a dynamic IP address that keeps changing. Or that Nimbus is unable to get your IP from the UPnP . The first step is to try relaunching the beacon node with the --enr-auto-update option. If that doesn't fix the problem, double check that your ports are open and that you have port forwarding enabled on your gateway (assuming that you are behind a NAT ). See our page on monitoring the health of your node for more. Raspberry Pi Trouble transferring data to/from USB3.0 SSDs We have seen reports of degraded performance when using several types of USB3.0 to SSD adapters or when using native USB3.0 disk drives. This post details why there is a difference in behaviour from models prior to Pi 4 and the recommended workaround.","title":"Troubleshooting"},{"location":"troubleshooting.html#troubleshooting","text":"Note The commands on this page refer to mainnet. If you're running on prater or another testnet, replace mainnet accordingly We are continuously making improvements to both stability and resource usage. If you run into any problem with Nimbus and are not running the latest version, chances are they have already been fixed - see the update guide for instructions of how to upgrade. If you can't find a solution to your problem here, get in touch with us on our discord ! Note When installing Nimbus, you will typically be using the latest stable release. However, the latest changes happen in the unstable branch - if you're looking to test the chaings coming to the next Nimbus release, consider building Nimbus from source using the unstable branch.","title":"Troubleshooting"},{"location":"troubleshooting.html#networking","text":"A correctly configured network is key to getting good performance - the networking guide details everything you need to know!","title":"Networking"},{"location":"troubleshooting.html#low-peer-count","text":"If you see a message that looks like the following in your logs: Peer count low, no new peers discovered... Your node is finding it hard to find peers. It's possible that you may be behind a firewall. Try restarting your client and passing --nat:extip:$EXT_IP_ADDRESS as an option to ./run-mainnet-beacon-node.sh , where $EXT_IP_ADDRESS is your real IP. For example, if your real IP address is 1.2.3.4 , you'd run: ./run-mainnet-beacon-node.sh --nat:extip:1.2.3.4 If this doesn't improve things, you may need to set enr-auto-update and/or set up port forwarding .","title":"Low peer count"},{"location":"troubleshooting.html#no-peers-for-topic","text":"If you see a message that looks like the following in your logs: No peers for topic, skipping publish... This means you've missed an attestation because either your peer count is too low, or the quality of your peers is lacking. There can be several reasons behind why this is the case. The first thing to check is that your max peer count ( --max-peers ) hasn't been set too low. In order to ensure your attestations are published correctly, --max-peers should be set to 70, at the very least . Note that Nimbus manages peers slightly differently to other clients (we automatically connect to more peers than we actually use, in order not to have to do costly reconnects). As such, --max-peers is set to 160 by default. If this doesn't fix the problem, please double check your node is able to receive incoming connections .","title":"No peers for topic"},{"location":"troubleshooting.html#misc","text":"","title":"Misc"},{"location":"troubleshooting.html#console-hanging-for-too-long-on-update","text":"To update and restart, run git pull , make update , followed by make nimbus_beacon_node : cd nimbus-eth2 git pull make update # Update dependencies make nimbus_beacon_node # Rebuild beacon node ./run-mainnet-beacon-node.sh # Restart using same keys as last run If you find that make update causes the console to hang for too long, try running make update V=1 or make update V=2 instead (these will print a more verbose output to the console which may make it easier to diagnose the problem). Note: rest assured that when you restart the beacon node, the software will resume from where it left off, using the validator keys you have already imported.","title":"Console hanging for too long on update"},{"location":"troubleshooting.html#starting-over-after-importing-wrong-keys","text":"Your keys and secrets are stored in the data directory (usually build/data/shared_mainnet_0 ). If you imported the wrong keys, simply remove them from validators and secrets found in the data directory.","title":"Starting over after importing wrong keys"},{"location":"troubleshooting.html#sync-problems","text":"If you\u2019re experiencing sync problems, make sure that your network is healthy and that you have a recent version installed. In rare cases, such as after an unclean shutdown, it may happen that the database has been corrupted and you need to restart the sync - to do so, remove the db folder from the data directory and restart the node. You can get re-synced faster using trusted node sync .","title":"Sync problems"},{"location":"troubleshooting.html#nocommand-does-not-accept-arguments","text":"If, on start, you see The command 'noCommand' does not accept arguments Double check to see if your command line flags are in the correct format, i.e. --foo=bar , --baz , or --foo-bar=qux . Tip All options accepting values need a = between the option name and the value!","title":"noCommand does not accept arguments"},{"location":"troubleshooting.html#address-already-in-use-error","text":"If you're seeing an error that looks like: Error: unhandled exception: (98) Address already in use [TransportOsError] It means that you're running another node that is using the same port as the one you're trying to start (or that you're trying to start a second instance of the same node). To change the base port, run: ./run-mainnet-beacon-node.sh --tcp-port=9100 --udp-port=9100 (You can replace 9100 with a port of your choosing)","title":"Address already in use error"},{"location":"troubleshooting.html#catching-up-on-validator-duties","text":"If you're being flooded with Catching up on validator duties messages, your CPU is probably too slow to run Nimbus. Please check that your setup matches our system requirements .","title":"Catching up on validator duties"},{"location":"troubleshooting.html#local-timer-is-broken-error","text":"If you cannot start your validator because you are seeing logs that look like the following: WRN 2021-01-08 06:32:46.975+00:00 Local timer is broken or peer's status information is invalid topics=\"beacnde\" tid=120491 file=sync_manager.nim:752 wall_clock_slot=271961 remote_head_slot=271962 local_head_slot=269254 peer=16U*mELUgu index=0 tolerance_value=0 peer_speed=2795.0 peer_score=200 This is likely due to the fact that your local clock is off. To compare your local time with a internet time, run: cat </dev/tcp/time.nist.gov/13 ; date -u The first line in the output will give you internet time. And the second line will give you the time according to your machine. These shouldn't be more than half a second apart. See the requirements page for more information on how to set automatic time synchronization.","title":"Local timer is broken error"},{"location":"troubleshooting.html#eth1-chain-monitor-failure","text":"If you see an error that looks like the following: {\"lvl\":\"ERR\",\"ts\":\"2021-05-11 09:05:53.547+00:00\",\"msg\":\"Eth1 chain monitoring failure, restarting\",\"topics\":\"eth1\",\"tid\":1,\"file\":\"eth1_monitor.nim:1158\",\"err\":\"Trying to access value with err: Failed to setup web3 connection\"} It's because your node can't connect to the web3 provider you have specified. Please double check that you've correctly specified your provider. If you haven't done so already, we recommend adding a backup .","title":"Eth1 chain monitor failure"},{"location":"troubleshooting.html#discovered-new-external-address-warning-log","text":"WRN 2021-03-11 13:26:25.943-08:00 Discovered new external address but ENR auto update is off topics=\"discv5\" tid=77655 file=protocol.nim:940 majority=Some(\"myIPaddressHere\":9000) previous=None[Address] This message is displayed regularly when Nimbus canot detect your correct IP address. It may be a sign that you have a dynamic IP address that keeps changing. Or that Nimbus is unable to get your IP from the UPnP . The first step is to try relaunching the beacon node with the --enr-auto-update option. If that doesn't fix the problem, double check that your ports are open and that you have port forwarding enabled on your gateway (assuming that you are behind a NAT ). See our page on monitoring the health of your node for more.","title":"Discovered new external address warning log"},{"location":"troubleshooting.html#raspberry-pi","text":"","title":"Raspberry Pi"},{"location":"troubleshooting.html#trouble-transferring-data-tofrom-usb30-ssds","text":"We have seen reports of degraded performance when using several types of USB3.0 to SSD adapters or when using native USB3.0 disk drives. This post details why there is a difference in behaviour from models prior to Pi 4 and the recommended workaround.","title":"Trouble transferring data to/from USB3.0 SSDs"},{"location":"trusted-node-sync.html","text":"Sync from a trusted node This feature is available from v1.7.0 onwards When you start the beacon node for the first time, it will connect to the beacon chain network and start syncing automatically - a process that can take several days. Trusted node sync allows you to get started more quickly by fetching a recent checkpoint from a trusted node - you can get started in minutes instead of days. To use trusted node sync, you must have access to a node that you trust that exposes the Beacon API (for example a locally running backup node). Should this node, or your connection to it, be compromised, your node will not be able to detect whether or not it is being served false information. It is possibly to use trusted node sync with a third-party API provider -- see here for how to verify that the chain you are given corresponds to the canonical chain at the time. Perform a trusted node sync Tip Make sure to replace http://localhost:5052 in the commands below with the appropriate endpoint of the trusted beacon node. http://localhost:5052 is the default endpoint exposed by Nimbus, but this is not consistent across all clients. For example, if your trusted node is a Prysm node , it exposes 127.0.0.1:3500 by default. Which means you would run the commands below with --trusted-node-url=http://127.0.0.1:3500 Mainnet Prater build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --trusted-node-url = http://localhost:5052 build/nimbus_beacon_node trustedNodeSync --network:prater \\ --data-dir = build/data/shared_prater_0 \\ --trusted-node-url = http://localhost:5052 Note Because trusted node sync by default copies all blocks via REST, you may hit API limits if you are using a third-party provider. If this happens to you, you may need to use the --backfill option to delay the backfill of the block history . Verify you synced the correct chain When performing a trusted node sync, you can manually verify that the correct chain was synced by comparing the head hash with other sources (e.g. your friends, forums, chats and web sites). If you're syncing using your own backup node you can retrieve the current head from the node using: # Make sure to enable the `--rest` option when running your node: curl http://localhost:5052/eth/v1/beacon/blocks/head/root The head root is also printed in the log output at regular intervals. Note The same Beacon API request works with any API provider. For example, to compare it out with our mainnet testing server , you can run: curl -X GET http://testing.mainnet.beacon-api.nimbus.team/eth/v1/beacon/blocks/head/root Advanced Delay block history backfill By default, both the state and the full block history will be downloaded from the trusted node. It is possible to get started more quickly by delaying the backfill of the block history using the --backfill=false parameter. In this case, the beacon node will first sync to the current head so that it can start performing its duties, then backfill the blocks from the network. You can also resume the trusted node backfill at any time by simply running the trusted node sync command again. Note While backfilling blocks, your node will not be able to answer historical requests or sync requests. This might lead to you being de-scored, and eventually disconnected, by your peers. Modify sync point By default, the node will sync up to the latest finalized checkpoint of the node that you're syncing with. While you can choose a different sync point using a block hash or a slot number, this block must fall on an epoch boundary: build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --blockId:0x239940f2537f5bbee1a3829f9058f4c04f49897e4d325145153ca89838dfc9e2 Sync from checkpoint files If you have a state and a block file available, you can start the node using the finalized checkpoint options: # Obtain a state and a block from a Beacon API - these must be in SSZ format: curl -o state.32000.ssz \\ -H 'Accept: application/octet-stream' \\ http://localhost:5052/eth/v2/debug/beacon/states/32000 curl -o block.32000.ssz \\ -H 'Accept: application/octet-stream' \\ http://localhost:5052/eth/v2/beacon/blocks/32000 # Start the beacon node using the downloaded state and block as starting point ./run-mainnet-beacon-node.sh \\ --finalized-checkpoint-block = block.32000.ssz \\ --finalized-checkpoint-state = state.32000.ssz Recreate historical state access indices When performing checkpoint sync, the historical state data from the time before the checkpoint is not available. To recreate the indices and caches necessary for historical state access, run trusted node sync with the --reindex flag - this can be done on an already-synced node as well, in which case the process will simply resume where it left off: build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --reindex = true","title":"Sync from a trusted node"},{"location":"trusted-node-sync.html#sync-from-a-trusted-node","text":"This feature is available from v1.7.0 onwards When you start the beacon node for the first time, it will connect to the beacon chain network and start syncing automatically - a process that can take several days. Trusted node sync allows you to get started more quickly by fetching a recent checkpoint from a trusted node - you can get started in minutes instead of days. To use trusted node sync, you must have access to a node that you trust that exposes the Beacon API (for example a locally running backup node). Should this node, or your connection to it, be compromised, your node will not be able to detect whether or not it is being served false information. It is possibly to use trusted node sync with a third-party API provider -- see here for how to verify that the chain you are given corresponds to the canonical chain at the time.","title":"Sync from a trusted node"},{"location":"trusted-node-sync.html#perform-a-trusted-node-sync","text":"Tip Make sure to replace http://localhost:5052 in the commands below with the appropriate endpoint of the trusted beacon node. http://localhost:5052 is the default endpoint exposed by Nimbus, but this is not consistent across all clients. For example, if your trusted node is a Prysm node , it exposes 127.0.0.1:3500 by default. Which means you would run the commands below with --trusted-node-url=http://127.0.0.1:3500 Mainnet Prater build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --trusted-node-url = http://localhost:5052 build/nimbus_beacon_node trustedNodeSync --network:prater \\ --data-dir = build/data/shared_prater_0 \\ --trusted-node-url = http://localhost:5052 Note Because trusted node sync by default copies all blocks via REST, you may hit API limits if you are using a third-party provider. If this happens to you, you may need to use the --backfill option to delay the backfill of the block history .","title":"Perform a trusted node sync"},{"location":"trusted-node-sync.html#verify-you-synced-the-correct-chain","text":"When performing a trusted node sync, you can manually verify that the correct chain was synced by comparing the head hash with other sources (e.g. your friends, forums, chats and web sites). If you're syncing using your own backup node you can retrieve the current head from the node using: # Make sure to enable the `--rest` option when running your node: curl http://localhost:5052/eth/v1/beacon/blocks/head/root The head root is also printed in the log output at regular intervals. Note The same Beacon API request works with any API provider. For example, to compare it out with our mainnet testing server , you can run: curl -X GET http://testing.mainnet.beacon-api.nimbus.team/eth/v1/beacon/blocks/head/root","title":"Verify you synced the correct chain"},{"location":"trusted-node-sync.html#advanced","text":"","title":"Advanced"},{"location":"trusted-node-sync.html#delay-block-history-backfill","text":"By default, both the state and the full block history will be downloaded from the trusted node. It is possible to get started more quickly by delaying the backfill of the block history using the --backfill=false parameter. In this case, the beacon node will first sync to the current head so that it can start performing its duties, then backfill the blocks from the network. You can also resume the trusted node backfill at any time by simply running the trusted node sync command again. Note While backfilling blocks, your node will not be able to answer historical requests or sync requests. This might lead to you being de-scored, and eventually disconnected, by your peers.","title":"Delay block history backfill"},{"location":"trusted-node-sync.html#modify-sync-point","text":"By default, the node will sync up to the latest finalized checkpoint of the node that you're syncing with. While you can choose a different sync point using a block hash or a slot number, this block must fall on an epoch boundary: build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --blockId:0x239940f2537f5bbee1a3829f9058f4c04f49897e4d325145153ca89838dfc9e2","title":"Modify sync point"},{"location":"trusted-node-sync.html#sync-from-checkpoint-files","text":"If you have a state and a block file available, you can start the node using the finalized checkpoint options: # Obtain a state and a block from a Beacon API - these must be in SSZ format: curl -o state.32000.ssz \\ -H 'Accept: application/octet-stream' \\ http://localhost:5052/eth/v2/debug/beacon/states/32000 curl -o block.32000.ssz \\ -H 'Accept: application/octet-stream' \\ http://localhost:5052/eth/v2/beacon/blocks/32000 # Start the beacon node using the downloaded state and block as starting point ./run-mainnet-beacon-node.sh \\ --finalized-checkpoint-block = block.32000.ssz \\ --finalized-checkpoint-state = state.32000.ssz","title":"Sync from checkpoint files"},{"location":"trusted-node-sync.html#recreate-historical-state-access-indices","text":"When performing checkpoint sync, the historical state data from the time before the checkpoint is not available. To recreate the indices and caches necessary for historical state access, run trusted node sync with the --reindex flag - this can be done on an already-synced node as well, in which case the process will simply resume where it left off: build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --reindex = true","title":"Recreate historical state access indices"},{"location":"validator-client.html","text":"Run a separate validator client Warning This feature is currently in BETA - we are still testing it and implementation details may change in response to community feedback. We strongly advise against using it on mainnet - your validators may get slashed By default, Nimbus loads validator keys into the main beacon node process, which is a simple, safe and efficient way to run a validator. Advanced users may wish to run validators in a separate process, allowing more flexible deployment strategies. The Nimbus beacon node supports both its own and third-party validator clients via the built-in REST API . Warning So far, all slashings with known causes have been linked to overly complex setups involving separation between beacon node and validator client! Only use this setup if you've taken steps to mitigate the increased risk. Build The validator client is currently only available when built from source. To build the validator client, build the beacon node , then issue: make -j4 nimbus_validator_client When upgrading, follow the upgrade guide but use the following command to update both beacon node and validator client at the same time: # after \"git pull && make update\": make -j4 nimbus_beacon_node nimbus_validator_client Setup To run a separate validator client, you must first make sure that your beacon node has its REST API enabled - start it with the --rest option. Next, choose a data directory for the validator client and import the keys there: build/nimbus_beacon_node deposits import \\ --data-dir:build/data/vc_shared_prater_0 \"<YOUR VALIDATOR KEYS DIRECTORY>\" Warning Do not use the same data directory for beacon node and validator client - they will both try to load the same keys which may result in slashing! Warning If you are migrating your keys from the beacon node to the validator client, simply move the secrets and validators folders in the beacon node data directory to the data directory of the validator client With the keys imported, you are ready to start validator client: build/nimbus_validator_client \\ --data-dir:build/data/vc_shared_prater_0 Options The validator client shares many of its options with the beacon node. To see the available command line options, run: # See help build/nimbus_validator_client --help --beacon-node The client will by defualt connect to a beacon node on the same machine as the validator client. Pick a different node with --beacon-node : build/nimbus_validator_client \\ --data-dir:build/data/vc_shared_prater_0 \\ --beacon-node:http://host:port/","title":"Run a separate validator client"},{"location":"validator-client.html#run-a-separate-validator-client","text":"Warning This feature is currently in BETA - we are still testing it and implementation details may change in response to community feedback. We strongly advise against using it on mainnet - your validators may get slashed By default, Nimbus loads validator keys into the main beacon node process, which is a simple, safe and efficient way to run a validator. Advanced users may wish to run validators in a separate process, allowing more flexible deployment strategies. The Nimbus beacon node supports both its own and third-party validator clients via the built-in REST API . Warning So far, all slashings with known causes have been linked to overly complex setups involving separation between beacon node and validator client! Only use this setup if you've taken steps to mitigate the increased risk.","title":"Run a separate validator client"},{"location":"validator-client.html#build","text":"The validator client is currently only available when built from source. To build the validator client, build the beacon node , then issue: make -j4 nimbus_validator_client When upgrading, follow the upgrade guide but use the following command to update both beacon node and validator client at the same time: # after \"git pull && make update\": make -j4 nimbus_beacon_node nimbus_validator_client","title":"Build"},{"location":"validator-client.html#setup","text":"To run a separate validator client, you must first make sure that your beacon node has its REST API enabled - start it with the --rest option. Next, choose a data directory for the validator client and import the keys there: build/nimbus_beacon_node deposits import \\ --data-dir:build/data/vc_shared_prater_0 \"<YOUR VALIDATOR KEYS DIRECTORY>\" Warning Do not use the same data directory for beacon node and validator client - they will both try to load the same keys which may result in slashing! Warning If you are migrating your keys from the beacon node to the validator client, simply move the secrets and validators folders in the beacon node data directory to the data directory of the validator client With the keys imported, you are ready to start validator client: build/nimbus_validator_client \\ --data-dir:build/data/vc_shared_prater_0","title":"Setup"},{"location":"validator-client.html#options","text":"The validator client shares many of its options with the beacon node. To see the available command line options, run: # See help build/nimbus_validator_client --help","title":"Options"},{"location":"validator-client.html#-beacon-node","text":"The client will by defualt connect to a beacon node on the same machine as the validator client. Pick a different node with --beacon-node : build/nimbus_validator_client \\ --data-dir:build/data/vc_shared_prater_0 \\ --beacon-node:http://host:port/","title":"--beacon-node"},{"location":"validator-monitor.html","text":"Validator monitoring Warning This feature is currently in BETA - implementation details such as metric names and counters may change in response to community feedback. The validator monitoring feature allows for tracking the life-cycle and performance of one or more validators in detail. Monitoring can be carried out for any validator, with slightly more detail for validators that are running in the same beacon node. Every time the validator performs a duty, the duty is recorded and the monitor keeps track of the reward-related events for having performed it. For example: When attesting, the attestation is added to an aggregate, then a block, before a reward is applied to the state When performing sync committee duties, likewise Validator actions can be traced either through logging, or comprehensive metrics that allow for creating alerts in monitoring tools. The metrics are broadly compatible with Lighthouse , thus dashboards and alerts can be used with either client with minor adjustments. Enabling validator monitoring The monitor can be enabled either for all keys that are used with a particular beacon node, or for a specific list of validators, or both. # Enable automatic monitoring of all validators used with this beacon node ./run-mainnet-beacon-node.sh --validator-monitor-auto # Enable monitoring of one or more specific validators ./run-mainnet-beacon-node.sh \\ --validator-monitor-pubkey=0xa1d1ad0714035353258038e964ae9675dc0252ee22cea896825c01458e1807bfad2f9969338798548d9858a571f7425c \\ --validator-monitor-pubkey=0xb2ff4716ed345b05dd1dfc6a5a9fa70856d8c75dcc9e881dd2f766d5f891326f0d10e96f3a444ce6c912b69c22c6754d # Publish metrics as totals for all monitored validators instead of each validator separately - used for limiting the load on metrics when monitoring many validators ./run-mainnet-beacon-node.sh --validator-monitor-totals Understanding monitoring When a validator performs a duty, such as signing an attestation or a sync committee message, this is broadcast to the network. Other nodes pick it up and package the message into an aggregate and later a block. The block is included in the canonical chain and a reward is given two epochs (~13 minutes) later. The monitor tracks these actions and will log each step at the INF level. If any step is missed, a NOT log is shown instead. The typical lifecycle of an attestation might look something like the following: INF 2021-11-22 11:32:44.228+01:00 Attestation seen topics=\"val_mon\" attestation=\"(aggregation_bits: 0b0000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, data: (slot: 2656363, index: 11, beacon_block_root: \\\"bbe7fc25\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\"), signature: \\\"b88ef2f2\\\")\" src=api epoch=83011 validator=b93c290b INF 2021-11-22 11:32:51.293+01:00 Attestation included in aggregate topics=\"val_mon\" aggregate=\"(aggregation_bits: 0b1111111101011111001101111111101100111111110100111011111110110101110111111010111111011101111011101111111111101111100001111111100111, data: (slot: 2656363, index: 11, beacon_block_root: \\\"bbe7fc25\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\"), signature: \\\"8576b3fc\\\")\" src=gossip epoch=83011 validator=b93c290b INF 2021-11-22 11:33:07.193+01:00 Attestation included in block attestation_data=\"(slot: 2656364, index: 9, beacon_block_root: \\\"c7761767\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\")\" block_slot=2656365 inclusion_lag_slots=0 epoch=83011 validator=b65b6e1b The lifecycle of a particular message can be traced by following the epoch=.... validator=... fields in the message. Failures at any point are recorded at a higher logging level, such as NOT (ice): NOT 2021-11-17 20:53:42.108+01:00 Attestation failed to match head topics=\"chaindag\" epoch=81972 validator=... Failures are reported with a lag of two epochs (~13 minutes) - to examine the log for potential root causes, the logs from the epoch in the failure message should be looked at. Warning It should be noted that metrics are tracked for the current history - in the case of a reorg on the chain - in particular a deep reorg - no attempt is made to revisit previously reported values. In the case that finality is delayed, the risk of stale metrics increases. Likewise, many metrics, such as aggregation inclusion, reflect conditions on the network - it may happen that the same message is counted more than once under certain conditions. Monitoring metrics The full list of metrics supported by the validator monitoring feature can be seen in the source code or by examining the metrics output: curl -s localhost:8008/metrics | grep HELP.*validator_","title":"Validator monitoring"},{"location":"validator-monitor.html#validator-monitoring","text":"Warning This feature is currently in BETA - implementation details such as metric names and counters may change in response to community feedback. The validator monitoring feature allows for tracking the life-cycle and performance of one or more validators in detail. Monitoring can be carried out for any validator, with slightly more detail for validators that are running in the same beacon node. Every time the validator performs a duty, the duty is recorded and the monitor keeps track of the reward-related events for having performed it. For example: When attesting, the attestation is added to an aggregate, then a block, before a reward is applied to the state When performing sync committee duties, likewise Validator actions can be traced either through logging, or comprehensive metrics that allow for creating alerts in monitoring tools. The metrics are broadly compatible with Lighthouse , thus dashboards and alerts can be used with either client with minor adjustments.","title":"Validator monitoring"},{"location":"validator-monitor.html#enabling-validator-monitoring","text":"The monitor can be enabled either for all keys that are used with a particular beacon node, or for a specific list of validators, or both. # Enable automatic monitoring of all validators used with this beacon node ./run-mainnet-beacon-node.sh --validator-monitor-auto # Enable monitoring of one or more specific validators ./run-mainnet-beacon-node.sh \\ --validator-monitor-pubkey=0xa1d1ad0714035353258038e964ae9675dc0252ee22cea896825c01458e1807bfad2f9969338798548d9858a571f7425c \\ --validator-monitor-pubkey=0xb2ff4716ed345b05dd1dfc6a5a9fa70856d8c75dcc9e881dd2f766d5f891326f0d10e96f3a444ce6c912b69c22c6754d # Publish metrics as totals for all monitored validators instead of each validator separately - used for limiting the load on metrics when monitoring many validators ./run-mainnet-beacon-node.sh --validator-monitor-totals","title":"Enabling validator monitoring"},{"location":"validator-monitor.html#understanding-monitoring","text":"When a validator performs a duty, such as signing an attestation or a sync committee message, this is broadcast to the network. Other nodes pick it up and package the message into an aggregate and later a block. The block is included in the canonical chain and a reward is given two epochs (~13 minutes) later. The monitor tracks these actions and will log each step at the INF level. If any step is missed, a NOT log is shown instead. The typical lifecycle of an attestation might look something like the following: INF 2021-11-22 11:32:44.228+01:00 Attestation seen topics=\"val_mon\" attestation=\"(aggregation_bits: 0b0000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, data: (slot: 2656363, index: 11, beacon_block_root: \\\"bbe7fc25\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\"), signature: \\\"b88ef2f2\\\")\" src=api epoch=83011 validator=b93c290b INF 2021-11-22 11:32:51.293+01:00 Attestation included in aggregate topics=\"val_mon\" aggregate=\"(aggregation_bits: 0b1111111101011111001101111111101100111111110100111011111110110101110111111010111111011101111011101111111111101111100001111111100111, data: (slot: 2656363, index: 11, beacon_block_root: \\\"bbe7fc25\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\"), signature: \\\"8576b3fc\\\")\" src=gossip epoch=83011 validator=b93c290b INF 2021-11-22 11:33:07.193+01:00 Attestation included in block attestation_data=\"(slot: 2656364, index: 9, beacon_block_root: \\\"c7761767\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\")\" block_slot=2656365 inclusion_lag_slots=0 epoch=83011 validator=b65b6e1b The lifecycle of a particular message can be traced by following the epoch=.... validator=... fields in the message. Failures at any point are recorded at a higher logging level, such as NOT (ice): NOT 2021-11-17 20:53:42.108+01:00 Attestation failed to match head topics=\"chaindag\" epoch=81972 validator=... Failures are reported with a lag of two epochs (~13 minutes) - to examine the log for potential root causes, the logs from the epoch in the failure message should be looked at. Warning It should be noted that metrics are tracked for the current history - in the case of a reorg on the chain - in particular a deep reorg - no attempt is made to revisit previously reported values. In the case that finality is delayed, the risk of stale metrics increases. Likewise, many metrics, such as aggregation inclusion, reflect conditions on the network - it may happen that the same message is counted more than once under certain conditions.","title":"Understanding monitoring"},{"location":"validator-monitor.html#monitoring-metrics","text":"The full list of metrics supported by the validator monitoring feature can be seen in the source code or by examining the metrics output: curl -s localhost:8008/metrics | grep HELP.*validator_","title":"Monitoring metrics"},{"location":"voluntary-exit.html","text":"Perform a voluntary exit This feature is available from v1.7.0 onwards - earlier versions relied on the now removed JSON-RPC API . Voluntary exits allow validators to permanently stop performing their duties, and eventually recover the deposit. Exits are subject to a wait period that depends on the length of the exit queue. While a validator is exiting, it still must perform its duties in order not to lose funds to inactivity penalities. Warning Voluntary exits are irreversible . You won't be able to validate again with the same key. You will also not be able to withdraw your funds until a future hard fork that enables withdrawals.* Note Voluntary exits won't be processed if the chain isn't finalising. To perform a voluntary exit, make sure your beacon node is running with the --rest option enabled (e.g. ./run-mainnet-beacon-node.sh --rest ), then run: Mainnet Prater build/nimbus_beacon_node deposits exit \\ --data-dir=build/data/shared_mainnet_0 \\ --validator=<VALIDATOR_PUBLIC_KEY> build/nimbus_beacon_node deposits exit \\ --data-dir=build/data/shared_prater_0 \\ --validator=<VALIDATOR_PUBLIC_KEY> Note Make sure your <VALIDATOR_PUBLIC_KEY> is prefixed with 0x . In other words the public key should look like 0x95e3... rest-url parameter The --rest-url parameter can be used to point the exit command to a specific node for publishing the request, as long as it's compatible with the REST API .","title":"Perform a voluntary exit"},{"location":"voluntary-exit.html#perform-a-voluntary-exit","text":"This feature is available from v1.7.0 onwards - earlier versions relied on the now removed JSON-RPC API . Voluntary exits allow validators to permanently stop performing their duties, and eventually recover the deposit. Exits are subject to a wait period that depends on the length of the exit queue. While a validator is exiting, it still must perform its duties in order not to lose funds to inactivity penalities. Warning Voluntary exits are irreversible . You won't be able to validate again with the same key. You will also not be able to withdraw your funds until a future hard fork that enables withdrawals.* Note Voluntary exits won't be processed if the chain isn't finalising. To perform a voluntary exit, make sure your beacon node is running with the --rest option enabled (e.g. ./run-mainnet-beacon-node.sh --rest ), then run: Mainnet Prater build/nimbus_beacon_node deposits exit \\ --data-dir=build/data/shared_mainnet_0 \\ --validator=<VALIDATOR_PUBLIC_KEY> build/nimbus_beacon_node deposits exit \\ --data-dir=build/data/shared_prater_0 \\ --validator=<VALIDATOR_PUBLIC_KEY> Note Make sure your <VALIDATOR_PUBLIC_KEY> is prefixed with 0x . In other words the public key should look like 0x95e3...","title":"Perform a voluntary exit"},{"location":"voluntary-exit.html#rest-url-parameter","text":"The --rest-url parameter can be used to point the exit command to a specific node for publishing the request, as long as it's compatible with the REST API .","title":"rest-url parameter"},{"location":"web3-backup.html","text":"Backup web3 provider It's a good idea to add a backup web3 provider in case your main one goes down. You can do this by simply repeating the --web3-url parameter on launch. For example, if your primary execution client is a local Geth , but you want to use Infura as a backup you would run: Warn After the merge , it will no longer be possible to rely on third-party services like Infura to run a beacon node! ./run-mainnet-beacon-node.sh \\ --web3-url = \"ws://127.0.0.1:8546\" \\ --web3-url = \"wss://mainnet.infura.io/ws/v3/...\"","title":"Backup web3 provider"},{"location":"web3-backup.html#backup-web3-provider","text":"It's a good idea to add a backup web3 provider in case your main one goes down. You can do this by simply repeating the --web3-url parameter on launch. For example, if your primary execution client is a local Geth , but you want to use Infura as a backup you would run: Warn After the merge , it will no longer be possible to rely on third-party services like Infura to run a beacon node! ./run-mainnet-beacon-node.sh \\ --web3-url = \"ws://127.0.0.1:8546\" \\ --web3-url = \"wss://mainnet.infura.io/ws/v3/...\"","title":"Backup web3 provider"}]}